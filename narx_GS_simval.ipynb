{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "from data import load_narx_data, load_data, convert_to_narx\n",
    "from model import Narx\n",
    "from util_fun import calculate_error_nrms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narx_sim_nrms(model, n_a, n_b, x_data, y_data, device, n_val_samples=3000):\n",
    "     #init upast and ypast as lists.\n",
    "    upast = [0]*n_b \n",
    "    ypast = [0]*n_a \n",
    "\n",
    "    x_data, y_data =[x[:n_val_samples] for x in [x_data, y_data]]\n",
    "    ylist = []\n",
    "    for unow in x_data.cpu().detach().numpy():\n",
    "        #compute the current y given by f\n",
    "        narx_input=torch.as_tensor(np.concatenate([upast,ypast])[None,:]).double()\n",
    "        narx_input=narx_input.to(device)\n",
    "        ynow = model.forward(narx_input).cpu().detach().item()\n",
    "        \n",
    "        #update past arrays\n",
    "        upast.append(unow)\n",
    "        upast.pop(0)\n",
    "        ypast.append(ynow)\n",
    "        ypast.pop(0)\n",
    "        \n",
    "        #save result\n",
    "        ylist.append(ynow)\n",
    "        \n",
    "    NRMS=calculate_error_nrms(np.array(ylist), y_data)\n",
    "    return NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_data()\n",
    "x_train, x_val, y_train, y_val =train_test_split(x, y, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=int(5e2)\n",
    "n_hidden_nodes=50\n",
    "na_list=[*range(3,8)]\n",
    "nb_list=[*range(14,26)]\n",
    "final_losses=np.ndarray((len(na_list),len(nb_list)))\n",
    "final_best_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "simulation_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "best_sim_NRMS=float('inf')\n",
    "best_sim_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current run: (3, 14), epoch: 25, Loss: 0.14808941922532376\n",
      "current RMS: 0.7873671591910069, best RMS: 0.7873671591910069\n",
      "current run: (3, 14), epoch: 50, Loss: 0.10971691831342946\n",
      "current RMS: 0.6811039628050367, best RMS: 0.6811039628050367\n",
      "current run: (3, 14), epoch: 75, Loss: 0.09700161858902678\n",
      "current RMS: 0.6394498832032613, best RMS: 0.6394498832032613\n",
      "current run: (3, 14), epoch: 100, Loss: 0.08630370516106564\n",
      "current RMS: 0.6031168834582208, best RMS: 0.6031168834582208\n",
      "current run: (3, 14), epoch: 125, Loss: 0.07589833353983216\n",
      "current RMS: 0.5654088140162951, best RMS: 0.5654088140162951\n",
      "current run: (3, 14), epoch: 150, Loss: 0.06548253223758106\n",
      "current RMS: 0.5248865479838457, best RMS: 0.5248865479838457\n",
      "current run: (3, 14), epoch: 175, Loss: 0.055387932995752044\n",
      "current RMS: 0.4825398790305613, best RMS: 0.4825398790305613\n",
      "current run: (3, 14), epoch: 200, Loss: 0.04625260863166986\n",
      "current RMS: 0.440817515745073, best RMS: 0.440817515745073\n",
      "current run: (3, 14), epoch: 225, Loss: 0.03874724634500322\n",
      "current RMS: 0.4033908382624425, best RMS: 0.4033908382624425\n",
      "current run: (3, 14), epoch: 250, Loss: 0.03324881908341361\n",
      "current RMS: 0.373623558682571, best RMS: 0.373623558682571\n",
      "current run: (3, 14), epoch: 275, Loss: 0.02964757458197217\n",
      "current RMS: 0.3527365732042465, best RMS: 0.3527365732042465\n",
      "current run: (3, 14), epoch: 300, Loss: 0.02744787693446332\n",
      "current RMS: 0.3392840827174979, best RMS: 0.3392840827174979\n",
      "current run: (3, 14), epoch: 325, Loss: 0.026064287478105633\n",
      "current RMS: 0.33049537385945055, best RMS: 0.33049537385945055\n",
      "current run: (3, 14), epoch: 350, Loss: 0.02505775522019103\n",
      "current RMS: 0.32395195987792824, best RMS: 0.32395195987792824\n",
      "current run: (3, 14), epoch: 375, Loss: 0.024188226729332088\n",
      "current RMS: 0.3182278030762062, best RMS: 0.3182278030762062\n",
      "current run: (3, 14), epoch: 400, Loss: 0.02335353528299094\n",
      "current RMS: 0.3126761335441707, best RMS: 0.3126761335441707\n",
      "current run: (3, 14), epoch: 425, Loss: 0.022518282466978082\n",
      "current RMS: 0.3070491394702309, best RMS: 0.3070491394702309\n",
      "current run: (3, 14), epoch: 450, Loss: 0.021672191846731664\n",
      "current RMS: 0.3012572441090624, best RMS: 0.3012572441090624\n",
      "current run: (3, 14), epoch: 475, Loss: 0.02081283471567904\n",
      "current RMS: 0.29526496040868894, best RMS: 0.29526496040868894\n",
      "current run: (3, 14), epoch: 500, Loss: 0.019940034141768582\n",
      "current RMS: 0.2890544724591971, best RMS: 0.2890544724591971\n",
      "current run: (3, 14), sim NRMS: 0.6782405591471029. This is better than last sim best:inf>0.6782405591471029\n",
      "current run: (3, 15), epoch: 25, Loss: 0.1501624950447402\n",
      "current RMS: 0.7914246430786989, best RMS: 0.7914246430786989\n",
      "current run: (3, 15), epoch: 50, Loss: 0.10378212546343453\n",
      "current RMS: 0.6641126516946442, best RMS: 0.6641126516946442\n",
      "current run: (3, 15), epoch: 75, Loss: 0.08915816918575739\n",
      "current RMS: 0.6151981716496978, best RMS: 0.6151981716496978\n",
      "current run: (3, 15), epoch: 100, Loss: 0.07959738570102229\n",
      "current RMS: 0.5808946579707566, best RMS: 0.5808946579707566\n",
      "current run: (3, 15), epoch: 125, Loss: 0.07016372275755965\n",
      "current RMS: 0.5454505148107212, best RMS: 0.5454505148107212\n",
      "current run: (3, 15), epoch: 150, Loss: 0.06072389586164416\n",
      "current RMS: 0.5074285926137246, best RMS: 0.5074285926137246\n",
      "current run: (3, 15), epoch: 175, Loss: 0.051537980631387086\n",
      "current RMS: 0.4674561141732188, best RMS: 0.4674561141732188\n",
      "current run: (3, 15), epoch: 200, Loss: 0.04315916319110116\n",
      "current RMS: 0.42780288244400916, best RMS: 0.42780288244400916\n",
      "current run: (3, 15), epoch: 225, Loss: 0.03619272698181214\n",
      "current RMS: 0.3917972791200909, best RMS: 0.3917972791200909\n",
      "current run: (3, 15), epoch: 250, Loss: 0.031001680772344463\n",
      "current RMS: 0.36261278284975434, best RMS: 0.36261278284975434\n",
      "current run: (3, 15), epoch: 275, Loss: 0.027536464641836022\n",
      "current RMS: 0.34166013699324327, best RMS: 0.34166013699324327\n",
      "current run: (3, 15), epoch: 300, Loss: 0.02539881726203898\n",
      "current RMS: 0.3279591915339803, best RMS: 0.3279591915339803\n",
      "current run: (3, 15), epoch: 325, Loss: 0.024077658869217214\n",
      "current RMS: 0.3191165123834084, best RMS: 0.3191165123834084\n",
      "current run: (3, 15), epoch: 350, Loss: 0.02316044491184219\n",
      "current RMS: 0.31281326973039913, best RMS: 0.31281326973039913\n",
      "current run: (3, 15), epoch: 375, Loss: 0.022403492546474037\n",
      "current RMS: 0.307553901080616, best RMS: 0.307553901080616\n",
      "current run: (3, 15), epoch: 400, Loss: 0.02169413524462052\n",
      "current RMS: 0.30259876099230126, best RMS: 0.30259876099230126\n",
      "current run: (3, 15), epoch: 425, Loss: 0.02098939599612398\n",
      "current RMS: 0.2976385044201413, best RMS: 0.2976385044201413\n",
      "current run: (3, 15), epoch: 450, Loss: 0.02027504190952665\n",
      "current RMS: 0.292551531140095, best RMS: 0.292551531140095\n",
      "current run: (3, 15), epoch: 475, Loss: 0.019546741205832004\n",
      "current RMS: 0.2872862851400401, best RMS: 0.2872862851400401\n",
      "current run: (3, 15), epoch: 500, Loss: 0.018803213971335064\n",
      "current RMS: 0.281815637732932, best RMS: 0.281815637732932\n",
      "current run: (3, 15), sim NRMS: 0.6758086286711223. This is better than last sim best:0.6782405591471029>0.6758086286711223\n",
      "current run: (3, 16), epoch: 25, Loss: 0.19230043893375562\n",
      "current RMS: 0.8875111634258475, best RMS: 0.8875111634258475\n",
      "current run: (3, 16), epoch: 50, Loss: 0.1242970661913135\n",
      "current RMS: 0.7213313953558025, best RMS: 0.7213313953558025\n",
      "current run: (3, 16), epoch: 75, Loss: 0.09182531543079987\n",
      "current RMS: 0.6249402367270962, best RMS: 0.6249402367270962\n",
      "current run: (3, 16), epoch: 100, Loss: 0.07716236858376914\n",
      "current RMS: 0.5739035390862831, best RMS: 0.5739035390862831\n",
      "current run: (3, 16), epoch: 125, Loss: 0.06879541038728043\n",
      "current RMS: 0.541855763425246, best RMS: 0.541855763425246\n",
      "current run: (3, 16), epoch: 150, Loss: 0.062194116265316006\n",
      "current RMS: 0.5150123479922593, best RMS: 0.5150123479922593\n",
      "current run: (3, 16), epoch: 175, Loss: 0.056091826578928514\n",
      "current RMS: 0.48909308391687656, best RMS: 0.48909308391687656\n",
      "current run: (3, 16), epoch: 200, Loss: 0.050345511504681015\n",
      "current RMS: 0.46344331604858235, best RMS: 0.46344331604858235\n",
      "current run: (3, 16), epoch: 225, Loss: 0.045029377639158014\n",
      "current RMS: 0.4383771653132473, best RMS: 0.4383771653132473\n",
      "current run: (3, 16), epoch: 250, Loss: 0.04024272056917858\n",
      "current RMS: 0.41448630746237825, best RMS: 0.41448630746237825\n",
      "current run: (3, 16), epoch: 275, Loss: 0.036075703664652466\n",
      "current RMS: 0.3924763963661202, best RMS: 0.3924763963661202\n",
      "current run: (3, 16), epoch: 300, Loss: 0.03258668417356029\n",
      "current RMS: 0.3730157733074646, best RMS: 0.3730157733074646\n",
      "current run: (3, 16), epoch: 325, Loss: 0.02978385189003292\n",
      "current RMS: 0.3565728742336939, best RMS: 0.3565728742336939\n",
      "current run: (3, 16), epoch: 350, Loss: 0.027619171486910107\n",
      "current RMS: 0.3432879496521712, best RMS: 0.3432879496521712\n",
      "current run: (3, 16), epoch: 375, Loss: 0.025997768323933343\n",
      "current RMS: 0.3329416330418758, best RMS: 0.3329416330418758\n",
      "current run: (3, 16), epoch: 400, Loss: 0.024799023558750893\n",
      "current RMS: 0.32503817257845546, best RMS: 0.32503817257845546\n",
      "current run: (3, 16), epoch: 425, Loss: 0.023900739672338276\n",
      "current RMS: 0.31895865756034636, best RMS: 0.31895865756034636\n",
      "current run: (3, 16), epoch: 450, Loss: 0.023197715897482422\n",
      "current RMS: 0.3141087162551579, best RMS: 0.3141087162551579\n",
      "current run: (3, 16), epoch: 475, Loss: 0.022610498603452073\n",
      "current RMS: 0.31000813316052944, best RMS: 0.31000813316052944\n",
      "current run: (3, 16), epoch: 500, Loss: 0.022085322136303626\n",
      "current RMS: 0.3063155350747976, best RMS: 0.3063155350747976\n",
      "current run: (3, 16), sim NRMS: 0.6572437581790145. This is better than last sim best:0.6758086286711223>0.6572437581790145\n",
      "current run: (3, 17), epoch: 25, Loss: 0.12607233991620762\n",
      "current RMS: 0.7248841063037205, best RMS: 0.7248841063037205\n",
      "current run: (3, 17), epoch: 50, Loss: 0.07422224734452047\n",
      "current RMS: 0.5625347839902837, best RMS: 0.5625347839902837\n",
      "current run: (3, 17), epoch: 75, Loss: 0.061073942026188925\n",
      "current RMS: 0.5111277382887408, best RMS: 0.5111277382887408\n",
      "current run: (3, 17), epoch: 100, Loss: 0.053696494186731634\n",
      "current RMS: 0.4791063547591581, best RMS: 0.4791063547591581\n",
      "current run: (3, 17), epoch: 125, Loss: 0.04659751073243277\n",
      "current RMS: 0.4465432844885286, best RMS: 0.4465432844885286\n",
      "current run: (3, 17), epoch: 150, Loss: 0.0400453478935232\n",
      "current RMS: 0.4139567875961968, best RMS: 0.4139567875961968\n",
      "current run: (3, 17), epoch: 175, Loss: 0.03431004487140841\n",
      "current RMS: 0.3831354982695788, best RMS: 0.3831354982695788\n",
      "current run: (3, 17), epoch: 200, Loss: 0.02966742854258513\n",
      "current RMS: 0.3562246731789094, best RMS: 0.3562246731789094\n",
      "current run: (3, 17), epoch: 225, Loss: 0.02623364071054713\n",
      "current RMS: 0.3348619966186805, best RMS: 0.3348619966186805\n",
      "current run: (3, 17), epoch: 250, Loss: 0.023902727234474667\n",
      "current RMS: 0.3194631541078938, best RMS: 0.3194631541078938\n",
      "current run: (3, 17), epoch: 275, Loss: 0.02239900173779741\n",
      "current RMS: 0.30903989958615563, best RMS: 0.30903989958615563\n",
      "current run: (3, 17), epoch: 300, Loss: 0.021402874856804286\n",
      "current RMS: 0.30188985306050975, best RMS: 0.30188985306050975\n",
      "current run: (3, 17), epoch: 325, Loss: 0.020659530534124712\n",
      "current RMS: 0.2964492090650813, best RMS: 0.2964492090650813\n",
      "current run: (3, 17), epoch: 350, Loss: 0.02001516758799995\n",
      "current RMS: 0.29169860537949294, best RMS: 0.29169860537949294\n",
      "current run: (3, 17), epoch: 375, Loss: 0.019396045995564513\n",
      "current RMS: 0.2871142466966505, best RMS: 0.2871142466966505\n",
      "current run: (3, 17), epoch: 400, Loss: 0.01877300847150301\n",
      "current RMS: 0.2824660482318298, best RMS: 0.2824660482318298\n",
      "current run: (3, 17), epoch: 425, Loss: 0.018136203569777666\n",
      "current RMS: 0.27765857530394095, best RMS: 0.27765857530394095\n",
      "current run: (3, 17), epoch: 450, Loss: 0.017482675624397155\n",
      "current RMS: 0.27264865736384297, best RMS: 0.27264865736384297\n",
      "current run: (3, 17), epoch: 475, Loss: 0.01681161792863475\n",
      "current RMS: 0.26741161067046904, best RMS: 0.26741161067046904\n",
      "current run: (3, 17), epoch: 500, Loss: 0.016122888340379376\n",
      "current RMS: 0.2619291426161157, best RMS: 0.2619291426161157\n",
      "current run: (3, 17), sim NRMS: 0.679259119179492\n",
      "current run: (3, 18), epoch: 25, Loss: 0.1302275071234091\n",
      "current RMS: 0.7379536362741431, best RMS: 0.7379536362741431\n",
      "current run: (3, 18), epoch: 50, Loss: 0.0814252791725625\n",
      "current RMS: 0.5900752878286387, best RMS: 0.5900752878286387\n",
      "current run: (3, 18), epoch: 75, Loss: 0.06672983375574353\n",
      "current RMS: 0.5355707711563462, best RMS: 0.5355707711563462\n",
      "current run: (3, 18), epoch: 100, Loss: 0.05985228377020011\n",
      "current RMS: 0.5075051777296482, best RMS: 0.5075051777296482\n",
      "current run: (3, 18), epoch: 125, Loss: 0.05451083051523693\n",
      "current RMS: 0.48452474389668726, best RMS: 0.48452474389668726\n",
      "current run: (3, 18), epoch: 150, Loss: 0.049520297452273966\n",
      "current RMS: 0.46192380279508133, best RMS: 0.46192380279508133\n",
      "current run: (3, 18), epoch: 175, Loss: 0.044781612093028805\n",
      "current RMS: 0.43932073818401457, best RMS: 0.43932073818401457\n",
      "current run: (3, 18), epoch: 200, Loss: 0.040374656239326845\n",
      "current RMS: 0.4171525711347407, best RMS: 0.4171525711347407\n",
      "current run: (3, 18), epoch: 225, Loss: 0.036396823847557894\n",
      "current RMS: 0.3960343182444674, best RMS: 0.3960343182444674\n",
      "current run: (3, 18), epoch: 250, Loss: 0.03293174922553514\n",
      "current RMS: 0.3766315704610048, best RMS: 0.3766315704610048\n",
      "current run: (3, 18), epoch: 275, Loss: 0.030030594254484358\n",
      "current RMS: 0.3595353434914041, best RMS: 0.3595353434914041\n",
      "current run: (3, 18), epoch: 300, Loss: 0.02769835228122285\n",
      "current RMS: 0.3451265016966155, best RMS: 0.3451265016966155\n",
      "current run: (3, 18), epoch: 325, Loss: 0.02589094222494459\n",
      "current RMS: 0.3334780656879734, best RMS: 0.3334780656879734\n",
      "current run: (3, 18), epoch: 350, Loss: 0.024525064332755964\n",
      "current RMS: 0.3243471958796362, best RMS: 0.3243471958796362\n",
      "current run: (3, 18), epoch: 375, Loss: 0.023497250369684402\n",
      "current RMS: 0.3172647923727195, best RMS: 0.3172647923727195\n",
      "current run: (3, 18), epoch: 400, Loss: 0.022704715047016454\n",
      "current RMS: 0.311675834852049, best RMS: 0.311675834852049\n",
      "current run: (3, 18), epoch: 425, Loss: 0.02206078518545056\n",
      "current RMS: 0.30706533686389326, best RMS: 0.30706533686389326\n",
      "current run: (3, 18), epoch: 450, Loss: 0.02150154968629559\n",
      "current RMS: 0.30302874920092765, best RMS: 0.30302874920092765\n",
      "current run: (3, 18), epoch: 475, Loss: 0.02098493039981739\n",
      "current RMS: 0.2992854584058562, best RMS: 0.2992854584058562\n",
      "current run: (3, 18), epoch: 500, Loss: 0.020485737366375833\n",
      "current RMS: 0.2956579292668424, best RMS: 0.2956579292668424\n",
      "current run: (3, 18), sim NRMS: 0.6698784268692916\n",
      "current run: (3, 19), epoch: 25, Loss: 0.12295028291915756\n",
      "current RMS: 0.7191909834772341, best RMS: 0.7191909834772341\n",
      "current run: (3, 19), epoch: 50, Loss: 0.07616688094050272\n",
      "current RMS: 0.5737307279334113, best RMS: 0.5737307279334113\n",
      "current run: (3, 19), epoch: 75, Loss: 0.06471306570785187\n",
      "current RMS: 0.5296032933819927, best RMS: 0.5296032933819927\n",
      "current run: (3, 19), epoch: 100, Loss: 0.0595394525887947\n",
      "current RMS: 0.507849110607043, best RMS: 0.507849110607043\n",
      "current run: (3, 19), epoch: 125, Loss: 0.054810400989573155\n",
      "current RMS: 0.48730448912720614, best RMS: 0.48730448912720614\n",
      "current run: (3, 19), epoch: 150, Loss: 0.05009198821376284\n",
      "current RMS: 0.46587695026308235, best RMS: 0.46587695026308235\n",
      "current run: (3, 19), epoch: 175, Loss: 0.045421025724559326\n",
      "current RMS: 0.4436025930557894, best RMS: 0.4436025930557894\n",
      "current run: (3, 19), epoch: 200, Loss: 0.040874951861230344\n",
      "current RMS: 0.42076999420490724, best RMS: 0.42076999420490724\n",
      "current run: (3, 19), epoch: 225, Loss: 0.036579573705716475\n",
      "current RMS: 0.3979802127556807, best RMS: 0.3979802127556807\n",
      "current run: (3, 19), epoch: 250, Loss: 0.03268936020431805\n",
      "current RMS: 0.3761233508009328, best RMS: 0.3761233508009328\n",
      "current run: (3, 19), epoch: 275, Loss: 0.02934860040901282\n",
      "current RMS: 0.35624073991110183, best RMS: 0.35624073991110183\n",
      "current run: (3, 19), epoch: 300, Loss: 0.026644919077228567\n",
      "current RMS: 0.33923633844006285, best RMS: 0.33923633844006285\n",
      "current run: (3, 19), epoch: 325, Loss: 0.02457809438268789\n",
      "current RMS: 0.32556499320710386, best RMS: 0.32556499320710386\n",
      "current run: (3, 19), epoch: 350, Loss: 0.023062704635584907\n",
      "current RMS: 0.31509140105533073, best RMS: 0.31509140105533073\n",
      "current run: (3, 19), epoch: 375, Loss: 0.021962341468284675\n",
      "current RMS: 0.3072086140584506, best RMS: 0.3072086140584506\n",
      "current run: (3, 19), epoch: 400, Loss: 0.021134177620099594\n",
      "current RMS: 0.3011205746642798, best RMS: 0.3011205746642798\n",
      "current run: (3, 19), epoch: 425, Loss: 0.020461358670819784\n",
      "current RMS: 0.29610143703233566, best RMS: 0.29610143703233566\n",
      "current run: (3, 19), epoch: 450, Loss: 0.019864399195930964\n",
      "current RMS: 0.2916209862963722, best RMS: 0.2916209862963722\n",
      "current run: (3, 19), epoch: 475, Loss: 0.019296724160694445\n",
      "current RMS: 0.28734758892321627, best RMS: 0.28734758892321627\n",
      "current run: (3, 19), epoch: 500, Loss: 0.018734178668665093\n",
      "current RMS: 0.283094528241403, best RMS: 0.283094528241403\n",
      "current run: (3, 19), sim NRMS: 0.6740971129605327\n",
      "current run: (3, 20), epoch: 25, Loss: 0.11804611757226913\n",
      "current RMS: 0.7071042289899879, best RMS: 0.7071042289899879\n",
      "current run: (3, 20), epoch: 50, Loss: 0.07352685669521686\n",
      "current RMS: 0.56386693468025, best RMS: 0.56386693468025\n",
      "current run: (3, 20), epoch: 75, Loss: 0.06130885388567043\n",
      "current RMS: 0.5167478321210148, best RMS: 0.5167478321210148\n",
      "current run: (3, 20), epoch: 100, Loss: 0.05581230768180615\n",
      "current RMS: 0.49261842260008953, best RMS: 0.49261842260008953\n",
      "current run: (3, 20), epoch: 125, Loss: 0.051377734949471995\n",
      "current RMS: 0.4726459161277133, best RMS: 0.4726459161277133\n",
      "current run: (3, 20), epoch: 150, Loss: 0.04724475730290832\n",
      "current RMS: 0.4532068718943863, best RMS: 0.4532068718943863\n",
      "current run: (3, 20), epoch: 175, Loss: 0.043269980380659635\n",
      "current RMS: 0.4336317797010167, best RMS: 0.4336317797010167\n",
      "current run: (3, 20), epoch: 200, Loss: 0.03943136088925059\n",
      "current RMS: 0.41385174075964654, best RMS: 0.41385174075964654\n",
      "current run: (3, 20), epoch: 225, Loss: 0.03577665839457873\n",
      "current RMS: 0.39410309063711846, best RMS: 0.39410309063711846\n",
      "current run: (3, 20), epoch: 250, Loss: 0.032388062993166995\n",
      "current RMS: 0.3748582594990364, best RMS: 0.3748582594990364\n",
      "current run: (3, 20), epoch: 275, Loss: 0.02935603421460376\n",
      "current RMS: 0.3567380374910288, best RMS: 0.3567380374910288\n",
      "current run: (3, 20), epoch: 300, Loss: 0.026754649146985807\n",
      "current RMS: 0.340389741845789, best RMS: 0.340389741845789\n",
      "current run: (3, 20), epoch: 325, Loss: 0.024619274003955558\n",
      "current RMS: 0.3263152852913189, best RMS: 0.3263152852913189\n",
      "current run: (3, 20), epoch: 350, Loss: 0.022934747810321322\n",
      "current RMS: 0.3147205054617676, best RMS: 0.3147205054617676\n",
      "current run: (3, 20), epoch: 375, Loss: 0.02163947635253587\n",
      "current RMS: 0.3054614723271923, best RMS: 0.3054614723271923\n",
      "current run: (3, 20), epoch: 400, Loss: 0.02064348784515932\n",
      "current RMS: 0.2981167251569052, best RMS: 0.2981167251569052\n",
      "current run: (3, 20), epoch: 425, Loss: 0.0198519272565315\n",
      "current RMS: 0.2921422837618211, best RMS: 0.2921422837618211\n",
      "current run: (3, 20), epoch: 450, Loss: 0.019183902001094853\n",
      "current RMS: 0.28702370514521985, best RMS: 0.28702370514521985\n",
      "current run: (3, 20), epoch: 475, Loss: 0.018581019997377532\n",
      "current RMS: 0.28236282863645323, best RMS: 0.28236282863645323\n",
      "current run: (3, 20), epoch: 500, Loss: 0.018006533023100662\n",
      "current RMS: 0.2778927487900062, best RMS: 0.2778927487900062\n",
      "current run: (3, 20), sim NRMS: 0.6662620220577685\n",
      "current run: (3, 21), epoch: 25, Loss: 0.07679148790018563\n",
      "current RMS: 0.5728892127329958, best RMS: 0.5728892127329958\n",
      "current run: (3, 21), epoch: 50, Loss: 0.05735299039849307\n",
      "current RMS: 0.49869177987976454, best RMS: 0.49869177987976454\n",
      "current run: (3, 21), epoch: 75, Loss: 0.05224917290512989\n",
      "current RMS: 0.47601042594058207, best RMS: 0.47601042594058207\n",
      "current run: (3, 21), epoch: 100, Loss: 0.04770358899488438\n",
      "current RMS: 0.4548521131694243, best RMS: 0.4548521131694243\n",
      "current run: (3, 21), epoch: 125, Loss: 0.04317022472902138\n",
      "current RMS: 0.4325004889388103, best RMS: 0.4325004889388103\n",
      "current run: (3, 21), epoch: 150, Loss: 0.03872837743042341\n",
      "current RMS: 0.4093481091179031, best RMS: 0.4093481091179031\n",
      "current run: (3, 21), epoch: 175, Loss: 0.03451759077757133\n",
      "current RMS: 0.38613823384677587, best RMS: 0.38613823384677587\n",
      "current run: (3, 21), epoch: 200, Loss: 0.030707369024027698\n",
      "current RMS: 0.3638619055914869, best RMS: 0.3638619055914869\n",
      "current run: (3, 21), epoch: 225, Loss: 0.027459832641119265\n",
      "current RMS: 0.34371796706211655, best RMS: 0.34371796706211655\n",
      "current run: (3, 21), epoch: 250, Loss: 0.024872453487278085\n",
      "current RMS: 0.3267480246504131, best RMS: 0.3267480246504131\n",
      "current run: (3, 21), epoch: 275, Loss: 0.022933371260037284\n",
      "current RMS: 0.31338282592428457, best RMS: 0.31338282592428457\n",
      "current run: (3, 21), epoch: 300, Loss: 0.021524774051960252\n",
      "current RMS: 0.3032682458769097, best RMS: 0.3032682458769097\n",
      "current run: (3, 21), epoch: 325, Loss: 0.02047602973365886\n",
      "current RMS: 0.29550841663351446, best RMS: 0.29550841663351446\n",
      "current run: (3, 21), epoch: 350, Loss: 0.01962831225839675\n",
      "current RMS: 0.2891214158214495, best RMS: 0.2891214158214495\n",
      "current run: (3, 21), epoch: 375, Loss: 0.01887078948344332\n",
      "current RMS: 0.28335685126005866, best RMS: 0.28335685126005866\n",
      "current run: (3, 21), epoch: 400, Loss: 0.018141559617389173\n",
      "current RMS: 0.27776046421514144, best RMS: 0.27776046421514144\n",
      "current run: (3, 21), epoch: 425, Loss: 0.01741158768393715\n",
      "current RMS: 0.27209442503106834, best RMS: 0.27209442503106834\n",
      "current run: (3, 21), epoch: 450, Loss: 0.016668918205582632\n",
      "current RMS: 0.2662403094125185, best RMS: 0.2662403094125185\n",
      "current run: (3, 21), epoch: 475, Loss: 0.01590909187636953\n",
      "current RMS: 0.26013539709038175, best RMS: 0.26013539709038175\n",
      "current run: (3, 21), epoch: 500, Loss: 0.015130715132121586\n",
      "current RMS: 0.2537410527911856, best RMS: 0.2537410527911856\n",
      "current run: (3, 21), sim NRMS: 0.6648674748911246\n",
      "current run: (3, 22), epoch: 25, Loss: 0.14166138810624904\n",
      "current RMS: 0.770508049056677, best RMS: 0.770508049056677\n",
      "current run: (3, 22), epoch: 50, Loss: 0.07801543972012498\n",
      "current RMS: 0.5811611234249525, best RMS: 0.5811611234249525\n",
      "current run: (3, 22), epoch: 75, Loss: 0.06261514758217909\n",
      "current RMS: 0.5221796858259724, best RMS: 0.5221796858259724\n",
      "current run: (3, 22), epoch: 100, Loss: 0.05768075305960568\n",
      "current RMS: 0.5009123503343728, best RMS: 0.5009123503343728\n",
      "current run: (3, 22), epoch: 125, Loss: 0.054376156578720906\n",
      "current RMS: 0.4861329463144424, best RMS: 0.4861329463144424\n",
      "current run: (3, 22), epoch: 150, Loss: 0.05120743584627855\n",
      "current RMS: 0.47159227565148487, best RMS: 0.47159227565148487\n",
      "current run: (3, 22), epoch: 175, Loss: 0.04801335868020978\n",
      "current RMS: 0.4564940045895534, best RMS: 0.4564940045895534\n",
      "current run: (3, 22), epoch: 200, Loss: 0.044798240469988745\n",
      "current RMS: 0.44077315979037984, best RMS: 0.44077315979037984\n",
      "current run: (3, 22), epoch: 225, Loss: 0.041592902592416374\n",
      "current RMS: 0.424532271914154, best RMS: 0.424532271914154\n",
      "current run: (3, 22), epoch: 250, Loss: 0.038437516445262096\n",
      "current RMS: 0.4079286302979834, best RMS: 0.4079286302979834\n",
      "current run: (3, 22), epoch: 275, Loss: 0.03538250289517742\n",
      "current RMS: 0.3911927253849645, best RMS: 0.3911927253849645\n",
      "current run: (3, 22), epoch: 300, Loss: 0.032487477319191174\n",
      "current RMS: 0.3746506999516292, best RMS: 0.3746506999516292\n",
      "current run: (3, 22), epoch: 325, Loss: 0.029815976656650076\n",
      "current RMS: 0.35871045224082065, best RMS: 0.35871045224082065\n",
      "current run: (3, 22), epoch: 350, Loss: 0.02742608487798801\n",
      "current RMS: 0.34381784810863025, best RMS: 0.34381784810863025\n",
      "current run: (3, 22), epoch: 375, Loss: 0.02535897070283807\n",
      "current RMS: 0.3303808442064974, best RMS: 0.3303808442064974\n",
      "current run: (3, 22), epoch: 400, Loss: 0.023629168814845117\n",
      "current RMS: 0.3186804607902545, best RMS: 0.3186804607902545\n",
      "current run: (3, 22), epoch: 425, Loss: 0.022220768319721293\n",
      "current RMS: 0.30880385951009803, best RMS: 0.30880385951009803\n",
      "current run: (3, 22), epoch: 450, Loss: 0.021091548776997083\n",
      "current RMS: 0.300631760551297, best RMS: 0.300631760551297\n",
      "current run: (3, 22), epoch: 475, Loss: 0.020183461140573827\n",
      "current RMS: 0.2938863506376416, best RMS: 0.2938863506376416\n",
      "current run: (3, 22), epoch: 500, Loss: 0.019435120619662082\n",
      "current RMS: 0.2882145638478917, best RMS: 0.2882145638478917\n",
      "current run: (3, 22), sim NRMS: 0.6274221633880565. This is better than last sim best:0.6572437581790145>0.6274221633880565\n",
      "current run: (3, 23), epoch: 25, Loss: 0.11761846327056377\n",
      "current RMS: 0.7048370675629431, best RMS: 0.7048370675629431\n",
      "current run: (3, 23), epoch: 50, Loss: 0.07149342966313274\n",
      "current RMS: 0.5563668953570634, best RMS: 0.5563668953570634\n",
      "current run: (3, 23), epoch: 75, Loss: 0.061514969032156384\n",
      "current RMS: 0.5166408540898692, best RMS: 0.5166408540898692\n",
      "current run: (3, 23), epoch: 100, Loss: 0.05733465016191616\n",
      "current RMS: 0.49867558074051055, best RMS: 0.49867558074051055\n",
      "current run: (3, 23), epoch: 125, Loss: 0.053600232836988344\n",
      "current RMS: 0.4821064204136588, best RMS: 0.4821064204136588\n",
      "current run: (3, 23), epoch: 150, Loss: 0.0498889184029111\n",
      "current RMS: 0.4651180766461468, best RMS: 0.4651180766461468\n",
      "current run: (3, 23), epoch: 175, Loss: 0.04617786142098267\n",
      "current RMS: 0.44739434611913265, best RMS: 0.44739434611913265\n",
      "current run: (3, 23), epoch: 200, Loss: 0.04249851680646668\n",
      "current RMS: 0.42908733012094863, best RMS: 0.42908733012094863\n",
      "current run: (3, 23), epoch: 225, Loss: 0.03889857229464127\n",
      "current RMS: 0.410390244911224, best RMS: 0.410390244911224\n",
      "current run: (3, 23), epoch: 250, Loss: 0.03543848231790525\n",
      "current RMS: 0.39157527320056357, best RMS: 0.39157527320056357\n",
      "current run: (3, 23), epoch: 275, Loss: 0.0321891961464677\n",
      "current RMS: 0.37303888897422693, best RMS: 0.37303888897422693\n",
      "current run: (3, 23), epoch: 300, Loss: 0.02922371504483911\n",
      "current RMS: 0.3552727638222091, best RMS: 0.3552727638222091\n",
      "current run: (3, 23), epoch: 325, Loss: 0.026604273818659513\n",
      "current RMS: 0.33879734505560705, best RMS: 0.33879734505560705\n",
      "current run: (3, 23), epoch: 350, Loss: 0.02436946197262438\n",
      "current RMS: 0.3240671269256056, best RMS: 0.3240671269256056\n",
      "current run: (3, 23), epoch: 375, Loss: 0.02252584545949642\n",
      "current RMS: 0.31137426743325836, best RMS: 0.31137426743325836\n",
      "current run: (3, 23), epoch: 400, Loss: 0.0210470121274795\n",
      "current RMS: 0.30078667890353716, best RMS: 0.30078667890353716\n",
      "current run: (3, 23), epoch: 425, Loss: 0.019880340797393464\n",
      "current RMS: 0.29214639919869734, best RMS: 0.29214639919869734\n",
      "current run: (3, 23), epoch: 450, Loss: 0.018958971752989783\n",
      "current RMS: 0.28512874526791143, best RMS: 0.28512874526791143\n",
      "current run: (3, 23), epoch: 475, Loss: 0.018214702004140312\n",
      "current RMS: 0.2793343339743525, best RMS: 0.2793343339743525\n",
      "current run: (3, 23), epoch: 500, Loss: 0.017587872639790735\n",
      "current RMS: 0.27437543722732055, best RMS: 0.27437543722732055\n",
      "current run: (3, 23), sim NRMS: 0.6010642884130336. This is better than last sim best:0.6274221633880565>0.6010642884130336\n",
      "current run: (3, 24), epoch: 25, Loss: 0.12197576863575318\n",
      "current RMS: 0.7140635589383462, best RMS: 0.7140635589383462\n",
      "current run: (3, 24), epoch: 50, Loss: 0.06625536193844987\n",
      "current RMS: 0.5353915764300786, best RMS: 0.5353915764300786\n",
      "current run: (3, 24), epoch: 75, Loss: 0.05617701346356707\n",
      "current RMS: 0.49364416035892916, best RMS: 0.49364416035892916\n",
      "current run: (3, 24), epoch: 100, Loss: 0.05144500659170523\n",
      "current RMS: 0.47282739495091847, best RMS: 0.47282739495091847\n",
      "current run: (3, 24), epoch: 125, Loss: 0.0466535098423226\n",
      "current RMS: 0.45021675979171205, best RMS: 0.45021675979171205\n",
      "current run: (3, 24), epoch: 150, Loss: 0.041572463805861166\n",
      "current RMS: 0.4248736930276627, best RMS: 0.4248736930276627\n",
      "current run: (3, 24), epoch: 175, Loss: 0.036277443345366485\n",
      "current RMS: 0.39672455494036496, best RMS: 0.39672455494036496\n",
      "current run: (3, 24), epoch: 200, Loss: 0.031061792474252604\n",
      "current RMS: 0.36691431497053123, best RMS: 0.36691431497053123\n",
      "current run: (3, 24), epoch: 225, Loss: 0.02637242901976044\n",
      "current RMS: 0.3378749010090699, best RMS: 0.3378749010090699\n",
      "current run: (3, 24), epoch: 250, Loss: 0.022624855705618764\n",
      "current RMS: 0.31271908682499694, best RMS: 0.31271908682499694\n",
      "current run: (3, 24), epoch: 275, Loss: 0.019987822742173336\n",
      "current RMS: 0.29367167127624777, best RMS: 0.29367167127624777\n",
      "current run: (3, 24), epoch: 300, Loss: 0.018305112291619827\n",
      "current RMS: 0.2807593623990299, best RMS: 0.2807593623990299\n",
      "current run: (3, 24), epoch: 325, Loss: 0.017232228886752052\n",
      "current RMS: 0.2721552926104085, best RMS: 0.2721552926104085\n",
      "current run: (3, 24), epoch: 350, Loss: 0.016450714563979497\n",
      "current RMS: 0.26573662146431515, best RMS: 0.26573662146431515\n",
      "current run: (3, 24), epoch: 375, Loss: 0.015772345776171492\n",
      "current RMS: 0.2601131150794725, best RMS: 0.2601131150794725\n",
      "current run: (3, 24), epoch: 400, Loss: 0.015117359728346106\n",
      "current RMS: 0.2546383168880055, best RMS: 0.2546383168880055\n",
      "current run: (3, 24), epoch: 425, Loss: 0.014459541077498026\n",
      "current RMS: 0.2490639768517165, best RMS: 0.2490639768517165\n",
      "current run: (3, 24), epoch: 450, Loss: 0.013791679903223554\n",
      "current RMS: 0.24329599294166068, best RMS: 0.24329599294166068\n",
      "current run: (3, 24), epoch: 475, Loss: 0.013112030370938426\n",
      "current RMS: 0.23729119975965077, best RMS: 0.23729119975965077\n",
      "current run: (3, 24), epoch: 500, Loss: 0.012420385233522535\n",
      "current RMS: 0.23102309795893683, best RMS: 0.23102309795893683\n",
      "current run: (3, 24), sim NRMS: 0.5607209570211669. This is better than last sim best:0.6010642884130336>0.5607209570211669\n",
      "current run: (3, 25), epoch: 25, Loss: 0.08909542667913245\n",
      "current RMS: 0.6191821216488264, best RMS: 0.6191821216488264\n",
      "current run: (3, 25), epoch: 50, Loss: 0.06306252191161606\n",
      "current RMS: 0.5250383241992652, best RMS: 0.5250383241992652\n",
      "current run: (3, 25), epoch: 75, Loss: 0.05732006100390846\n",
      "current RMS: 0.5000434726671539, best RMS: 0.5000434726671539\n",
      "current run: (3, 25), epoch: 100, Loss: 0.052338125695796905\n",
      "current RMS: 0.4780302448586238, best RMS: 0.4780302448586238\n",
      "current run: (3, 25), epoch: 125, Loss: 0.04718540095889956\n",
      "current RMS: 0.4537960773724076, best RMS: 0.4537960773724076\n",
      "current run: (3, 25), epoch: 150, Loss: 0.04182119121820166\n",
      "current RMS: 0.42705891248869754, best RMS: 0.42705891248869754\n",
      "current run: (3, 25), epoch: 175, Loss: 0.036326360052839346\n",
      "current RMS: 0.39787347393585576, best RMS: 0.39787347393585576\n",
      "current run: (3, 25), epoch: 200, Loss: 0.03092160381587791\n",
      "current RMS: 0.3669600925311133, best RMS: 0.3669600925311133\n",
      "current run: (3, 25), epoch: 225, Loss: 0.02597468081571164\n",
      "current RMS: 0.3362199695706713, best RMS: 0.3362199695706713\n",
      "current run: (3, 25), epoch: 250, Loss: 0.021892665228508662\n",
      "current RMS: 0.30856270144757175, best RMS: 0.30856270144757175\n",
      "current run: (3, 25), epoch: 275, Loss: 0.018918657759346685\n",
      "current RMS: 0.286691877133381, best RMS: 0.286691877133381\n",
      "current run: (3, 25), epoch: 300, Loss: 0.016993836780197107\n",
      "current RMS: 0.27150950929723117, best RMS: 0.27150950929723117\n",
      "current run: (3, 25), epoch: 325, Loss: 0.015820538967793292\n",
      "current RMS: 0.2617353323391919, best RMS: 0.2617353323391919\n",
      "current run: (3, 25), epoch: 350, Loss: 0.015058381692406905\n",
      "current RMS: 0.25515550016725846, best RMS: 0.25515550016725846\n",
      "current run: (3, 25), epoch: 375, Loss: 0.014468902356429279\n",
      "current RMS: 0.2499897073322001, best RMS: 0.2499897073322001\n",
      "current run: (3, 25), epoch: 400, Loss: 0.013933541734845793\n",
      "current RMS: 0.24527516112501438, best RMS: 0.24527516112501438\n",
      "current run: (3, 25), epoch: 425, Loss: 0.013407110749730427\n",
      "current RMS: 0.24060648154348926, best RMS: 0.24060648154348926\n",
      "current run: (3, 25), epoch: 450, Loss: 0.012875564978730242\n",
      "current RMS: 0.23583222019449498, best RMS: 0.23583222019449498\n",
      "current run: (3, 25), epoch: 475, Loss: 0.012335182633523017\n",
      "current RMS: 0.23089341462517776, best RMS: 0.23089341462517776\n",
      "current run: (3, 25), epoch: 500, Loss: 0.011785179481953335\n",
      "current RMS: 0.2257617223396775, best RMS: 0.2257617223396775\n",
      "current run: (3, 25), sim NRMS: 0.5251546463864887. This is better than last sim best:0.5607209570211669>0.5251546463864887\n",
      "current run: (4, 14), epoch: 25, Loss: 0.13047960848704998\n",
      "current RMS: 0.7403057484644687, best RMS: 0.7403057484644687\n",
      "current run: (4, 14), epoch: 50, Loss: 0.10276737247457861\n",
      "current RMS: 0.6575761979435776, best RMS: 0.6575761979435776\n",
      "current run: (4, 14), epoch: 75, Loss: 0.08760852745223133\n",
      "current RMS: 0.6072568107248137, best RMS: 0.6072568107248137\n",
      "current run: (4, 14), epoch: 100, Loss: 0.07258251245422141\n",
      "current RMS: 0.5521385318988907, best RMS: 0.5521385318988907\n",
      "current run: (4, 14), epoch: 125, Loss: 0.05832850309380889\n",
      "current RMS: 0.4943642274024358, best RMS: 0.4943642274024358\n",
      "current run: (4, 14), epoch: 150, Loss: 0.04679374575899248\n",
      "current RMS: 0.4424325444580195, best RMS: 0.4424325444580195\n",
      "current run: (4, 14), epoch: 175, Loss: 0.039103216180045024\n",
      "current RMS: 0.40424409276871937, best RMS: 0.40424409276871937\n",
      "current run: (4, 14), epoch: 200, Loss: 0.034130160277070894\n",
      "current RMS: 0.37748335193792665, best RMS: 0.37748335193792665\n",
      "current run: (4, 14), epoch: 225, Loss: 0.030183232410263158\n",
      "current RMS: 0.35486033672694967, best RMS: 0.35486033672694967\n",
      "current run: (4, 14), epoch: 250, Loss: 0.02648228473017324\n",
      "current RMS: 0.33237306948594225, best RMS: 0.33237306948594225\n",
      "current run: (4, 14), epoch: 275, Loss: 0.022858971023214852\n",
      "current RMS: 0.3088551208937416, best RMS: 0.3088551208937416\n",
      "current run: (4, 14), epoch: 300, Loss: 0.01932029847960086\n",
      "current RMS: 0.2840508336506054, best RMS: 0.2840508336506054\n",
      "current run: (4, 14), epoch: 325, Loss: 0.015918770619064684\n",
      "current RMS: 0.2579977608463597, best RMS: 0.2579977608463597\n",
      "current run: (4, 14), epoch: 350, Loss: 0.012728624611752594\n",
      "current RMS: 0.23094300772653537, best RMS: 0.23094300772653537\n",
      "current run: (4, 14), epoch: 375, Loss: 0.009834122018276126\n",
      "current RMS: 0.20334911926019136, best RMS: 0.20334911926019136\n",
      "current run: (4, 14), epoch: 400, Loss: 0.007314539534897251\n",
      "current RMS: 0.17589179825913845, best RMS: 0.17589179825913845\n",
      "current run: (4, 14), epoch: 425, Loss: 0.005226840993333054\n",
      "current RMS: 0.14942037543353434, best RMS: 0.14942037543353434\n",
      "current run: (4, 14), epoch: 450, Loss: 0.0035912737697697174\n",
      "current RMS: 0.12487145875837341, best RMS: 0.12487145875837341\n",
      "current run: (4, 14), epoch: 475, Loss: 0.002385840455100592\n",
      "current RMS: 0.1031445111503165, best RMS: 0.1031445111503165\n",
      "current run: (4, 14), epoch: 500, Loss: 0.0015524311425739255\n",
      "current RMS: 0.08496014701452619, best RMS: 0.08496014701452619\n",
      "current run: (4, 14), sim NRMS: 0.5070604740599356. This is better than last sim best:0.5251546463864887>0.5070604740599356\n",
      "current run: (4, 15), epoch: 25, Loss: 0.14903874423942975\n",
      "current RMS: 0.7842805718965471, best RMS: 0.7842805718965471\n",
      "current run: (4, 15), epoch: 50, Loss: 0.08865585412902166\n",
      "current RMS: 0.6115190801782135, best RMS: 0.6115190801782135\n",
      "current run: (4, 15), epoch: 75, Loss: 0.07011657905842618\n",
      "current RMS: 0.544333039097405, best RMS: 0.544333039097405\n",
      "current run: (4, 15), epoch: 100, Loss: 0.05872131726107386\n",
      "current RMS: 0.4976493296302689, best RMS: 0.4976493296302689\n",
      "current run: (4, 15), epoch: 125, Loss: 0.04891208533656583\n",
      "current RMS: 0.4543664520406027, best RMS: 0.4543664520406027\n",
      "current run: (4, 15), epoch: 150, Loss: 0.04146851381744869\n",
      "current RMS: 0.41827157907633117, best RMS: 0.41827157907633117\n",
      "current run: (4, 15), epoch: 175, Loss: 0.0363551551144304\n",
      "current RMS: 0.3915030236703801, best RMS: 0.3915030236703801\n",
      "current run: (4, 15), epoch: 200, Loss: 0.03279005004264329\n",
      "current RMS: 0.37169061482710525, best RMS: 0.37169061482710525\n",
      "current run: (4, 15), epoch: 225, Loss: 0.029922007296652054\n",
      "current RMS: 0.35497785181384645, best RMS: 0.35497785181384645\n",
      "current run: (4, 15), epoch: 250, Loss: 0.027267742146760147\n",
      "current RMS: 0.3388560804745865, best RMS: 0.3388560804745865\n",
      "current run: (4, 15), epoch: 275, Loss: 0.024654810274314928\n",
      "current RMS: 0.32226850761905984, best RMS: 0.32226850761905984\n",
      "current run: (4, 15), epoch: 300, Loss: 0.022047708714883773\n",
      "current RMS: 0.3048615918006333, best RMS: 0.3048615918006333\n",
      "current run: (4, 15), epoch: 325, Loss: 0.01945475447722415\n",
      "current RMS: 0.28652437047441615, best RMS: 0.28652437047441615\n",
      "current run: (4, 15), epoch: 350, Loss: 0.016900049768734906\n",
      "current RMS: 0.2672459514473999, best RMS: 0.2672459514473999\n",
      "current run: (4, 15), epoch: 375, Loss: 0.014417237580726334\n",
      "current RMS: 0.24708945605061902, best RMS: 0.24708945605061902\n",
      "current run: (4, 15), epoch: 400, Loss: 0.012047259612587907\n",
      "current RMS: 0.22619863853782288, best RMS: 0.22619863853782288\n",
      "current run: (4, 15), epoch: 425, Loss: 0.009835494872390788\n",
      "current RMS: 0.20481065427287407, best RMS: 0.20481065427287407\n",
      "current run: (4, 15), epoch: 450, Loss: 0.007827223926326413\n",
      "current RMS: 0.18326374168178558, best RMS: 0.18326374168178558\n",
      "current run: (4, 15), epoch: 475, Loss: 0.006061610628287409\n",
      "current RMS: 0.16199213806507592, best RMS: 0.16199213806507592\n",
      "current run: (4, 15), epoch: 500, Loss: 0.0045653520546671935\n",
      "current RMS: 0.14150330024328364, best RMS: 0.14150330024328364\n",
      "current run: (4, 15), sim NRMS: 0.569047264604625\n",
      "current run: (4, 16), epoch: 25, Loss: 0.11454928374627027\n",
      "current RMS: 0.6938987454268729, best RMS: 0.6938987454268729\n",
      "current run: (4, 16), epoch: 50, Loss: 0.08153541872885467\n",
      "current RMS: 0.589026253052935, best RMS: 0.589026253052935\n",
      "current run: (4, 16), epoch: 75, Loss: 0.07151315961302253\n",
      "current RMS: 0.5512928707643987, best RMS: 0.5512928707643987\n",
      "current run: (4, 16), epoch: 100, Loss: 0.06281394018282337\n",
      "current RMS: 0.5169621449931088, best RMS: 0.5169621449931088\n",
      "current run: (4, 16), epoch: 125, Loss: 0.055051697279087396\n",
      "current RMS: 0.4838374310969491, best RMS: 0.4838374310969491\n",
      "current run: (4, 16), epoch: 150, Loss: 0.0482950956172877\n",
      "current RMS: 0.4529859708207029, best RMS: 0.4529859708207029\n",
      "current run: (4, 16), epoch: 175, Loss: 0.042706920577036594\n",
      "current RMS: 0.4258465101805878, best RMS: 0.4258465101805878\n",
      "current run: (4, 16), epoch: 200, Loss: 0.03833008730764529\n",
      "current RMS: 0.40330514261571115, best RMS: 0.40330514261571115\n",
      "current run: (4, 16), epoch: 225, Loss: 0.03500162951338372\n",
      "current RMS: 0.38526113179789584, best RMS: 0.38526113179789584\n",
      "current run: (4, 16), epoch: 250, Loss: 0.03240758696305001\n",
      "current RMS: 0.37058272547660903, best RMS: 0.37058272547660903\n",
      "current run: (4, 16), epoch: 275, Loss: 0.030226666595202612\n",
      "current RMS: 0.35780315529472034, best RMS: 0.35780315529472034\n",
      "current run: (4, 16), epoch: 300, Loss: 0.02823148181290801\n",
      "current RMS: 0.34575351466134935, best RMS: 0.34575351466134935\n",
      "current run: (4, 16), epoch: 325, Loss: 0.026299885055397994\n",
      "current RMS: 0.3337336780115786, best RMS: 0.3337336780115786\n",
      "current run: (4, 16), epoch: 350, Loss: 0.02438072502125009\n",
      "current RMS: 0.3213949509751043, best RMS: 0.3213949509751043\n",
      "current run: (4, 16), epoch: 375, Loss: 0.022459288682007666\n",
      "current RMS: 0.3085811209586122, best RMS: 0.3085811209586122\n",
      "current run: (4, 16), epoch: 400, Loss: 0.020537034586743774\n",
      "current RMS: 0.295226872418371, best RMS: 0.295226872418371\n",
      "current run: (4, 16), epoch: 425, Loss: 0.018622737368744594\n",
      "current RMS: 0.28131159090156643, best RMS: 0.28131159090156643\n",
      "current run: (4, 16), epoch: 450, Loss: 0.01672930363918955\n",
      "current RMS: 0.26684358572802763, best RMS: 0.26684358572802763\n",
      "current run: (4, 16), epoch: 475, Loss: 0.014872653225378216\n",
      "current RMS: 0.25185712944973143, best RMS: 0.25185712944973143\n",
      "current run: (4, 16), epoch: 500, Loss: 0.01307107275767932\n",
      "current RMS: 0.23641394431561702, best RMS: 0.23641394431561702\n",
      "current run: (4, 16), sim NRMS: 0.6176602177846839\n",
      "current run: (4, 17), epoch: 25, Loss: 0.14391992210613067\n",
      "current RMS: 0.7716420401575232, best RMS: 0.7716420401575232\n",
      "current run: (4, 17), epoch: 50, Loss: 0.08060260137645824\n",
      "current RMS: 0.584636859643998, best RMS: 0.584636859643998\n",
      "current run: (4, 17), epoch: 75, Loss: 0.06409412627875856\n",
      "current RMS: 0.5224334895442367, best RMS: 0.5224334895442367\n",
      "current run: (4, 17), epoch: 100, Loss: 0.05639597011044401\n",
      "current RMS: 0.4899246814271912, best RMS: 0.4899246814271912\n",
      "current run: (4, 17), epoch: 125, Loss: 0.04980000356195502\n",
      "current RMS: 0.4603021378560383, best RMS: 0.4603021378560383\n",
      "current run: (4, 17), epoch: 150, Loss: 0.04424306122585895\n",
      "current RMS: 0.43369356207463955, best RMS: 0.43369356207463955\n",
      "current run: (4, 17), epoch: 175, Loss: 0.039739781004019856\n",
      "current RMS: 0.4108757938803131, best RMS: 0.4108757938803131\n",
      "current run: (4, 17), epoch: 200, Loss: 0.036184027917967626\n",
      "current RMS: 0.3919647080670694, best RMS: 0.3919647080670694\n",
      "current run: (4, 17), epoch: 225, Loss: 0.033318698109308625\n",
      "current RMS: 0.37605749397516675, best RMS: 0.37605749397516675\n",
      "current run: (4, 17), epoch: 250, Loss: 0.030841382268509483\n",
      "current RMS: 0.3617690314130553, best RMS: 0.3617690314130553\n",
      "current run: (4, 17), epoch: 275, Loss: 0.028524844311241263\n",
      "current RMS: 0.34791896540388956, best RMS: 0.34791896540388956\n",
      "current run: (4, 17), epoch: 300, Loss: 0.026247762411403433\n",
      "current RMS: 0.3337893679819811, best RMS: 0.3337893679819811\n",
      "current run: (4, 17), epoch: 325, Loss: 0.023961469228618176\n",
      "current RMS: 0.31901021959268494, best RMS: 0.31901021959268494\n",
      "current run: (4, 17), epoch: 350, Loss: 0.021654304757142664\n",
      "current RMS: 0.30339373661093544, best RMS: 0.30339373661093544\n",
      "current run: (4, 17), epoch: 375, Loss: 0.01933338898407447\n",
      "current RMS: 0.2868475640464465, best RMS: 0.2868475640464465\n",
      "current run: (4, 17), epoch: 400, Loss: 0.01701813931377587\n",
      "current RMS: 0.26934827688782603, best RMS: 0.26934827688782603\n",
      "current run: (4, 17), epoch: 425, Loss: 0.014737923554194027\n",
      "current RMS: 0.25094077280497423, best RMS: 0.25094077280497423\n",
      "current run: (4, 17), epoch: 450, Loss: 0.012530124132697338\n",
      "current RMS: 0.23174565674052372, best RMS: 0.23174565674052372\n",
      "current run: (4, 17), epoch: 475, Loss: 0.010437210388880602\n",
      "current RMS: 0.21196627388746542, best RMS: 0.21196627388746542\n",
      "current run: (4, 17), epoch: 500, Loss: 0.008502435907087089\n",
      "current RMS: 0.19188953909633275, best RMS: 0.19188953909633275\n",
      "current run: (4, 17), sim NRMS: 0.5925160204249446\n",
      "current run: (4, 18), epoch: 25, Loss: 0.12528315656228273\n",
      "current RMS: 0.7222952501232962, best RMS: 0.7222952501232962\n",
      "current run: (4, 18), epoch: 50, Loss: 0.07654479380035911\n",
      "current RMS: 0.5718081290325302, best RMS: 0.5718081290325302\n",
      "current run: (4, 18), epoch: 75, Loss: 0.0642495818442734\n",
      "current RMS: 0.525211918155752, best RMS: 0.525211918155752\n",
      "current run: (4, 18), epoch: 100, Loss: 0.058138953670546535\n",
      "current RMS: 0.4994931000700236, best RMS: 0.4994931000700236\n",
      "current run: (4, 18), epoch: 125, Loss: 0.05253301793465619\n",
      "current RMS: 0.47476901022411044, best RMS: 0.47476901022411044\n",
      "current run: (4, 18), epoch: 150, Loss: 0.0473490147580008\n",
      "current RMS: 0.450643794270838, best RMS: 0.450643794270838\n",
      "current run: (4, 18), epoch: 175, Loss: 0.04268355642135159\n",
      "current RMS: 0.4277191291167109, best RMS: 0.4277191291167109\n",
      "current run: (4, 18), epoch: 200, Loss: 0.03868663819925618\n",
      "current RMS: 0.4070791501087999, best RMS: 0.4070791501087999\n",
      "current run: (4, 18), epoch: 225, Loss: 0.03542402242686651\n",
      "current RMS: 0.389408677071473, best RMS: 0.389408677071473\n",
      "current run: (4, 18), epoch: 250, Loss: 0.03281154471891329\n",
      "current RMS: 0.3746442802437676, best RMS: 0.3746442802437676\n",
      "current run: (4, 18), epoch: 275, Loss: 0.030656595632058345\n",
      "current RMS: 0.3620203290148264, best RMS: 0.3620203290148264\n",
      "current run: (4, 18), epoch: 300, Loss: 0.028756919536994885\n",
      "current RMS: 0.3505562377788727, best RMS: 0.3505562377788727\n",
      "current run: (4, 18), epoch: 325, Loss: 0.026967009813637748\n",
      "current RMS: 0.3394625338752494, best RMS: 0.3394625338752494\n",
      "current run: (4, 18), epoch: 350, Loss: 0.025205854683121937\n",
      "current RMS: 0.3282426348426995, best RMS: 0.3282426348426995\n",
      "current run: (4, 18), epoch: 375, Loss: 0.023436882110364092\n",
      "current RMS: 0.3166214767840583, best RMS: 0.3166214767840583\n",
      "current run: (4, 18), epoch: 400, Loss: 0.02164785527911202\n",
      "current RMS: 0.3044514992020222, best RMS: 0.3044514992020222\n",
      "current run: (4, 18), epoch: 425, Loss: 0.019838948061142187\n",
      "current RMS: 0.29165235948749063, best RMS: 0.29165235948749063\n",
      "current run: (4, 18), epoch: 450, Loss: 0.018017368501085398\n",
      "current RMS: 0.2781831819105406, best RMS: 0.2781831819105406\n",
      "current run: (4, 18), epoch: 475, Loss: 0.016195387675595675\n",
      "current RMS: 0.2640339899460007, best RMS: 0.2640339899460007\n",
      "current run: (4, 18), epoch: 500, Loss: 0.014389658784685493\n",
      "current RMS: 0.2492263880786476, best RMS: 0.2492263880786476\n",
      "current run: (4, 18), sim NRMS: 0.6280992959035798\n",
      "current run: (4, 19), epoch: 25, Loss: 0.12955596222927712\n",
      "current RMS: 0.7372632818439194, best RMS: 0.7372632818439194\n",
      "current run: (4, 19), epoch: 50, Loss: 0.07458857419796291\n",
      "current RMS: 0.566882835249139, best RMS: 0.566882835249139\n",
      "current run: (4, 19), epoch: 75, Loss: 0.06313173965366477\n",
      "current RMS: 0.5217760403767273, best RMS: 0.5217760403767273\n",
      "current run: (4, 19), epoch: 100, Loss: 0.05798928807797502\n",
      "current RMS: 0.49964081318337644, best RMS: 0.49964081318337644\n",
      "current run: (4, 19), epoch: 125, Loss: 0.05335581113538693\n",
      "current RMS: 0.47929673499441167, best RMS: 0.47929673499441167\n",
      "current run: (4, 19), epoch: 150, Loss: 0.049087564807435154\n",
      "current RMS: 0.4596149584465387, best RMS: 0.4596149584465387\n",
      "current run: (4, 19), epoch: 175, Loss: 0.04520407707131931\n",
      "current RMS: 0.4408634056853044, best RMS: 0.4408634056853044\n",
      "current run: (4, 19), epoch: 200, Loss: 0.04173633999578774\n",
      "current RMS: 0.4234088167645371, best RMS: 0.4234088167645371\n",
      "current run: (4, 19), epoch: 225, Loss: 0.03870516203882724\n",
      "current RMS: 0.4075269806071409, best RMS: 0.4075269806071409\n",
      "current run: (4, 19), epoch: 250, Loss: 0.036097530382896814\n",
      "current RMS: 0.393339473187127, best RMS: 0.393339473187127\n",
      "current run: (4, 19), epoch: 275, Loss: 0.03385768464493616\n",
      "current RMS: 0.3807325515778342, best RMS: 0.3807325515778342\n",
      "current run: (4, 19), epoch: 300, Loss: 0.03189971706590566\n",
      "current RMS: 0.36938109593005686, best RMS: 0.36938109593005686\n",
      "current run: (4, 19), epoch: 325, Loss: 0.030131399714410916\n",
      "current RMS: 0.35886178794546847, best RMS: 0.35886178794546847\n",
      "current run: (4, 19), epoch: 350, Loss: 0.028473347174361476\n",
      "current RMS: 0.3487650114247806, best RMS: 0.3487650114247806\n",
      "current run: (4, 19), epoch: 375, Loss: 0.02686735855678448\n",
      "current RMS: 0.3387569822839686, best RMS: 0.3387569822839686\n",
      "current run: (4, 19), epoch: 400, Loss: 0.025276043914352064\n",
      "current RMS: 0.3285939230252308, best RMS: 0.3285939230252308\n",
      "current run: (4, 19), epoch: 425, Loss: 0.02367838331627441\n",
      "current RMS: 0.31810882485901415, best RMS: 0.31810882485901415\n",
      "current run: (4, 19), epoch: 450, Loss: 0.022064917374679315\n",
      "current RMS: 0.3071916153015487, best RMS: 0.3071916153015487\n",
      "current run: (4, 19), epoch: 475, Loss: 0.020434121253407433\n",
      "current RMS: 0.2957730412573595, best RMS: 0.2957730412573595\n",
      "current run: (4, 19), epoch: 500, Loss: 0.018790064166021036\n",
      "current RMS: 0.2838144355505783, best RMS: 0.2838144355505783\n",
      "current run: (4, 19), sim NRMS: 0.630586572997945\n",
      "current run: (4, 20), epoch: 25, Loss: 0.1459661448951689\n",
      "current RMS: 0.7821339539884202, best RMS: 0.7821339539884202\n",
      "current run: (4, 20), epoch: 50, Loss: 0.08099046029994254\n",
      "current RMS: 0.5901129438586883, best RMS: 0.5901129438586883\n",
      "current run: (4, 20), epoch: 75, Loss: 0.06277249974363676\n",
      "current RMS: 0.5223901767560494, best RMS: 0.5223901767560494\n",
      "current run: (4, 20), epoch: 100, Loss: 0.05742762416434949\n",
      "current RMS: 0.4990395911576724, best RMS: 0.4990395911576724\n",
      "current run: (4, 20), epoch: 125, Loss: 0.053885947530557095\n",
      "current RMS: 0.4830270307224452, best RMS: 0.4830270307224452\n",
      "current run: (4, 20), epoch: 150, Loss: 0.05060676974549568\n",
      "current RMS: 0.467982090357327, best RMS: 0.467982090357327\n",
      "current run: (4, 20), epoch: 175, Loss: 0.04749508072815856\n",
      "current RMS: 0.4532137070784786, best RMS: 0.4532137070784786\n",
      "current run: (4, 20), epoch: 200, Loss: 0.04455876429715331\n",
      "current RMS: 0.4387960856536085, best RMS: 0.4387960856536085\n",
      "current run: (4, 20), epoch: 225, Loss: 0.04181601148905829\n",
      "current RMS: 0.42488243282099186, best RMS: 0.42488243282099186\n",
      "current run: (4, 20), epoch: 250, Loss: 0.039282377652723945\n",
      "current RMS: 0.4116078396797881, best RMS: 0.4116078396797881\n",
      "current run: (4, 20), epoch: 275, Loss: 0.036965974611916155\n",
      "current RMS: 0.399080598963802, best RMS: 0.399080598963802\n",
      "current run: (4, 20), epoch: 300, Loss: 0.03486380827630523\n",
      "current RMS: 0.3873599948609721, best RMS: 0.3873599948609721\n",
      "current run: (4, 20), epoch: 325, Loss: 0.03295993746599865\n",
      "current RMS: 0.37643428570728504, best RMS: 0.37643428570728504\n",
      "current run: (4, 20), epoch: 350, Loss: 0.031226422726452596\n",
      "current RMS: 0.3662155199672451, best RMS: 0.3662155199672451\n",
      "current run: (4, 20), epoch: 375, Loss: 0.029627129960750658\n",
      "current RMS: 0.35655177061374005, best RMS: 0.35655177061374005\n",
      "current run: (4, 20), epoch: 400, Loss: 0.02812324109547066\n",
      "current RMS: 0.3472533709267294, best RMS: 0.3472533709267294\n",
      "current run: (4, 20), epoch: 425, Loss: 0.026678667034656434\n",
      "current RMS: 0.33812343773892917, best RMS: 0.33812343773892917\n",
      "current run: (4, 20), epoch: 450, Loss: 0.025263836337279914\n",
      "current RMS: 0.32898261593203054, best RMS: 0.32898261593203054\n",
      "current run: (4, 20), epoch: 475, Loss: 0.0238572849568016\n",
      "current RMS: 0.31968283701598416, best RMS: 0.31968283701598416\n",
      "current run: (4, 20), epoch: 500, Loss: 0.022445421593143815\n",
      "current RMS: 0.310110600632977, best RMS: 0.310110600632977\n",
      "current run: (4, 20), sim NRMS: 0.6242843389446744\n",
      "current run: (4, 21), epoch: 25, Loss: 0.14493544495356253\n",
      "current RMS: 0.7724412116083456, best RMS: 0.7724412116083456\n",
      "current run: (4, 21), epoch: 50, Loss: 0.08208678204733648\n",
      "current RMS: 0.5934180013906837, best RMS: 0.5934180013906837\n",
      "current run: (4, 21), epoch: 75, Loss: 0.06271002714981229\n",
      "current RMS: 0.5225944706914722, best RMS: 0.5225944706914722\n",
      "current run: (4, 21), epoch: 100, Loss: 0.057149075715678066\n",
      "current RMS: 0.4982361505077273, best RMS: 0.4982361505077273\n",
      "current run: (4, 21), epoch: 125, Loss: 0.05394041229288659\n",
      "current RMS: 0.4836469857958868, best RMS: 0.4836469857958868\n",
      "current run: (4, 21), epoch: 150, Loss: 0.051123058216130356\n",
      "current RMS: 0.4707354443054756, best RMS: 0.4707354443054756\n",
      "current run: (4, 21), epoch: 175, Loss: 0.048404072028234234\n",
      "current RMS: 0.4580057554246058, best RMS: 0.4580057554246058\n",
      "current run: (4, 21), epoch: 200, Loss: 0.045771836988014236\n",
      "current RMS: 0.4453426984890539, best RMS: 0.4453426984890539\n",
      "current run: (4, 21), epoch: 225, Loss: 0.0432458647118786\n",
      "current RMS: 0.4328336627971443, best RMS: 0.4328336627971443\n",
      "current run: (4, 21), epoch: 250, Loss: 0.04084408309397807\n",
      "current RMS: 0.42058184617725697, best RMS: 0.42058184617725697\n",
      "current run: (4, 21), epoch: 275, Loss: 0.0385813397707748\n",
      "current RMS: 0.4086923684284894, best RMS: 0.4086923684284894\n",
      "current run: (4, 21), epoch: 300, Loss: 0.03646796723712071\n",
      "current RMS: 0.39725815618550847, best RMS: 0.39725815618550847\n",
      "current run: (4, 21), epoch: 325, Loss: 0.03450792951594719\n",
      "current RMS: 0.38634526205389136, best RMS: 0.38634526205389136\n",
      "current run: (4, 21), epoch: 350, Loss: 0.03269738078599245\n",
      "current RMS: 0.375980945354245, best RMS: 0.375980945354245\n",
      "current run: (4, 21), epoch: 375, Loss: 0.031024376144344935\n",
      "current RMS: 0.3661460904453934, best RMS: 0.3661460904453934\n",
      "current run: (4, 21), epoch: 400, Loss: 0.029470073382279582\n",
      "current RMS: 0.35677555358010976, best RMS: 0.35677555358010976\n",
      "current run: (4, 21), epoch: 425, Loss: 0.02801122845130377\n",
      "current RMS: 0.3477675101453189, best RMS: 0.3477675101453189\n",
      "current run: (4, 21), epoch: 450, Loss: 0.026623325033179584\n",
      "current RMS: 0.3389989030091446, best RMS: 0.3389989030091446\n",
      "current run: (4, 21), epoch: 475, Loss: 0.02528350914373095\n",
      "current RMS: 0.33034224769520687, best RMS: 0.33034224769520687\n",
      "current run: (4, 21), epoch: 500, Loss: 0.02397268638792689\n",
      "current RMS: 0.32167946315077783, best RMS: 0.32167946315077783\n",
      "current run: (4, 21), sim NRMS: 0.6194286880061763\n",
      "current run: (4, 22), epoch: 25, Loss: 0.09081636774855685\n",
      "current RMS: 0.6177575843210444, best RMS: 0.6177575843210444\n",
      "current run: (4, 22), epoch: 50, Loss: 0.057336199257282366\n",
      "current RMS: 0.4977900551766089, best RMS: 0.4977900551766089\n",
      "current run: (4, 22), epoch: 75, Loss: 0.05243310294113719\n",
      "current RMS: 0.4754289996295158, best RMS: 0.4754289996295158\n",
      "current run: (4, 22), epoch: 100, Loss: 0.048120225796480454\n",
      "current RMS: 0.4555386292942277, best RMS: 0.4555386292942277\n",
      "current run: (4, 22), epoch: 125, Loss: 0.0438526918233226\n",
      "current RMS: 0.43454810769180485, best RMS: 0.43454810769180485\n",
      "current run: (4, 22), epoch: 150, Loss: 0.03964218996256731\n",
      "current RMS: 0.41276496484185854, best RMS: 0.41276496484185854\n",
      "current run: (4, 22), epoch: 175, Loss: 0.035674483341742315\n",
      "current RMS: 0.3912113171911249, best RMS: 0.3912113171911249\n",
      "current run: (4, 22), epoch: 200, Loss: 0.03211288516757454\n",
      "current RMS: 0.37081925568013674, best RMS: 0.37081925568013674\n",
      "current run: (4, 22), epoch: 225, Loss: 0.02896688337744065\n",
      "current RMS: 0.3518779433068218, best RMS: 0.3518779433068218\n",
      "current run: (4, 22), epoch: 250, Loss: 0.026113833792595284\n",
      "current RMS: 0.33387507468644295, best RMS: 0.33387507468644295\n",
      "current run: (4, 22), epoch: 275, Loss: 0.023413842863649965\n",
      "current RMS: 0.31602944310640396, best RMS: 0.31602944310640396\n",
      "current run: (4, 22), epoch: 300, Loss: 0.020775827364322565\n",
      "current RMS: 0.297692885258231, best RMS: 0.297692885258231\n",
      "current run: (4, 22), epoch: 325, Loss: 0.018165070337320954\n",
      "current RMS: 0.278465231242797, best RMS: 0.278465231242797\n",
      "current run: (4, 22), epoch: 350, Loss: 0.015588428622012585\n",
      "current RMS: 0.2581658758609122, best RMS: 0.2581658758609122\n",
      "current run: (4, 22), epoch: 375, Loss: 0.013079898094003787\n",
      "current RMS: 0.23679294811495769, best RMS: 0.23679294811495769\n",
      "current run: (4, 22), epoch: 400, Loss: 0.010690786982692328\n",
      "current RMS: 0.21450844507407923, best RMS: 0.21450844507407923\n",
      "current run: (4, 22), epoch: 425, Loss: 0.008481431015839013\n",
      "current RMS: 0.19164018049081066, best RMS: 0.19164018049081066\n",
      "current run: (4, 22), epoch: 450, Loss: 0.006511684306670216\n",
      "current RMS: 0.16868025128915198, best RMS: 0.16868025128915198\n",
      "current run: (4, 22), epoch: 475, Loss: 0.0048299857580100325\n",
      "current RMS: 0.1462627091554195, best RMS: 0.1462627091554195\n",
      "current run: (4, 22), epoch: 500, Loss: 0.003463223587197891\n",
      "current RMS: 0.12511071055018674, best RMS: 0.12511071055018674\n",
      "current run: (4, 22), sim NRMS: 0.5300863546059775\n",
      "current run: (4, 23), epoch: 25, Loss: 0.09424076324961905\n",
      "current RMS: 0.6327299909415561, best RMS: 0.6327299909415561\n",
      "current run: (4, 23), epoch: 50, Loss: 0.06272519929285678\n",
      "current RMS: 0.5206503035151308, best RMS: 0.5206503035151308\n",
      "current run: (4, 23), epoch: 75, Loss: 0.056361270968117744\n",
      "current RMS: 0.49359278529268713, best RMS: 0.49359278529268713\n",
      "current run: (4, 23), epoch: 100, Loss: 0.05103062824515668\n",
      "current RMS: 0.46968921314681206, best RMS: 0.46968921314681206\n",
      "current run: (4, 23), epoch: 125, Loss: 0.045712394733890174\n",
      "current RMS: 0.4440354333579844, best RMS: 0.4440354333579844\n",
      "current run: (4, 23), epoch: 150, Loss: 0.04046376505651547\n",
      "current RMS: 0.4173325220856893, best RMS: 0.4173325220856893\n",
      "current run: (4, 23), epoch: 175, Loss: 0.035561431867628994\n",
      "current RMS: 0.3908044101676896, best RMS: 0.3908044101676896\n",
      "current run: (4, 23), epoch: 200, Loss: 0.03131302049617915\n",
      "current RMS: 0.3663229496504165, best RMS: 0.3663229496504165\n",
      "current run: (4, 23), epoch: 225, Loss: 0.027761558013007986\n",
      "current RMS: 0.344591964312946, best RMS: 0.344591964312946\n",
      "current run: (4, 23), epoch: 250, Loss: 0.024679488458806034\n",
      "current RMS: 0.3246779547944588, best RMS: 0.3246779547944588\n",
      "current run: (4, 23), epoch: 275, Loss: 0.021818899675414567\n",
      "current RMS: 0.30519126600935736, best RMS: 0.30519126600935736\n",
      "current run: (4, 23), epoch: 300, Loss: 0.019038919257935646\n",
      "current RMS: 0.2851273115303816, best RMS: 0.2851273115303816\n",
      "current run: (4, 23), epoch: 325, Loss: 0.016300082478350197\n",
      "current RMS: 0.26398436779565987, best RMS: 0.26398436779565987\n",
      "current run: (4, 23), epoch: 350, Loss: 0.013625681770638158\n",
      "current RMS: 0.24163480416416538, best RMS: 0.24163480416416538\n",
      "current run: (4, 23), epoch: 375, Loss: 0.011071607815040423\n",
      "current RMS: 0.2182123244363434, best RMS: 0.2182123244363434\n",
      "current run: (4, 23), epoch: 400, Loss: 0.00870823025877361\n",
      "current RMS: 0.19406973982097656, best RMS: 0.19406973982097656\n",
      "current run: (4, 23), epoch: 425, Loss: 0.006607112588307809\n",
      "current RMS: 0.1697718200685897, best RMS: 0.1697718200685897\n",
      "current run: (4, 23), epoch: 450, Loss: 0.004826473818425523\n",
      "current RMS: 0.14606350098296686, best RMS: 0.14606350098296686\n",
      "current run: (4, 23), epoch: 475, Loss: 0.003397603931721423\n",
      "current RMS: 0.1237958558946157, best RMS: 0.1237958558946157\n",
      "current run: (4, 23), epoch: 500, Loss: 0.002317467642395778\n",
      "current RMS: 0.1038164807056827, best RMS: 0.1038164807056827\n",
      "current run: (4, 23), sim NRMS: 0.4914541494350217. This is better than last sim best:0.5070604740599356>0.4914541494350217\n",
      "current run: (4, 24), epoch: 25, Loss: 0.12529761894621907\n",
      "current RMS: 0.7249784620597267, best RMS: 0.7249784620597267\n",
      "current run: (4, 24), epoch: 50, Loss: 0.07505238046332428\n",
      "current RMS: 0.5694563409529273, best RMS: 0.5694563409529273\n",
      "current run: (4, 24), epoch: 75, Loss: 0.05958845260525552\n",
      "current RMS: 0.5099459281280359, best RMS: 0.5099459281280359\n",
      "current run: (4, 24), epoch: 100, Loss: 0.054728121730666886\n",
      "current RMS: 0.48860818407890705, best RMS: 0.48860818407890705\n",
      "current run: (4, 24), epoch: 125, Loss: 0.0515720591856213\n",
      "current RMS: 0.4739170858619912, best RMS: 0.4739170858619912\n",
      "current run: (4, 24), epoch: 150, Loss: 0.048606102017523446\n",
      "current RMS: 0.4599300708337196, best RMS: 0.4599300708337196\n",
      "current run: (4, 24), epoch: 175, Loss: 0.04571236399914362\n",
      "current RMS: 0.44589912452591324, best RMS: 0.44589912452591324\n",
      "current run: (4, 24), epoch: 200, Loss: 0.042902682533161075\n",
      "current RMS: 0.43185437059757975, best RMS: 0.43185437059757975\n",
      "current run: (4, 24), epoch: 225, Loss: 0.04020329360381148\n",
      "current RMS: 0.4179300366335016, best RMS: 0.4179300366335016\n",
      "current run: (4, 24), epoch: 250, Loss: 0.03763996661093342\n",
      "current RMS: 0.4042791248699377, best RMS: 0.4042791248699377\n",
      "current run: (4, 24), epoch: 275, Loss: 0.03523477471050848\n",
      "current RMS: 0.39104955904290467, best RMS: 0.39104955904290467\n",
      "current run: (4, 24), epoch: 300, Loss: 0.033003664842124185\n",
      "current RMS: 0.37837417206269547, best RMS: 0.37837417206269547\n",
      "current run: (4, 24), epoch: 325, Loss: 0.03095365314185605\n",
      "current RMS: 0.3663505454081592, best RMS: 0.3663505454081592\n",
      "current run: (4, 24), epoch: 350, Loss: 0.0290807341884609\n",
      "current RMS: 0.3550198745361227, best RMS: 0.3550198745361227\n",
      "current run: (4, 24), epoch: 375, Loss: 0.027369635734428733\n",
      "current RMS: 0.34435516150890777, best RMS: 0.34435516150890777\n",
      "current run: (4, 24), epoch: 400, Loss: 0.025795933024794895\n",
      "current RMS: 0.3342637641271802, best RMS: 0.3342637641271802\n",
      "current run: (4, 24), epoch: 425, Loss: 0.024330091962434453\n",
      "current RMS: 0.3246045859611503, best RMS: 0.3246045859611503\n",
      "current run: (4, 24), epoch: 450, Loss: 0.022942208211945626\n",
      "current RMS: 0.3152140732918997, best RMS: 0.3152140732918997\n",
      "current run: (4, 24), epoch: 475, Loss: 0.02160601251327322\n",
      "current RMS: 0.3059319491109199, best RMS: 0.3059319491109199\n",
      "current run: (4, 24), epoch: 500, Loss: 0.020301224035984323\n",
      "current RMS: 0.2966194675179492, best RMS: 0.2966194675179492\n",
      "current run: (4, 24), sim NRMS: 0.5628642641166344\n",
      "current run: (4, 25), epoch: 25, Loss: 0.1249437088874778\n",
      "current RMS: 0.7159314323364817, best RMS: 0.7159314323364817\n",
      "current run: (4, 25), epoch: 50, Loss: 0.06939751073712284\n",
      "current RMS: 0.5462272654065337, best RMS: 0.5462272654065337\n",
      "current run: (4, 25), epoch: 75, Loss: 0.05581839483973208\n",
      "current RMS: 0.49331047631092523, best RMS: 0.49331047631092523\n",
      "current run: (4, 25), epoch: 100, Loss: 0.05231755710037564\n",
      "current RMS: 0.4768997246909726, best RMS: 0.4768997246909726\n",
      "current run: (4, 25), epoch: 125, Loss: 0.0493129821168356\n",
      "current RMS: 0.46294967617735194, best RMS: 0.46294967617735194\n",
      "current run: (4, 25), epoch: 150, Loss: 0.046349951619670766\n",
      "current RMS: 0.44887236183093676, best RMS: 0.44887236183093676\n",
      "current run: (4, 25), epoch: 175, Loss: 0.04346358253979103\n",
      "current RMS: 0.43462256702660756, best RMS: 0.43462256702660756\n",
      "current run: (4, 25), epoch: 200, Loss: 0.0406867210939916\n",
      "current RMS: 0.4204424648909624, best RMS: 0.4204424648909624\n",
      "current run: (4, 25), epoch: 225, Loss: 0.03805229735720467\n",
      "current RMS: 0.4065470634422257, best RMS: 0.4065470634422257\n",
      "current run: (4, 25), epoch: 250, Loss: 0.03558733490342773\n",
      "current RMS: 0.3931077350102596, best RMS: 0.3931077350102596\n",
      "current run: (4, 25), epoch: 275, Loss: 0.03331114206259616\n",
      "current RMS: 0.38028010438044435, best RMS: 0.38028010438044435\n",
      "current run: (4, 25), epoch: 300, Loss: 0.031234002544992055\n",
      "current RMS: 0.368187552839176, best RMS: 0.368187552839176\n",
      "current run: (4, 25), epoch: 325, Loss: 0.02935637062977359\n",
      "current RMS: 0.356906421694649, best RMS: 0.356906421694649\n",
      "current run: (4, 25), epoch: 350, Loss: 0.027668895699348505\n",
      "current RMS: 0.3464571692521665, best RMS: 0.3464571692521665\n",
      "current run: (4, 25), epoch: 375, Loss: 0.026153559008909984\n",
      "current RMS: 0.3368020295978765, best RMS: 0.3368020295978765\n",
      "current run: (4, 25), epoch: 400, Loss: 0.02478592712061749\n",
      "current RMS: 0.3278512582994561, best RMS: 0.3278512582994561\n",
      "current run: (4, 25), epoch: 425, Loss: 0.0235381773480553\n",
      "current RMS: 0.3194774549389038, best RMS: 0.3194774549389038\n",
      "current run: (4, 25), epoch: 450, Loss: 0.0223822840497659\n",
      "current RMS: 0.3115343124403893, best RMS: 0.3115343124403893\n",
      "current run: (4, 25), epoch: 475, Loss: 0.021292717219764185\n",
      "current RMS: 0.3038750963376236, best RMS: 0.3038750963376236\n",
      "current run: (4, 25), epoch: 500, Loss: 0.020248212589434243\n",
      "current RMS: 0.2963669212102596, best RMS: 0.2963669212102596\n",
      "current run: (4, 25), sim NRMS: 0.5340130559448398\n",
      "current run: (5, 14), epoch: 25, Loss: 0.17184857731373657\n",
      "current RMS: 0.8447525268431727, best RMS: 0.8447525268431727\n",
      "current run: (5, 14), epoch: 50, Loss: 0.1155547657659681\n",
      "current RMS: 0.6974452823727945, best RMS: 0.6974452823727945\n",
      "current run: (5, 14), epoch: 75, Loss: 0.09483402876789038\n",
      "current RMS: 0.6322588201928468, best RMS: 0.6322588201928468\n",
      "current run: (5, 14), epoch: 100, Loss: 0.08427729657022191\n",
      "current RMS: 0.5953824124246961, best RMS: 0.5953824124246961\n",
      "current run: (5, 14), epoch: 125, Loss: 0.07499752206243106\n",
      "current RMS: 0.5617555843097053, best RMS: 0.5617555843097053\n",
      "current run: (5, 14), epoch: 150, Loss: 0.06600213898450207\n",
      "current RMS: 0.5270776901391196, best RMS: 0.5270776901391196\n",
      "current run: (5, 14), epoch: 175, Loss: 0.05726614811064389\n",
      "current RMS: 0.49098524334008986, best RMS: 0.49098524334008986\n",
      "current run: (5, 14), epoch: 200, Loss: 0.04890432597962666\n",
      "current RMS: 0.4537813564239721, best RMS: 0.4537813564239721\n",
      "current run: (5, 14), epoch: 225, Loss: 0.04102451900860966\n",
      "current RMS: 0.41572829061333155, best RMS: 0.41572829061333155\n",
      "current run: (5, 14), epoch: 250, Loss: 0.033683604793618885\n",
      "current RMS: 0.3769221949888979, best RMS: 0.3769221949888979\n",
      "current run: (5, 14), epoch: 275, Loss: 0.02691928423175069\n",
      "current RMS: 0.33735713154320485, best RMS: 0.33735713154320485\n",
      "current run: (5, 14), epoch: 300, Loss: 0.02080493684198862\n",
      "current RMS: 0.29722552744374536, best RMS: 0.29722552744374536\n",
      "current run: (5, 14), epoch: 325, Loss: 0.015455735249953534\n",
      "current RMS: 0.2571479828421784, best RMS: 0.2571479828421784\n",
      "current run: (5, 14), epoch: 350, Loss: 0.010986367614543106\n",
      "current RMS: 0.2181890940481601, best RMS: 0.2181890940481601\n",
      "current run: (5, 14), epoch: 375, Loss: 0.007461218888151606\n",
      "current RMS: 0.1817406137662632, best RMS: 0.1817406137662632\n",
      "current run: (5, 14), epoch: 400, Loss: 0.004861079034133553\n",
      "current RMS: 0.14930555048165142, best RMS: 0.14930555048165142\n",
      "current run: (5, 14), epoch: 425, Loss: 0.003079237136626168\n",
      "current RMS: 0.12220699493593992, best RMS: 0.12220699493593992\n",
      "current run: (5, 14), epoch: 450, Loss: 0.0019482986198301258\n",
      "current RMS: 0.10126861583899141, best RMS: 0.10126861583899141\n",
      "current run: (5, 14), epoch: 475, Loss: 0.0012830923475132554\n",
      "current RMS: 0.08653436484740262, best RMS: 0.08653436484740262\n",
      "current run: (5, 14), epoch: 500, Loss: 0.0009188539352436507\n",
      "current RMS: 0.07717747261899256, best RMS: 0.07717747261899256\n",
      "current run: (5, 14), sim NRMS: 0.365500778669576. This is better than last sim best:0.4914541494350217>0.365500778669576\n",
      "current run: (5, 15), epoch: 25, Loss: 0.11740642643176319\n",
      "current RMS: 0.701369980865748, best RMS: 0.701369980865748\n",
      "current run: (5, 15), epoch: 50, Loss: 0.08817335823562955\n",
      "current RMS: 0.6102402533043356, best RMS: 0.6102402533043356\n",
      "current run: (5, 15), epoch: 75, Loss: 0.07779640857219544\n",
      "current RMS: 0.5727087113176623, best RMS: 0.5727087113176623\n",
      "current run: (5, 15), epoch: 100, Loss: 0.06906620229044613\n",
      "current RMS: 0.5399469169975537, best RMS: 0.5399469169975537\n",
      "current run: (5, 15), epoch: 125, Loss: 0.061082899683788036\n",
      "current RMS: 0.5077225075224752, best RMS: 0.5077225075224752\n",
      "current run: (5, 15), epoch: 150, Loss: 0.05372763886156515\n",
      "current RMS: 0.47613720575585483, best RMS: 0.47613720575585483\n",
      "current run: (5, 15), epoch: 175, Loss: 0.046884389485531315\n",
      "current RMS: 0.4447814102964139, best RMS: 0.4447814102964139\n",
      "current run: (5, 15), epoch: 200, Loss: 0.040421096967533314\n",
      "current RMS: 0.41304569578988204, best RMS: 0.41304569578988204\n",
      "current run: (5, 15), epoch: 225, Loss: 0.034255592642765446\n",
      "current RMS: 0.38039930783171444, best RMS: 0.38039930783171444\n",
      "current run: (5, 15), epoch: 250, Loss: 0.028380357656130298\n",
      "current RMS: 0.34653044090492896, best RMS: 0.34653044090492896\n",
      "current run: (5, 15), epoch: 275, Loss: 0.022858720946206466\n",
      "current RMS: 0.3114500242560824, best RMS: 0.3114500242560824\n",
      "current run: (5, 15), epoch: 300, Loss: 0.017802065239642208\n",
      "current RMS: 0.275519273573787, best RMS: 0.275519273573787\n",
      "current run: (5, 15), epoch: 325, Loss: 0.013339106626675546\n",
      "current RMS: 0.23945060268611928, best RMS: 0.23945060268611928\n",
      "current run: (5, 15), epoch: 350, Loss: 0.009581583006345179\n",
      "current RMS: 0.2042748219634872, best RMS: 0.2042748219634872\n",
      "current run: (5, 15), epoch: 375, Loss: 0.006591454781508329\n",
      "current RMS: 0.17124868118064218, best RMS: 0.17124868118064218\n",
      "current run: (5, 15), epoch: 400, Loss: 0.004359561912043679\n",
      "current RMS: 0.14168944550575396, best RMS: 0.14168944550575396\n",
      "current run: (5, 15), epoch: 425, Loss: 0.0028052154684783327\n",
      "current RMS: 0.1167502179516683, best RMS: 0.1167502179516683\n",
      "current run: (5, 15), epoch: 450, Loss: 0.0017976609204099984\n",
      "current RMS: 0.09717048447104248, best RMS: 0.09717048447104248\n",
      "current run: (5, 15), epoch: 475, Loss: 0.0011892245690423452\n",
      "current RMS: 0.0830546331967241, best RMS: 0.0830546331967241\n",
      "current run: (5, 15), epoch: 500, Loss: 0.000845394382552823\n",
      "current RMS: 0.07378595888971927, best RMS: 0.07378595888971927\n",
      "current run: (5, 15), sim NRMS: 0.36055434651162976. This is better than last sim best:0.365500778669576>0.36055434651162976\n",
      "current run: (5, 16), epoch: 25, Loss: 0.12360566988960399\n",
      "current RMS: 0.7209398601721938, best RMS: 0.7209398601721938\n",
      "current run: (5, 16), epoch: 50, Loss: 0.08307871660983476\n",
      "current RMS: 0.5942378267855633, best RMS: 0.5942378267855633\n",
      "current run: (5, 16), epoch: 75, Loss: 0.07160934122489784\n",
      "current RMS: 0.5513524965197967, best RMS: 0.5513524965197967\n",
      "current run: (5, 16), epoch: 100, Loss: 0.06299504920002053\n",
      "current RMS: 0.5172520450364098, best RMS: 0.5172520450364098\n",
      "current run: (5, 16), epoch: 125, Loss: 0.054998537138068744\n",
      "current RMS: 0.48319119203504574, best RMS: 0.48319119203504574\n",
      "current run: (5, 16), epoch: 150, Loss: 0.04764693769901556\n",
      "current RMS: 0.4495598986427816, best RMS: 0.4495598986427816\n",
      "current run: (5, 16), epoch: 175, Loss: 0.041024079614440837\n",
      "current RMS: 0.4170628744684844, best RMS: 0.4170628744684844\n",
      "current run: (5, 16), epoch: 200, Loss: 0.035048993559244075\n",
      "current RMS: 0.38547315449158615, best RMS: 0.38547315449158615\n",
      "current run: (5, 16), epoch: 225, Loss: 0.029527547756489147\n",
      "current RMS: 0.35390792178309005, best RMS: 0.35390792178309005\n",
      "current run: (5, 16), epoch: 250, Loss: 0.024329045420858546\n",
      "current RMS: 0.32151888561769104, best RMS: 0.32151888561769104\n",
      "current run: (5, 16), epoch: 275, Loss: 0.019457908215177993\n",
      "current RMS: 0.28802152324276653, best RMS: 0.28802152324276653\n",
      "current run: (5, 16), epoch: 300, Loss: 0.015006514181469062\n",
      "current RMS: 0.2536832830610518, best RMS: 0.2536832830610518\n",
      "current run: (5, 16), epoch: 325, Loss: 0.011097200211460606\n",
      "current RMS: 0.2192253718961624, best RMS: 0.2192253718961624\n",
      "current run: (5, 16), epoch: 350, Loss: 0.007837792515849163\n",
      "current RMS: 0.1857437966741383, best RMS: 0.1857437966741383\n",
      "current run: (5, 16), epoch: 375, Loss: 0.005285064961725993\n",
      "current RMS: 0.15458406435283856, best RMS: 0.15458406435283856\n",
      "current run: (5, 16), epoch: 400, Loss: 0.0034230868454307216\n",
      "current RMS: 0.12713697405589539, best RMS: 0.12713697405589539\n",
      "current run: (5, 16), epoch: 425, Loss: 0.002165579400834842\n",
      "current RMS: 0.10456730480145734, best RMS: 0.10456730480145734\n",
      "current run: (5, 16), epoch: 450, Loss: 0.0013811905142048196\n",
      "current RMS: 0.08751349354911746, best RMS: 0.08751349354911746\n",
      "current run: (5, 16), epoch: 475, Loss: 0.0009287254563930423\n",
      "current RMS: 0.07584496176878566, best RMS: 0.07584496176878566\n",
      "current run: (5, 16), epoch: 500, Loss: 0.0006860856401834697\n",
      "current RMS: 0.06865509593642173, best RMS: 0.06865509593642173\n",
      "current run: (5, 16), sim NRMS: 0.3421378935880203. This is better than last sim best:0.36055434651162976>0.3421378935880203\n",
      "current run: (5, 17), epoch: 25, Loss: 0.14564066489891614\n",
      "current RMS: 0.7768929842113155, best RMS: 0.7768929842113155\n",
      "current run: (5, 17), epoch: 50, Loss: 0.08800382836969742\n",
      "current RMS: 0.6111568843413934, best RMS: 0.6111568843413934\n",
      "current run: (5, 17), epoch: 75, Loss: 0.07133323465281353\n",
      "current RMS: 0.5513164226256057, best RMS: 0.5513164226256057\n",
      "current run: (5, 17), epoch: 100, Loss: 0.06297901391706417\n",
      "current RMS: 0.5181877914204118, best RMS: 0.5181877914204118\n",
      "current run: (5, 17), epoch: 125, Loss: 0.05633310947613946\n",
      "current RMS: 0.49024236636562485, best RMS: 0.49024236636562485\n",
      "current run: (5, 17), epoch: 150, Loss: 0.05054426586927112\n",
      "current RMS: 0.46435384557295034, best RMS: 0.46435384557295034\n",
      "current run: (5, 17), epoch: 175, Loss: 0.045361576872110995\n",
      "current RMS: 0.43987317056785447, best RMS: 0.43987317056785447\n",
      "current run: (5, 17), epoch: 200, Loss: 0.04058753895829951\n",
      "current RMS: 0.41609248151507117, best RMS: 0.41609248151507117\n",
      "current run: (5, 17), epoch: 225, Loss: 0.03606879201633137\n",
      "current RMS: 0.39231706069090855, best RMS: 0.39231706069090855\n",
      "current run: (5, 17), epoch: 250, Loss: 0.03171614164445018\n",
      "current RMS: 0.36804645891175675, best RMS: 0.36804645891175675\n",
      "current run: (5, 17), epoch: 275, Loss: 0.02749745309880466\n",
      "current RMS: 0.3429688990161957, best RMS: 0.3429688990161957\n",
      "current run: (5, 17), epoch: 300, Loss: 0.023423797711881175\n",
      "current RMS: 0.31695015952704303, best RMS: 0.31695015952704303\n",
      "current run: (5, 17), epoch: 325, Loss: 0.019539595211916484\n",
      "current RMS: 0.29003890549544165, best RMS: 0.29003890549544165\n",
      "current run: (5, 17), epoch: 350, Loss: 0.01591129940024812\n",
      "current RMS: 0.26247071429210245, best RMS: 0.26247071429210245\n",
      "current run: (5, 17), epoch: 375, Loss: 0.012613303178381356\n",
      "current RMS: 0.23465626191235028, best RMS: 0.23465626191235028\n",
      "current run: (5, 17), epoch: 400, Loss: 0.009713741074723118\n",
      "current RMS: 0.20716281977499573, best RMS: 0.20716281977499573\n",
      "current run: (5, 17), epoch: 425, Loss: 0.0072614075952532105\n",
      "current RMS: 0.18068050316298423, best RMS: 0.18068050316298423\n",
      "current run: (5, 17), epoch: 450, Loss: 0.005275558592184263\n",
      "current RMS: 0.15596242886733924, best RMS: 0.15596242886733924\n",
      "current run: (5, 17), epoch: 475, Loss: 0.0037414685834450496\n",
      "current RMS: 0.13374014934319362, best RMS: 0.13374014934319362\n",
      "current run: (5, 17), epoch: 500, Loss: 0.002613531698058558\n",
      "current RMS: 0.11462489315720478, best RMS: 0.11462489315720478\n",
      "current run: (5, 17), sim NRMS: 0.45550022541319296\n",
      "current run: (5, 18), epoch: 25, Loss: 0.07736056847815556\n",
      "current RMS: 0.5736212278414595, best RMS: 0.5736212278414595\n",
      "current run: (5, 18), epoch: 50, Loss: 0.062038649786816835\n",
      "current RMS: 0.5132660372027988, best RMS: 0.5132660372027988\n",
      "current run: (5, 18), epoch: 75, Loss: 0.053268841213769604\n",
      "current RMS: 0.4769990558181559, best RMS: 0.4769990558181559\n",
      "current run: (5, 18), epoch: 100, Loss: 0.04563187529329303\n",
      "current RMS: 0.4410862030581383, best RMS: 0.4410862030581383\n",
      "current run: (5, 18), epoch: 125, Loss: 0.038819928593117975\n",
      "current RMS: 0.4065981919639953, best RMS: 0.4065981919639953\n",
      "current run: (5, 18), epoch: 150, Loss: 0.03266796747657815\n",
      "current RMS: 0.3727842802209941, best RMS: 0.3727842802209941\n",
      "current run: (5, 18), epoch: 175, Loss: 0.026853252639262144\n",
      "current RMS: 0.337953763355079, best RMS: 0.337953763355079\n",
      "current run: (5, 18), epoch: 200, Loss: 0.021224720559606232\n",
      "current RMS: 0.30067709359201544, best RMS: 0.30067709359201544\n",
      "current run: (5, 18), epoch: 225, Loss: 0.01588013035888655\n",
      "current RMS: 0.2606223382477144, best RMS: 0.2606223382477144\n",
      "current run: (5, 18), epoch: 250, Loss: 0.011081363842254797\n",
      "current RMS: 0.21868911761610343, best RMS: 0.21868911761610343\n",
      "current run: (5, 18), epoch: 275, Loss: 0.007131043170500527\n",
      "current RMS: 0.1770217874962548, best RMS: 0.1770217874962548\n",
      "current run: (5, 18), epoch: 300, Loss: 0.004223007887731883\n",
      "current RMS: 0.1386524939426099, best RMS: 0.1386524939426099\n",
      "current run: (5, 18), epoch: 325, Loss: 0.0023443079310535987\n",
      "current RMS: 0.10675656589676437, best RMS: 0.10675656589676437\n",
      "current run: (5, 18), epoch: 350, Loss: 0.0012916315598066077\n",
      "current RMS: 0.08360257461151459, best RMS: 0.08360257461151459\n",
      "current run: (5, 18), epoch: 375, Loss: 0.0007806322942552739\n",
      "current RMS: 0.06943087127129853, best RMS: 0.06943087127129853\n",
      "current run: (5, 18), epoch: 400, Loss: 0.0005625579593031507\n",
      "current RMS: 0.062186785545568043, best RMS: 0.062186785545568043\n",
      "current run: (5, 18), epoch: 425, Loss: 0.0004772195402899822\n",
      "current RMS: 0.05892255131894675, best RMS: 0.05892255131894675\n",
      "current run: (5, 18), epoch: 450, Loss: 0.00044343809874824856\n",
      "current RMS: 0.05744667768270568, best RMS: 0.05744667768270568\n",
      "current run: (5, 18), epoch: 475, Loss: 0.0004273661191335996\n",
      "current RMS: 0.05665771928884588, best RMS: 0.05665771928884588\n",
      "current run: (5, 18), epoch: 500, Loss: 0.0004169748231856946\n",
      "current RMS: 0.05611934394128786, best RMS: 0.05611934394128786\n",
      "current run: (5, 18), sim NRMS: 0.33898142115517355. This is better than last sim best:0.3421378935880203>0.33898142115517355\n",
      "current run: (5, 19), epoch: 25, Loss: 0.11480145368345877\n",
      "current RMS: 0.6938610502132269, best RMS: 0.6938610502132269\n",
      "current run: (5, 19), epoch: 50, Loss: 0.07071756110605606\n",
      "current RMS: 0.5515565415768002, best RMS: 0.5515565415768002\n",
      "current run: (5, 19), epoch: 75, Loss: 0.0609309460138686\n",
      "current RMS: 0.5122019413846028, best RMS: 0.5122019413846028\n",
      "current run: (5, 19), epoch: 100, Loss: 0.05574967675755387\n",
      "current RMS: 0.49011238620416453, best RMS: 0.49011238620416453\n",
      "current run: (5, 19), epoch: 125, Loss: 0.051242352294887536\n",
      "current RMS: 0.4698066616584716, best RMS: 0.4698066616584716\n",
      "current run: (5, 19), epoch: 150, Loss: 0.04712443650082838\n",
      "current RMS: 0.45029604207019075, best RMS: 0.45029604207019075\n",
      "current run: (5, 19), epoch: 175, Loss: 0.043219397037836345\n",
      "current RMS: 0.4310470179359442, best RMS: 0.4310470179359442\n",
      "current run: (5, 19), epoch: 200, Loss: 0.03941768856479627\n",
      "current RMS: 0.4115354583318861, best RMS: 0.4115354583318861\n",
      "current run: (5, 19), epoch: 225, Loss: 0.035645385008875576\n",
      "current RMS: 0.3913069040143473, best RMS: 0.3913069040143473\n",
      "current run: (5, 19), epoch: 250, Loss: 0.03185902466283857\n",
      "current RMS: 0.3699795461640401, best RMS: 0.3699795461640401\n",
      "current run: (5, 19), epoch: 275, Loss: 0.02804255144254931\n",
      "current RMS: 0.3472439067354289, best RMS: 0.3472439067354289\n",
      "current run: (5, 19), epoch: 300, Loss: 0.024208345615043907\n",
      "current RMS: 0.3228766621508106, best RMS: 0.3228766621508106\n",
      "current run: (5, 19), epoch: 325, Loss: 0.020401068776316304\n",
      "current RMS: 0.29679031434257547, best RMS: 0.29679031434257547\n",
      "current run: (5, 19), epoch: 350, Loss: 0.01669940548828288\n",
      "current RMS: 0.2690951034226021, best RMS: 0.2690951034226021\n",
      "current run: (5, 19), epoch: 375, Loss: 0.013210808661623101\n",
      "current RMS: 0.2401627926442289, best RMS: 0.2401627926442289\n",
      "current run: (5, 19), epoch: 400, Loss: 0.010056034773453121\n",
      "current RMS: 0.21066523001551143, best RMS: 0.21066523001551143\n",
      "current run: (5, 19), epoch: 425, Loss: 0.007344607147860795\n",
      "current RMS: 0.1815598446808095, best RMS: 0.1815598446808095\n",
      "current run: (5, 19), epoch: 450, Loss: 0.005148023934560002\n",
      "current RMS: 0.1540025384498802, best RMS: 0.1540025384498802\n",
      "current run: (5, 19), epoch: 475, Loss: 0.003481278620676325\n",
      "current RMS: 0.1291890051275564, best RMS: 0.1291890051275564\n",
      "current run: (5, 19), epoch: 500, Loss: 0.0023012824325135224\n",
      "current RMS: 0.10814878978165943, best RMS: 0.10814878978165943\n",
      "current run: (5, 19), sim NRMS: 0.44784972050580657\n",
      "current run: (5, 20), epoch: 25, Loss: 0.1297607967169865\n",
      "current RMS: 0.7370701661365305, best RMS: 0.7370701661365305\n",
      "current run: (5, 20), epoch: 50, Loss: 0.07445677810770927\n",
      "current RMS: 0.5663458805844938, best RMS: 0.5663458805844938\n",
      "current run: (5, 20), epoch: 75, Loss: 0.060082591491881866\n",
      "current RMS: 0.5098266273186446, best RMS: 0.5098266273186446\n",
      "current run: (5, 20), epoch: 100, Loss: 0.055421110604542696\n",
      "current RMS: 0.4890540239466912, best RMS: 0.4890540239466912\n",
      "current run: (5, 20), epoch: 125, Loss: 0.0517543882423041\n",
      "current RMS: 0.47244039631482604, best RMS: 0.47244039631482604\n",
      "current run: (5, 20), epoch: 150, Loss: 0.04815977080779071\n",
      "current RMS: 0.45559175465082474, best RMS: 0.45559175465082474\n",
      "current run: (5, 20), epoch: 175, Loss: 0.044491785810133196\n",
      "current RMS: 0.43775353722151483, best RMS: 0.43775353722151483\n",
      "current run: (5, 20), epoch: 200, Loss: 0.040645488416202365\n",
      "current RMS: 0.41830244723472654, best RMS: 0.41830244723472654\n",
      "current run: (5, 20), epoch: 225, Loss: 0.03656813651276291\n",
      "current RMS: 0.39674274042879054, best RMS: 0.39674274042879054\n",
      "current run: (5, 20), epoch: 250, Loss: 0.032268035074434535\n",
      "current RMS: 0.3727519370723944, best RMS: 0.3727519370723944\n",
      "current run: (5, 20), epoch: 275, Loss: 0.02781345546434631\n",
      "current RMS: 0.34625569436578907, best RMS: 0.34625569436578907\n",
      "current run: (5, 20), epoch: 300, Loss: 0.023313732945159468\n",
      "current RMS: 0.3173719937084329, best RMS: 0.3173719937084329\n",
      "current run: (5, 20), epoch: 325, Loss: 0.01890737320761984\n",
      "current RMS: 0.28640234673008635, best RMS: 0.28640234673008635\n",
      "current run: (5, 20), epoch: 350, Loss: 0.014757085045494231\n",
      "current RMS: 0.2539142315080127, best RMS: 0.2539142315080127\n",
      "current run: (5, 20), epoch: 375, Loss: 0.01103119362526987\n",
      "current RMS: 0.22080098675406, best RMS: 0.22080098675406\n",
      "current run: (5, 20), epoch: 400, Loss: 0.00787295878875956\n",
      "current RMS: 0.18827646354207914, best RMS: 0.18827646354207914\n",
      "current run: (5, 20), epoch: 425, Loss: 0.005367338868238818\n",
      "current RMS: 0.15777313824426875, best RMS: 0.15777313824426875\n",
      "current run: (5, 20), epoch: 450, Loss: 0.003519925899926197\n",
      "current RMS: 0.13074140812606122, best RMS: 0.13074140812606122\n",
      "current run: (5, 20), epoch: 475, Loss: 0.002259705628276882\n",
      "current RMS: 0.10837802184611559, best RMS: 0.10837802184611559\n",
      "current run: (5, 20), epoch: 500, Loss: 0.0014653199664625511\n",
      "current RMS: 0.09133694170375822, best RMS: 0.09133694170375822\n",
      "current run: (5, 20), sim NRMS: 0.40086964468524117\n",
      "current run: (5, 21), epoch: 25, Loss: 0.13092281568367092\n",
      "current RMS: 0.7366207314203073, best RMS: 0.7366207314203073\n",
      "current run: (5, 21), epoch: 50, Loss: 0.0733909768571273\n",
      "current RMS: 0.5600357401699444, best RMS: 0.5600357401699444\n",
      "current run: (5, 21), epoch: 75, Loss: 0.05862262629064987\n",
      "current RMS: 0.5032681978482783, best RMS: 0.5032681978482783\n",
      "current run: (5, 21), epoch: 100, Loss: 0.05405763002031246\n",
      "current RMS: 0.48283477472340786, best RMS: 0.48283477472340786\n",
      "current run: (5, 21), epoch: 125, Loss: 0.05041716602359126\n",
      "current RMS: 0.4661797937716553, best RMS: 0.4661797937716553\n",
      "current run: (5, 21), epoch: 150, Loss: 0.04692964006557074\n",
      "current RMS: 0.44963117660447016, best RMS: 0.44963117660447016\n",
      "current run: (5, 21), epoch: 175, Loss: 0.043404308554311086\n",
      "current RMS: 0.4322873123991904, best RMS: 0.4322873123991904\n",
      "current run: (5, 21), epoch: 200, Loss: 0.039746472792389693\n",
      "current RMS: 0.4136455216578386, best RMS: 0.4136455216578386\n",
      "current run: (5, 21), epoch: 225, Loss: 0.03591766400409542\n",
      "current RMS: 0.3933018652470325, best RMS: 0.3933018652470325\n",
      "current run: (5, 21), epoch: 250, Loss: 0.03192404783826042\n",
      "current RMS: 0.3709815233579182, best RMS: 0.3709815233579182\n",
      "current run: (5, 21), epoch: 275, Loss: 0.027815263597857708\n",
      "current RMS: 0.3465919771132398, best RMS: 0.3465919771132398\n",
      "current run: (5, 21), epoch: 300, Loss: 0.02368048527184051\n",
      "current RMS: 0.3202430315283173, best RMS: 0.3202430315283173\n",
      "current run: (5, 21), epoch: 325, Loss: 0.019636026961502132\n",
      "current RMS: 0.2922444858403299, best RMS: 0.2922444858403299\n",
      "current run: (5, 21), epoch: 350, Loss: 0.01580705672206876\n",
      "current RMS: 0.2630684561774145, best RMS: 0.2630684561774145\n",
      "current run: (5, 21), epoch: 375, Loss: 0.012313716889067985\n",
      "current RMS: 0.2333416378224581, best RMS: 0.2333416378224581\n",
      "current run: (5, 21), epoch: 400, Loss: 0.00925947090923667\n",
      "current RMS: 0.20386179888063005, best RMS: 0.20386179888063005\n",
      "current run: (5, 21), epoch: 425, Loss: 0.0067159285998634145\n",
      "current RMS: 0.17557345312314449, best RMS: 0.17557345312314449\n",
      "current run: (5, 21), epoch: 450, Loss: 0.004709176014796301\n",
      "current RMS: 0.14948346843631363, best RMS: 0.14948346843631363\n",
      "current run: (5, 21), epoch: 475, Loss: 0.003215394554931782\n",
      "current RMS: 0.12653231409595195, best RMS: 0.12653231409595195\n",
      "current run: (5, 21), epoch: 500, Loss: 0.00216876781982675\n",
      "current RMS: 0.10744162810204803, best RMS: 0.10744162810204803\n",
      "current run: (5, 21), sim NRMS: 0.4248593179637831\n",
      "current run: (5, 22), epoch: 25, Loss: 0.0902604551040608\n",
      "current RMS: 0.6201018747079226, best RMS: 0.6201018747079226\n",
      "current run: (5, 22), epoch: 50, Loss: 0.06222665384295979\n",
      "current RMS: 0.5187042433852942, best RMS: 0.5187042433852942\n",
      "current run: (5, 22), epoch: 75, Loss: 0.056681273911580496\n",
      "current RMS: 0.49484278512201385, best RMS: 0.49484278512201385\n",
      "current run: (5, 22), epoch: 100, Loss: 0.05241107306447275\n",
      "current RMS: 0.47579453238686287, best RMS: 0.47579453238686287\n",
      "current run: (5, 22), epoch: 125, Loss: 0.048067583186852135\n",
      "current RMS: 0.45556358792679424, best RMS: 0.45556358792679424\n",
      "current run: (5, 22), epoch: 150, Loss: 0.04351902112805732\n",
      "current RMS: 0.43319829858484427, best RMS: 0.43319829858484427\n",
      "current run: (5, 22), epoch: 175, Loss: 0.03873806097276436\n",
      "current RMS: 0.40856540221844717, best RMS: 0.40856540221844717\n",
      "current run: (5, 22), epoch: 200, Loss: 0.033765072237540494\n",
      "current RMS: 0.3813901522302276, best RMS: 0.3813901522302276\n",
      "current run: (5, 22), epoch: 225, Loss: 0.028699564789669164\n",
      "current RMS: 0.3517122457701459, best RMS: 0.3517122457701459\n",
      "current run: (5, 22), epoch: 250, Loss: 0.02366738917472021\n",
      "current RMS: 0.319677977558632, best RMS: 0.319677977558632\n",
      "current run: (5, 22), epoch: 275, Loss: 0.018810976631269516\n",
      "current RMS: 0.28553791326791195, best RMS: 0.28553791326791195\n",
      "current run: (5, 22), epoch: 300, Loss: 0.014300262578764747\n",
      "current RMS: 0.24983114712199334, best RMS: 0.24983114712199334\n",
      "current run: (5, 22), epoch: 325, Loss: 0.010321645187379908\n",
      "current RMS: 0.21355684208047315, best RMS: 0.21355684208047315\n",
      "current run: (5, 22), epoch: 350, Loss: 0.007037355396607667\n",
      "current RMS: 0.17821020994762385, best RMS: 0.17821020994762385\n",
      "current run: (5, 22), epoch: 375, Loss: 0.0045348657523653\n",
      "current RMS: 0.14563964098587462, best RMS: 0.14563964098587462\n",
      "current run: (5, 22), epoch: 400, Loss: 0.002794173095079263\n",
      "current RMS: 0.11770959832739034, best RMS: 0.11770959832739034\n",
      "current run: (5, 22), epoch: 425, Loss: 0.001695974504838809\n",
      "current RMS: 0.09582506088152748, best RMS: 0.09582506088152748\n",
      "current run: (5, 22), epoch: 450, Loss: 0.0010680052410513346\n",
      "current RMS: 0.080451780812339, best RMS: 0.080451780812339\n",
      "current run: (5, 22), epoch: 475, Loss: 0.0007405976163587021\n",
      "current RMS: 0.07087953649417426, best RMS: 0.07087953649417426\n",
      "current run: (5, 22), epoch: 500, Loss: 0.0005826736302046928\n",
      "current RMS: 0.06554060845546147, best RMS: 0.06554060845546147\n",
      "current run: (5, 22), sim NRMS: 0.3173155712022983. This is better than last sim best:0.33898142115517355>0.3173155712022983\n",
      "current run: (5, 23), epoch: 25, Loss: 0.12003185513441915\n",
      "current RMS: 0.7092709375331884, best RMS: 0.7092709375331884\n",
      "current run: (5, 23), epoch: 50, Loss: 0.06647015614751126\n",
      "current RMS: 0.5361071059202432, best RMS: 0.5361071059202432\n",
      "current run: (5, 23), epoch: 75, Loss: 0.05771590774393537\n",
      "current RMS: 0.49976280253927596, best RMS: 0.49976280253927596\n",
      "current run: (5, 23), epoch: 100, Loss: 0.054246844727880966\n",
      "current RMS: 0.48417332220215636, best RMS: 0.48417332220215636\n",
      "current run: (5, 23), epoch: 125, Loss: 0.051011825150502135\n",
      "current RMS: 0.46958577457299977, best RMS: 0.46958577457299977\n",
      "current run: (5, 23), epoch: 150, Loss: 0.04779166794962841\n",
      "current RMS: 0.45439695725477675, best RMS: 0.45439695725477675\n",
      "current run: (5, 23), epoch: 175, Loss: 0.04453525962505154\n",
      "current RMS: 0.4385396467011124, best RMS: 0.4385396467011124\n",
      "current run: (5, 23), epoch: 200, Loss: 0.04123010485020439\n",
      "current RMS: 0.42190202800543847, best RMS: 0.42190202800543847\n",
      "current run: (5, 23), epoch: 225, Loss: 0.0378685922560365\n",
      "current RMS: 0.40433183041225995, best RMS: 0.40433183041225995\n",
      "current run: (5, 23), epoch: 250, Loss: 0.034450435679302345\n",
      "current RMS: 0.38569796800390777, best RMS: 0.38569796800390777\n",
      "current run: (5, 23), epoch: 275, Loss: 0.030985715574289033\n",
      "current RMS: 0.36589691169695665, best RMS: 0.36589691169695665\n",
      "current run: (5, 23), epoch: 300, Loss: 0.027497120797459706\n",
      "current RMS: 0.3448658496337276, best RMS: 0.3448658496337276\n",
      "current run: (5, 23), epoch: 325, Loss: 0.024021008976421804\n",
      "current RMS: 0.32260197223854764, best RMS: 0.32260197223854764\n",
      "current run: (5, 23), epoch: 350, Loss: 0.02060699699430075\n",
      "current RMS: 0.29917942575190776, best RMS: 0.29917942575190776\n",
      "current run: (5, 23), epoch: 375, Loss: 0.01731584781466345\n",
      "current RMS: 0.2747660101516869, best RMS: 0.2747660101516869\n",
      "current run: (5, 23), epoch: 400, Loss: 0.014215427871996781\n",
      "current RMS: 0.24963885414945985, best RMS: 0.24963885414945985\n",
      "current run: (5, 23), epoch: 425, Loss: 0.011374512058868061\n",
      "current RMS: 0.224194812823847, best RMS: 0.224194812823847\n",
      "current run: (5, 23), epoch: 450, Loss: 0.00885460898840434\n",
      "current RMS: 0.19894873482129288, best RMS: 0.19894873482129288\n",
      "current run: (5, 23), epoch: 475, Loss: 0.006700926588867649\n",
      "current RMS: 0.17451220718874055, best RMS: 0.17451220718874055\n",
      "current run: (5, 23), epoch: 500, Loss: 0.004934684304938196\n",
      "current RMS: 0.151548811591285, best RMS: 0.151548811591285\n",
      "current run: (5, 23), sim NRMS: 0.4906277951130938\n",
      "current run: (5, 24), epoch: 25, Loss: 0.09195430180661164\n",
      "current RMS: 0.6228769518737738, best RMS: 0.6228769518737738\n",
      "current run: (5, 24), epoch: 50, Loss: 0.058695424484160395\n",
      "current RMS: 0.5027830209151942, best RMS: 0.5027830209151942\n",
      "current run: (5, 24), epoch: 75, Loss: 0.05257454783892188\n",
      "current RMS: 0.4766276174520289, best RMS: 0.4766276174520289\n",
      "current run: (5, 24), epoch: 100, Loss: 0.04777830146801364\n",
      "current RMS: 0.4544212982691789, best RMS: 0.4544212982691789\n",
      "current run: (5, 24), epoch: 125, Loss: 0.04287285267953596\n",
      "current RMS: 0.4301464513087757, best RMS: 0.4301464513087757\n",
      "current run: (5, 24), epoch: 150, Loss: 0.03782988737070714\n",
      "current RMS: 0.40378293268473936, best RMS: 0.40378293268473936\n",
      "current run: (5, 24), epoch: 175, Loss: 0.032702718268796935\n",
      "current RMS: 0.37520049160776064, best RMS: 0.37520049160776064\n",
      "current run: (5, 24), epoch: 200, Loss: 0.02758554399555552\n",
      "current RMS: 0.34447289760606264, best RMS: 0.34447289760606264\n",
      "current run: (5, 24), epoch: 225, Loss: 0.022588433053084077\n",
      "current RMS: 0.311759379061473, best RMS: 0.311759379061473\n",
      "current run: (5, 24), epoch: 250, Loss: 0.017826546396674713\n",
      "current RMS: 0.2772387987171912, best RMS: 0.2772387987171912\n",
      "current run: (5, 24), epoch: 275, Loss: 0.013437733472141443\n",
      "current RMS: 0.2413030238517804, best RMS: 0.2413030238517804\n",
      "current run: (5, 24), epoch: 300, Loss: 0.009589738704219314\n",
      "current RMS: 0.2048561895982084, best RMS: 0.2048561895982084\n",
      "current run: (5, 24), epoch: 325, Loss: 0.006440565910195414\n",
      "current RMS: 0.1694250799293179, best RMS: 0.1694250799293179\n",
      "current run: (5, 24), epoch: 350, Loss: 0.004075610611082168\n",
      "current RMS: 0.13698528080963884, best RMS: 0.13698528080963884\n",
      "current run: (5, 24), epoch: 375, Loss: 0.0024671194385364453\n",
      "current RMS: 0.10954657293794956, best RMS: 0.10954657293794956\n",
      "current run: (5, 24), epoch: 400, Loss: 0.001483826276713804\n",
      "current RMS: 0.08857591566560027, best RMS: 0.08857591566560027\n",
      "current run: (5, 24), epoch: 425, Loss: 0.0009438458579235207\n",
      "current RMS: 0.07441703767057681, best RMS: 0.07441703767057681\n",
      "current run: (5, 24), epoch: 450, Loss: 0.0006752158960669343\n",
      "current RMS: 0.06606150793181782, best RMS: 0.06606150793181782\n",
      "current run: (5, 24), epoch: 475, Loss: 0.0005515283511206978\n",
      "current RMS: 0.06166404088734692, best RMS: 0.06166404088734692\n",
      "current run: (5, 24), epoch: 500, Loss: 0.0004964211040142888\n",
      "current RMS: 0.05947083471808779, best RMS: 0.05947083471808779\n",
      "current run: (5, 24), sim NRMS: 0.3100336894152448. This is better than last sim best:0.3173155712022983>0.3100336894152448\n",
      "current run: (5, 25), epoch: 25, Loss: 0.09560116404628455\n",
      "current RMS: 0.6342553837720191, best RMS: 0.6342553837720191\n",
      "current run: (5, 25), epoch: 50, Loss: 0.05869854479564393\n",
      "current RMS: 0.5025931923644158, best RMS: 0.5025931923644158\n",
      "current run: (5, 25), epoch: 75, Loss: 0.05240778010910528\n",
      "current RMS: 0.4757607449795855, best RMS: 0.4757607449795855\n",
      "current run: (5, 25), epoch: 100, Loss: 0.04749112523395001\n",
      "current RMS: 0.45301344257255394, best RMS: 0.45301344257255394\n",
      "current run: (5, 25), epoch: 125, Loss: 0.04264081956875252\n",
      "current RMS: 0.42903436487687147, best RMS: 0.42903436487687147\n",
      "current run: (5, 25), epoch: 150, Loss: 0.037684997272121566\n",
      "current RMS: 0.40306123938154265, best RMS: 0.40306123938154265\n",
      "current run: (5, 25), epoch: 175, Loss: 0.03264983768770052\n",
      "current RMS: 0.3749678808450531, best RMS: 0.3749678808450531\n",
      "current run: (5, 25), epoch: 200, Loss: 0.02762933866906145\n",
      "current RMS: 0.34479014535920455, best RMS: 0.34479014535920455\n",
      "current run: (5, 25), epoch: 225, Loss: 0.022733359839621874\n",
      "current RMS: 0.31274232487246967, best RMS: 0.31274232487246967\n",
      "current run: (5, 25), epoch: 250, Loss: 0.018053364340005523\n",
      "current RMS: 0.2788941978944832, best RMS: 0.2788941978944832\n",
      "current run: (5, 25), epoch: 275, Loss: 0.013695545192056947\n",
      "current RMS: 0.2434044420537692, best RMS: 0.2434044420537692\n",
      "current run: (5, 25), epoch: 300, Loss: 0.00981541566737463\n",
      "current RMS: 0.20695089281569845, best RMS: 0.20695089281569845\n",
      "current run: (5, 25), epoch: 325, Loss: 0.0065858821916431965\n",
      "current RMS: 0.1709477398096322, best RMS: 0.1709477398096322\n",
      "current run: (5, 25), epoch: 350, Loss: 0.004127031401207025\n",
      "current RMS: 0.13746391866116353, best RMS: 0.13746391866116353\n",
      "current run: (5, 25), epoch: 375, Loss: 0.0024464211506214995\n",
      "current RMS: 0.10883868199984616, best RMS: 0.10883868199984616\n",
      "current run: (5, 25), epoch: 400, Loss: 0.0014287456702434696\n",
      "current RMS: 0.08698063339565117, best RMS: 0.08698063339565117\n",
      "current run: (5, 25), epoch: 425, Loss: 0.000885037141392314\n",
      "current RMS: 0.07251150031781056, best RMS: 0.07251150031781056\n",
      "current run: (5, 25), epoch: 450, Loss: 0.0006263970870060742\n",
      "current RMS: 0.06432352009153687, best RMS: 0.06432352009153687\n",
      "current run: (5, 25), epoch: 475, Loss: 0.0005135543237737426\n",
      "current RMS: 0.060244593671505094, best RMS: 0.060244593671505094\n",
      "current run: (5, 25), epoch: 500, Loss: 0.00046532678518691875\n",
      "current RMS: 0.05829471235284783, best RMS: 0.05829471235284783\n",
      "current run: (5, 25), sim NRMS: 0.30014231312149425. This is better than last sim best:0.3100336894152448>0.30014231312149425\n",
      "current run: (6, 14), epoch: 25, Loss: 0.13009632936288443\n",
      "current RMS: 0.737757206605121, best RMS: 0.737757206605121\n",
      "current run: (6, 14), epoch: 50, Loss: 0.09599966987166023\n",
      "current RMS: 0.6354982753252514, best RMS: 0.6354982753252514\n",
      "current run: (6, 14), epoch: 75, Loss: 0.08203628944602102\n",
      "current RMS: 0.5877144346087135, best RMS: 0.5877144346087135\n",
      "current run: (6, 14), epoch: 100, Loss: 0.06810369752686887\n",
      "current RMS: 0.5356990801730537, best RMS: 0.5356990801730537\n",
      "current run: (6, 14), epoch: 125, Loss: 0.05354979566476082\n",
      "current RMS: 0.47522062828306055, best RMS: 0.47522062828306055\n",
      "current run: (6, 14), epoch: 150, Loss: 0.038977363306149516\n",
      "current RMS: 0.40581668630879547, best RMS: 0.40581668630879547\n",
      "current run: (6, 14), epoch: 175, Loss: 0.025618697822260526\n",
      "current RMS: 0.3300008714596, best RMS: 0.3300008714596\n",
      "current run: (6, 14), epoch: 200, Loss: 0.014819654385386377\n",
      "current RMS: 0.2530588314861838, best RMS: 0.2530588314861838\n",
      "current run: (6, 14), epoch: 225, Loss: 0.007435738581466387\n",
      "current RMS: 0.18320514756989542, best RMS: 0.18320514756989542\n",
      "current run: (6, 14), epoch: 250, Loss: 0.003353148450359264\n",
      "current RMS: 0.12961234871538435, best RMS: 0.12961234871538435\n",
      "current run: (6, 14), epoch: 275, Loss: 0.0015918328961892028\n",
      "current RMS: 0.09770676968304921, best RMS: 0.09770676968304921\n",
      "current run: (6, 14), epoch: 300, Loss: 0.0010032395892417992\n",
      "current RMS: 0.08402732436685978, best RMS: 0.08402732436685978\n",
      "current run: (6, 14), epoch: 325, Loss: 0.0008433236031552959\n",
      "current RMS: 0.07956359907524325, best RMS: 0.07956359907524325\n",
      "current run: (6, 14), epoch: 350, Loss: 0.0007999300329474227\n",
      "current RMS: 0.07808934057041977, best RMS: 0.07808934057041977\n",
      "current run: (6, 14), epoch: 375, Loss: 0.0007812189014002095\n",
      "current RMS: 0.07735373900197254, best RMS: 0.07735373900197254\n",
      "current run: (6, 14), epoch: 400, Loss: 0.0007671570644510492\n",
      "current RMS: 0.07679455286121085, best RMS: 0.07679455286121085\n",
      "current run: (6, 14), epoch: 425, Loss: 0.0007543570114434686\n",
      "current RMS: 0.07629272645944529, best RMS: 0.07629272645944529\n",
      "current run: (6, 14), epoch: 450, Loss: 0.0007423297501919564\n",
      "current RMS: 0.07582125855818148, best RMS: 0.07582125855818148\n",
      "current run: (6, 14), epoch: 475, Loss: 0.0007309756574803732\n",
      "current RMS: 0.07537221452372345, best RMS: 0.07537221452372345\n",
      "current run: (6, 14), epoch: 500, Loss: 0.0007202387108232604\n",
      "current RMS: 0.07494251388365301, best RMS: 0.07494251388365301\n",
      "current run: (6, 14), sim NRMS: 0.331066299095247\n",
      "current run: (6, 15), epoch: 25, Loss: 0.13143286658522393\n",
      "current RMS: 0.7412236980734044, best RMS: 0.7412236980734044\n",
      "current run: (6, 15), epoch: 50, Loss: 0.09214589250985462\n",
      "current RMS: 0.623400728508341, best RMS: 0.623400728508341\n",
      "current run: (6, 15), epoch: 75, Loss: 0.07447564943688431\n",
      "current RMS: 0.5603363689127502, best RMS: 0.5603363689127502\n",
      "current run: (6, 15), epoch: 100, Loss: 0.0588133688847052\n",
      "current RMS: 0.49798507889724664, best RMS: 0.49798507889724664\n",
      "current run: (6, 15), epoch: 125, Loss: 0.043803256687726715\n",
      "current RMS: 0.4297525695087886, best RMS: 0.4297525695087886\n",
      "current run: (6, 15), epoch: 150, Loss: 0.029984062371300902\n",
      "current RMS: 0.3559181585135575, best RMS: 0.3559181585135575\n",
      "current run: (6, 15), epoch: 175, Loss: 0.018248831625914314\n",
      "current RMS: 0.2789628678641683, best RMS: 0.2789628678641683\n",
      "current run: (6, 15), epoch: 200, Loss: 0.00957362131435023\n",
      "current RMS: 0.20498992722264384, best RMS: 0.20498992722264384\n",
      "current run: (6, 15), epoch: 225, Loss: 0.004346146097298082\n",
      "current RMS: 0.14354675512473936, best RMS: 0.14354675512473936\n",
      "current run: (6, 15), epoch: 250, Loss: 0.0019075941031186012\n",
      "current RMS: 0.1031142834829903, best RMS: 0.1031142834829903\n",
      "current run: (6, 15), epoch: 275, Loss: 0.0010503183093986547\n",
      "current RMS: 0.0841229649028112, best RMS: 0.0841229649028112\n",
      "current run: (6, 15), epoch: 300, Loss: 0.0008197932802559181\n",
      "current RMS: 0.07790360632624424, best RMS: 0.07790360632624424\n",
      "current run: (6, 15), epoch: 325, Loss: 0.00076591315440542\n",
      "current RMS: 0.07615818890050295, best RMS: 0.07615818890050295\n",
      "current run: (6, 15), epoch: 350, Loss: 0.0007485778678280924\n",
      "current RMS: 0.07548480951008542, best RMS: 0.07548480951008542\n",
      "current run: (6, 15), epoch: 375, Loss: 0.0007372528042426899\n",
      "current RMS: 0.0750357986858741, best RMS: 0.0750357986858741\n",
      "current run: (6, 15), epoch: 400, Loss: 0.0007271103800722254\n",
      "current RMS: 0.07464655632089037, best RMS: 0.07464655632089037\n",
      "current run: (6, 15), epoch: 425, Loss: 0.000717567225546744\n",
      "current RMS: 0.07428434884307013, best RMS: 0.07428434884307013\n",
      "current run: (6, 15), epoch: 450, Loss: 0.0007085321651982692\n",
      "current RMS: 0.07394066660076803, best RMS: 0.07394066660076803\n",
      "current run: (6, 15), epoch: 475, Loss: 0.0006999506419562037\n",
      "current RMS: 0.07361228298055154, best RMS: 0.07361228298055154\n",
      "current run: (6, 15), epoch: 500, Loss: 0.0006917694845980664\n",
      "current RMS: 0.07329729183403576, best RMS: 0.07329729183403576\n",
      "current run: (6, 15), sim NRMS: 0.32174639233838526\n",
      "current run: (6, 16), epoch: 25, Loss: 0.11055417517284556\n",
      "current RMS: 0.6813365203175512, best RMS: 0.6813365203175512\n",
      "current run: (6, 16), epoch: 50, Loss: 0.07766790123830966\n",
      "current RMS: 0.5734703971248587, best RMS: 0.5734703971248587\n",
      "current run: (6, 16), epoch: 75, Loss: 0.062017954989630204\n",
      "current RMS: 0.512912251714719, best RMS: 0.512912251714719\n",
      "current run: (6, 16), epoch: 100, Loss: 0.047504481798879665\n",
      "current RMS: 0.4492561758294661, best RMS: 0.4492561758294661\n",
      "current run: (6, 16), epoch: 125, Loss: 0.033954222799796124\n",
      "current RMS: 0.3801991350196146, best RMS: 0.3801991350196146\n",
      "current run: (6, 16), epoch: 150, Loss: 0.022277017716587303\n",
      "current RMS: 0.3089644132349238, best RMS: 0.3089644132349238\n",
      "current run: (6, 16), epoch: 175, Loss: 0.013102779464510434\n",
      "current RMS: 0.23903707053809148, best RMS: 0.23903707053809148\n",
      "current run: (6, 16), epoch: 200, Loss: 0.006746275548609566\n",
      "current RMS: 0.1756293313557284, best RMS: 0.1756293313557284\n",
      "current run: (6, 16), epoch: 225, Loss: 0.003120932214966036\n",
      "current RMS: 0.12633859385568605, best RMS: 0.12633859385568605\n",
      "current run: (6, 16), epoch: 250, Loss: 0.001514610682335716\n",
      "current RMS: 0.0966903457447758, best RMS: 0.0966903457447758\n",
      "current run: (6, 16), epoch: 275, Loss: 0.0009722044548593704\n",
      "current RMS: 0.0839940286459173, best RMS: 0.0839940286459173\n",
      "current run: (6, 16), epoch: 300, Loss: 0.0008253779751241256\n",
      "current RMS: 0.07985734954113718, best RMS: 0.07985734954113718\n",
      "current run: (6, 16), epoch: 325, Loss: 0.000784368585742916\n",
      "current RMS: 0.07840873953767262, best RMS: 0.07840873953767262\n",
      "current run: (6, 16), epoch: 350, Loss: 0.0007651958344788268\n",
      "current RMS: 0.07760767669970889, best RMS: 0.07760767669970889\n",
      "current run: (6, 16), epoch: 375, Loss: 0.0007505498928182714\n",
      "current RMS: 0.07698437162315974, best RMS: 0.07698437162315974\n",
      "current run: (6, 16), epoch: 400, Loss: 0.0007375795763381911\n",
      "current RMS: 0.07644247857940854, best RMS: 0.07644247857940854\n",
      "current run: (6, 16), epoch: 425, Loss: 0.0007257086054281785\n",
      "current RMS: 0.07595421298562903, best RMS: 0.07595421298562903\n",
      "current run: (6, 16), epoch: 450, Loss: 0.0007146945759374739\n",
      "current RMS: 0.07550585301160287, best RMS: 0.07550585301160287\n",
      "current run: (6, 16), epoch: 475, Loss: 0.0007043915130517217\n",
      "current RMS: 0.07508872175338031, best RMS: 0.07508872175338031\n",
      "current run: (6, 16), epoch: 500, Loss: 0.0006947085324690544\n",
      "current RMS: 0.07469706045173088, best RMS: 0.07469706045173088\n",
      "current run: (6, 16), sim NRMS: 0.31271100536238505\n",
      "current run: (6, 17), epoch: 25, Loss: 0.10600421731009205\n",
      "current RMS: 0.6643075488046895, best RMS: 0.6643075488046895\n",
      "current run: (6, 17), epoch: 50, Loss: 0.06400296606899641\n",
      "current RMS: 0.5217907820533841, best RMS: 0.5217907820533841\n",
      "current run: (6, 17), epoch: 75, Loss: 0.053130273098181\n",
      "current RMS: 0.47587831050164825, best RMS: 0.47587831050164825\n",
      "current run: (6, 17), epoch: 100, Loss: 0.04541666370889447\n",
      "current RMS: 0.44026849374415583, best RMS: 0.44026849374415583\n",
      "current run: (6, 17), epoch: 125, Loss: 0.03739810114950679\n",
      "current RMS: 0.40015400527040373, best RMS: 0.40015400527040373\n",
      "current run: (6, 17), epoch: 150, Loss: 0.029309850049391392\n",
      "current RMS: 0.3549408070810865, best RMS: 0.3549408070810865\n",
      "current run: (6, 17), epoch: 175, Loss: 0.021521005253326057\n",
      "current RMS: 0.3052924419872535, best RMS: 0.3052924419872535\n",
      "current run: (6, 17), epoch: 200, Loss: 0.01457170057890425\n",
      "current RMS: 0.2530643509593618, best RMS: 0.2530643509593618\n",
      "current run: (6, 17), epoch: 225, Loss: 0.008990927255722245\n",
      "current RMS: 0.2017072849239421, best RMS: 0.2017072849239421\n",
      "current run: (6, 17), epoch: 250, Loss: 0.005072804578680089\n",
      "current RMS: 0.15591614550275668, best RMS: 0.15591614550275668\n",
      "current run: (6, 17), epoch: 275, Loss: 0.0027252855072188837\n",
      "current RMS: 0.1202844097619538, best RMS: 0.1202844097619538\n",
      "current run: (6, 17), epoch: 300, Loss: 0.0015409525785655112\n",
      "current RMS: 0.09717600832921568, best RMS: 0.09717600832921568\n",
      "current run: (6, 17), epoch: 325, Loss: 0.0010366503958938425\n",
      "current RMS: 0.0850855930390469, best RMS: 0.0850855930390469\n",
      "current run: (6, 17), epoch: 350, Loss: 0.0008503518024296731\n",
      "current RMS: 0.07983717915795865, best RMS: 0.07983717915795865\n",
      "current run: (6, 17), epoch: 375, Loss: 0.0007855872775012387\n",
      "current RMS: 0.07770745715197204, best RMS: 0.07770745715197204\n",
      "current run: (6, 17), epoch: 400, Loss: 0.0007599912472733005\n",
      "current RMS: 0.07673014866892686, best RMS: 0.07673014866892686\n",
      "current run: (6, 17), epoch: 425, Loss: 0.0007456348445210315\n",
      "current RMS: 0.07614449488150599, best RMS: 0.07614449488150599\n",
      "current run: (6, 17), epoch: 450, Loss: 0.0007345514632772315\n",
      "current RMS: 0.0757005257413008, best RMS: 0.0757005257413008\n",
      "current run: (6, 17), epoch: 475, Loss: 0.0007247331993355277\n",
      "current RMS: 0.07531913755486926, best RMS: 0.07531913755486926\n",
      "current run: (6, 17), epoch: 500, Loss: 0.000715678847733444\n",
      "current RMS: 0.07497283247964684, best RMS: 0.07497283247964684\n",
      "current run: (6, 17), sim NRMS: 0.33376999690105913\n",
      "current run: (6, 18), epoch: 25, Loss: 0.10338042356248035\n",
      "current RMS: 0.6587075583493892, best RMS: 0.6587075583493892\n",
      "current run: (6, 18), epoch: 50, Loss: 0.0695176157694548\n",
      "current RMS: 0.5460407955154992, best RMS: 0.5460407955154992\n",
      "current run: (6, 18), epoch: 75, Loss: 0.06069821194130745\n",
      "current RMS: 0.5098172139897993, best RMS: 0.5098172139897993\n",
      "current run: (6, 18), epoch: 100, Loss: 0.05297388681481623\n",
      "current RMS: 0.47707164891001913, best RMS: 0.47707164891001913\n",
      "current run: (6, 18), epoch: 125, Loss: 0.045499601773168884\n",
      "current RMS: 0.4424963701320281, best RMS: 0.4424963701320281\n",
      "current run: (6, 18), epoch: 150, Loss: 0.038169940401325334\n",
      "current RMS: 0.4057085127914118, best RMS: 0.4057085127914118\n",
      "current run: (6, 18), epoch: 175, Loss: 0.031042547974299613\n",
      "current RMS: 0.36652515036711913, best RMS: 0.36652515036711913\n",
      "current run: (6, 18), epoch: 200, Loss: 0.024266230256926244\n",
      "current RMS: 0.325023044015248, best RMS: 0.325023044015248\n",
      "current run: (6, 18), epoch: 225, Loss: 0.018065966441810657\n",
      "current RMS: 0.28185955023680265, best RMS: 0.28185955023680265\n",
      "current run: (6, 18), epoch: 250, Loss: 0.012701696712118961\n",
      "current RMS: 0.23839850929430156, best RMS: 0.23839850929430156\n",
      "current run: (6, 18), epoch: 275, Loss: 0.008396190113994543\n",
      "current RMS: 0.19675298634700597, best RMS: 0.19675298634700597\n",
      "current run: (6, 18), epoch: 300, Loss: 0.005247498164965885\n",
      "current RMS: 0.1595348918756539, best RMS: 0.1595348918756539\n",
      "current run: (6, 18), epoch: 325, Loss: 0.003178059797580057\n",
      "current RMS: 0.12922268946534093, best RMS: 0.12922268946534093\n",
      "current run: (6, 18), epoch: 350, Loss: 0.0019644852770200967\n",
      "current RMS: 0.10728503239998476, best RMS: 0.10728503239998476\n",
      "current run: (6, 18), epoch: 375, Loss: 0.0013289298171625754\n",
      "current RMS: 0.09345464807000585, best RMS: 0.09345464807000585\n",
      "current run: (6, 18), epoch: 400, Loss: 0.0010283249843562991\n",
      "current RMS: 0.08583645906959353, best RMS: 0.08583645906959353\n",
      "current run: (6, 18), epoch: 425, Loss: 0.000896317168762837\n",
      "current RMS: 0.08201450882756993, best RMS: 0.08201450882756993\n",
      "current run: (6, 18), epoch: 450, Loss: 0.0008392563934032703\n",
      "current RMS: 0.08012216855036818, best RMS: 0.08012216855036818\n",
      "current run: (6, 18), epoch: 475, Loss: 0.000812265214760962\n",
      "current RMS: 0.07909937803581348, best RMS: 0.07909937803581348\n",
      "current run: (6, 18), epoch: 500, Loss: 0.0007965297250365306\n",
      "current RMS: 0.07844982505189471, best RMS: 0.07844982505189471\n",
      "current run: (6, 18), sim NRMS: 0.31894904493130244\n",
      "current run: (6, 19), epoch: 25, Loss: 0.1308416970155353\n",
      "current RMS: 0.7360094856316941, best RMS: 0.7360094856316941\n",
      "current run: (6, 19), epoch: 50, Loss: 0.07377095692120211\n",
      "current RMS: 0.5618441173383283, best RMS: 0.5618441173383283\n",
      "current run: (6, 19), epoch: 75, Loss: 0.05976942185085666\n",
      "current RMS: 0.5077562809059122, best RMS: 0.5077562809059122\n",
      "current run: (6, 19), epoch: 100, Loss: 0.05391392689391714\n",
      "current RMS: 0.48223828165735744, best RMS: 0.48223828165735744\n",
      "current run: (6, 19), epoch: 125, Loss: 0.04862869520968569\n",
      "current RMS: 0.45822520366505715, best RMS: 0.45822520366505715\n",
      "current run: (6, 19), epoch: 150, Loss: 0.043240458634250446\n",
      "current RMS: 0.43241592217892444, best RMS: 0.43241592217892444\n",
      "current run: (6, 19), epoch: 175, Loss: 0.03775564939675131\n",
      "current RMS: 0.4044586034751821, best RMS: 0.4044586034751821\n",
      "current run: (6, 19), epoch: 200, Loss: 0.032229607456567715\n",
      "current RMS: 0.37423406019190514, best RMS: 0.37423406019190514\n",
      "current run: (6, 19), epoch: 225, Loss: 0.026759538729321505\n",
      "current RMS: 0.34174422376349645, best RMS: 0.34174422376349645\n",
      "current run: (6, 19), epoch: 250, Loss: 0.021489664975227977\n",
      "current RMS: 0.307261005218899, best RMS: 0.307261005218899\n",
      "current run: (6, 19), epoch: 275, Loss: 0.016600460967170362\n",
      "current RMS: 0.27142970493798285, best RMS: 0.27142970493798285\n",
      "current run: (6, 19), epoch: 300, Loss: 0.012279935078004338\n",
      "current RMS: 0.2353098567083247, best RMS: 0.2353098567083247\n",
      "current run: (6, 19), epoch: 325, Loss: 0.00868224451564555\n",
      "current RMS: 0.20033886758784372, best RMS: 0.20033886758784372\n",
      "current run: (6, 19), epoch: 350, Loss: 0.005886205641834065\n",
      "current RMS: 0.16817347959162854, best RMS: 0.16817347959162854\n",
      "current run: (6, 19), epoch: 375, Loss: 0.0038728765691071424\n",
      "current RMS: 0.1404132058673538, best RMS: 0.1404132058673538\n",
      "current run: (6, 19), epoch: 400, Loss: 0.002535264989554816\n",
      "current RMS: 0.11823949554292999, best RMS: 0.11823949554292999\n",
      "current run: (6, 19), epoch: 425, Loss: 0.0017155633815940188\n",
      "current RMS: 0.10206276901392966, best RMS: 0.10206276901392966\n",
      "current run: (6, 19), epoch: 450, Loss: 0.001250387724568116\n",
      "current RMS: 0.09135975746946522, best RMS: 0.09135975746946522\n",
      "current run: (6, 19), epoch: 475, Loss: 0.0010037239852783914\n",
      "current RMS: 0.08489165052820291, best RMS: 0.08489165052820291\n",
      "current run: (6, 19), epoch: 500, Loss: 0.0008795164461662523\n",
      "current RMS: 0.08122610303659611, best RMS: 0.08122610303659611\n",
      "current run: (6, 19), sim NRMS: 0.2965187818157026. This is better than last sim best:0.30014231312149425>0.2965187818157026\n",
      "current run: (6, 20), epoch: 25, Loss: 0.12263176293194457\n",
      "current RMS: 0.7153237456450737, best RMS: 0.7153237456450737\n",
      "current run: (6, 20), epoch: 50, Loss: 0.0699668647328789\n",
      "current RMS: 0.5492742882983873, best RMS: 0.5492742882983873\n",
      "current run: (6, 20), epoch: 75, Loss: 0.058262363808251054\n",
      "current RMS: 0.5029294642528213, best RMS: 0.5029294642528213\n",
      "current run: (6, 20), epoch: 100, Loss: 0.05227608646339708\n",
      "current RMS: 0.4766943122006101, best RMS: 0.4766943122006101\n",
      "current run: (6, 20), epoch: 125, Loss: 0.046857194893243435\n",
      "current RMS: 0.4516072762934209, best RMS: 0.4516072762934209\n",
      "current run: (6, 20), epoch: 150, Loss: 0.041468884449887056\n",
      "current RMS: 0.42529212406500394, best RMS: 0.42529212406500394\n",
      "current run: (6, 20), epoch: 175, Loss: 0.03608818123664004\n",
      "current RMS: 0.3973014671470224, best RMS: 0.3973014671470224\n",
      "current run: (6, 20), epoch: 200, Loss: 0.03074928572294345\n",
      "current RMS: 0.3674585183571436, best RMS: 0.3674585183571436\n",
      "current run: (6, 20), epoch: 225, Loss: 0.025524138045805087\n",
      "current RMS: 0.3357308422511317, best RMS: 0.3357308422511317\n",
      "current run: (6, 20), epoch: 250, Loss: 0.02052654721264205\n",
      "current RMS: 0.3023180293564069, best RMS: 0.3023180293564069\n",
      "current run: (6, 20), epoch: 275, Loss: 0.015905844994366678\n",
      "current RMS: 0.2677645853042772, best RMS: 0.2677645853042772\n",
      "current run: (6, 20), epoch: 300, Loss: 0.011823875371114007\n",
      "current RMS: 0.23301677524894884, best RMS: 0.23301677524894884\n",
      "current run: (6, 20), epoch: 325, Loss: 0.008417378963081226\n",
      "current RMS: 0.19939719960152535, best RMS: 0.19939719960152535\n",
      "current run: (6, 20), epoch: 350, Loss: 0.0057585765323874445\n",
      "current RMS: 0.1684585790347286, best RMS: 0.1684585790347286\n",
      "current run: (6, 20), epoch: 375, Loss: 0.003832501306822594\n",
      "current RMS: 0.14171682509788383, best RMS: 0.14171682509788383\n",
      "current run: (6, 20), epoch: 400, Loss: 0.002543462169629578\n",
      "current RMS: 0.12030033372994184, best RMS: 0.12030033372994184\n",
      "current run: (6, 20), epoch: 425, Loss: 0.0017472160642358716\n",
      "current RMS: 0.10460753684740269, best RMS: 0.10460753684740269\n",
      "current run: (6, 20), epoch: 450, Loss: 0.0012917732318171366\n",
      "current RMS: 0.09415024265041562, best RMS: 0.09415024265041562\n",
      "current run: (6, 20), epoch: 475, Loss: 0.0010485086809807118\n",
      "current RMS: 0.08776263821452202, best RMS: 0.08776263821452202\n",
      "current run: (6, 20), epoch: 500, Loss: 0.0009252400777752304\n",
      "current RMS: 0.08409257032243077, best RMS: 0.08409257032243077\n",
      "current run: (6, 20), sim NRMS: 0.2910511430701576. This is better than last sim best:0.2965187818157026>0.2910511430701576\n",
      "current run: (6, 21), epoch: 25, Loss: 0.1017540501353017\n",
      "current RMS: 0.6526727046510022, best RMS: 0.6526727046510022\n",
      "current run: (6, 21), epoch: 50, Loss: 0.0613636031993099\n",
      "current RMS: 0.5151784979662355, best RMS: 0.5151784979662355\n",
      "current run: (6, 21), epoch: 75, Loss: 0.05488091090488398\n",
      "current RMS: 0.4870319063634139, best RMS: 0.4870319063634139\n",
      "current run: (6, 21), epoch: 100, Loss: 0.0491182731746683\n",
      "current RMS: 0.4616495577515414, best RMS: 0.4616495577515414\n",
      "current run: (6, 21), epoch: 125, Loss: 0.04320661683249019\n",
      "current RMS: 0.4334420891673897, best RMS: 0.4334420891673897\n",
      "current run: (6, 21), epoch: 150, Loss: 0.03702550996970054\n",
      "current RMS: 0.40169097077795, best RMS: 0.40169097077795\n",
      "current run: (6, 21), epoch: 175, Loss: 0.030656548758970226\n",
      "current RMS: 0.36625022060133583, best RMS: 0.36625022060133583\n",
      "current run: (6, 21), epoch: 200, Loss: 0.024279499551293122\n",
      "current RMS: 0.3270045707394206, best RMS: 0.3270045707394206\n",
      "current run: (6, 21), epoch: 225, Loss: 0.018183769318399132\n",
      "current RMS: 0.2845924420086729, best RMS: 0.2845924420086729\n",
      "current run: (6, 21), epoch: 250, Loss: 0.012742840772601464\n",
      "current RMS: 0.2405963387416928, best RMS: 0.2405963387416928\n",
      "current run: (6, 21), epoch: 275, Loss: 0.008310781473480036\n",
      "current RMS: 0.1976749251814444, best RMS: 0.1976749251814444\n",
      "current run: (6, 21), epoch: 300, Loss: 0.005078737955415941\n",
      "current RMS: 0.15914382139737818, best RMS: 0.15914382139737818\n",
      "current run: (6, 21), epoch: 325, Loss: 0.002998441713612337\n",
      "current RMS: 0.12811494329897796, best RMS: 0.12811494329897796\n",
      "current run: (6, 21), epoch: 350, Loss: 0.0018260072663168771\n",
      "current RMS: 0.10633581218948372, best RMS: 0.10633581218948372\n",
      "current run: (6, 21), epoch: 375, Loss: 0.0012463043595214872\n",
      "current RMS: 0.09326615347125138, best RMS: 0.09326615347125138\n",
      "current run: (6, 21), epoch: 400, Loss: 0.0009902828681865687\n",
      "current RMS: 0.0864546778343001, best RMS: 0.0864546778343001\n",
      "current run: (6, 21), epoch: 425, Loss: 0.0008844108859841824\n",
      "current RMS: 0.08315218055374256, best RMS: 0.08315218055374256\n",
      "current run: (6, 21), epoch: 450, Loss: 0.000839033451155199\n",
      "current RMS: 0.08148354581683107, best RMS: 0.08148354581683107\n",
      "current run: (6, 21), epoch: 475, Loss: 0.0008155424862113461\n",
      "current RMS: 0.08050341593021561, best RMS: 0.08050341593021561\n",
      "current run: (6, 21), epoch: 500, Loss: 0.0007996231237698401\n",
      "current RMS: 0.07981322300976124, best RMS: 0.07981322300976124\n",
      "current run: (6, 21), sim NRMS: 0.3302688909279063\n",
      "current run: (6, 22), epoch: 25, Loss: 0.12114331073551249\n",
      "current RMS: 0.7138575082152929, best RMS: 0.7138575082152929\n",
      "current run: (6, 22), epoch: 50, Loss: 0.07187588065572868\n",
      "current RMS: 0.5571561526429251, best RMS: 0.5571561526429251\n",
      "current run: (6, 22), epoch: 75, Loss: 0.05719065233556427\n",
      "current RMS: 0.49946566362298733, best RMS: 0.49946566362298733\n",
      "current run: (6, 22), epoch: 100, Loss: 0.052189056480316805\n",
      "current RMS: 0.4771782080883885, best RMS: 0.4771782080883885\n",
      "current run: (6, 22), epoch: 125, Loss: 0.0484896954339007\n",
      "current RMS: 0.4599817570264239, best RMS: 0.4599817570264239\n",
      "current run: (6, 22), epoch: 150, Loss: 0.04471734882255435\n",
      "current RMS: 0.44218762801279354, best RMS: 0.44218762801279354\n",
      "current run: (6, 22), epoch: 175, Loss: 0.04081591151272234\n",
      "current RMS: 0.4229486833333478, best RMS: 0.4229486833333478\n",
      "current run: (6, 22), epoch: 200, Loss: 0.03678524105842336\n",
      "current RMS: 0.40205642252360074, best RMS: 0.40205642252360074\n",
      "current run: (6, 22), epoch: 225, Loss: 0.032643931630400136\n",
      "current RMS: 0.3793922652729185, best RMS: 0.3793922652729185\n",
      "current run: (6, 22), epoch: 250, Loss: 0.02843188893532876\n",
      "current RMS: 0.3548663465019821, best RMS: 0.3548663465019821\n",
      "current run: (6, 22), epoch: 275, Loss: 0.02421585803651616\n",
      "current RMS: 0.3284929606230058, best RMS: 0.3284929606230058\n",
      "current run: (6, 22), epoch: 300, Loss: 0.0200915008248083\n",
      "current RMS: 0.3004631802055908, best RMS: 0.3004631802055908\n",
      "current run: (6, 22), epoch: 325, Loss: 0.016178079087406955\n",
      "current RMS: 0.2711962276264405, best RMS: 0.2711962276264405\n",
      "current run: (6, 22), epoch: 350, Loss: 0.012604333222784234\n",
      "current RMS: 0.24136895473639983, best RMS: 0.24136895473639983\n",
      "current run: (6, 22), epoch: 375, Loss: 0.00948690962091196\n",
      "current RMS: 0.21190370329089367, best RMS: 0.21190370329089367\n",
      "current run: (6, 22), epoch: 400, Loss: 0.006906685312191284\n",
      "current RMS: 0.18389663994427868, best RMS: 0.18389663994427868\n",
      "current run: (6, 22), epoch: 425, Loss: 0.004891332885136917\n",
      "current RMS: 0.15848441420340328, best RMS: 0.15848441420340328\n",
      "current run: (6, 22), epoch: 450, Loss: 0.003411312297980973\n",
      "current RMS: 0.13666135618675332, best RMS: 0.13666135618675332\n",
      "current run: (6, 22), epoch: 475, Loss: 0.0023910294310892765\n",
      "current RMS: 0.11907728049680452, best RMS: 0.11907728049680452\n",
      "current run: (6, 22), epoch: 500, Loss: 0.0017301897382971613\n",
      "current RMS: 0.10587422919465499, best RMS: 0.10587422919465499\n",
      "current run: (6, 22), sim NRMS: 0.34998926310287976\n",
      "current run: (6, 23), epoch: 25, Loss: 0.11461001546210264\n",
      "current RMS: 0.6847184740688246, best RMS: 0.6847184740688246\n",
      "current run: (6, 23), epoch: 50, Loss: 0.06999595466853492\n",
      "current RMS: 0.5507190801755392, best RMS: 0.5507190801755392\n",
      "current run: (6, 23), epoch: 75, Loss: 0.056959237739523626\n",
      "current RMS: 0.49877990030824165, best RMS: 0.49877990030824165\n",
      "current run: (6, 23), epoch: 100, Loss: 0.05167126911293292\n",
      "current RMS: 0.4756212310224587, best RMS: 0.4756212310224587\n",
      "current run: (6, 23), epoch: 125, Loss: 0.04742386964780866\n",
      "current RMS: 0.4558284265479236, best RMS: 0.4558284265479236\n",
      "current run: (6, 23), epoch: 150, Loss: 0.04324530764440028\n",
      "current RMS: 0.4356596289634184, best RMS: 0.4356596289634184\n",
      "current run: (6, 23), epoch: 175, Loss: 0.039076077705761804\n",
      "current RMS: 0.4146431233745811, best RMS: 0.4146431233745811\n",
      "current run: (6, 23), epoch: 200, Loss: 0.03492796003818947\n",
      "current RMS: 0.3926099168132692, best RMS: 0.3926099168132692\n",
      "current run: (6, 23), epoch: 225, Loss: 0.030824631772703188\n",
      "current RMS: 0.36952743150007433, best RMS: 0.36952743150007433\n",
      "current run: (6, 23), epoch: 250, Loss: 0.026802077116165744\n",
      "current RMS: 0.3454191261950747, best RMS: 0.3454191261950747\n",
      "current run: (6, 23), epoch: 275, Loss: 0.02290932095131607\n",
      "current RMS: 0.32037719869521386, best RMS: 0.32037719869521386\n",
      "current run: (6, 23), epoch: 300, Loss: 0.019207327251421907\n",
      "current RMS: 0.29460058047795606, best RMS: 0.29460058047795606\n",
      "current run: (6, 23), epoch: 325, Loss: 0.01576447795495365\n",
      "current RMS: 0.2684138012877178, best RMS: 0.2684138012877178\n",
      "current run: (6, 23), epoch: 350, Loss: 0.012648638695178394\n",
      "current RMS: 0.24227122112156416, best RMS: 0.24227122112156416\n",
      "current run: (6, 23), epoch: 375, Loss: 0.009917144977902123\n",
      "current RMS: 0.2167408232356243, best RMS: 0.2167408232356243\n",
      "current run: (6, 23), epoch: 400, Loss: 0.007607109877057182\n",
      "current RMS: 0.19246583000513878, best RMS: 0.19246583000513878\n",
      "current run: (6, 23), epoch: 425, Loss: 0.005728784491489702\n",
      "current RMS: 0.17010494291348763, best RMS: 0.17010494291348763\n",
      "current run: (6, 23), epoch: 450, Loss: 0.004263981365305633\n",
      "current RMS: 0.15025570686647852, best RMS: 0.15025570686647852\n",
      "current run: (6, 23), epoch: 475, Loss: 0.0031700161854955325\n",
      "current RMS: 0.1333691549200773, best RMS: 0.1333691549200773\n",
      "current run: (6, 23), epoch: 500, Loss: 0.0023878750540576935\n",
      "current RMS: 0.11967069357186548, best RMS: 0.11967069357186548\n",
      "current run: (6, 23), sim NRMS: 0.37241240059055625\n",
      "current run: (6, 24), epoch: 25, Loss: 0.09968574861554728\n",
      "current RMS: 0.6459139830925604, best RMS: 0.6459139830925604\n",
      "current run: (6, 24), epoch: 50, Loss: 0.05722765667126836\n",
      "current RMS: 0.4976039050544127, best RMS: 0.4976039050544127\n",
      "current run: (6, 24), epoch: 75, Loss: 0.05129333453273882\n",
      "current RMS: 0.4709339682731125, best RMS: 0.4709339682731125\n",
      "current run: (6, 24), epoch: 100, Loss: 0.04475059719639809\n",
      "current RMS: 0.4408060848225001, best RMS: 0.4408060848225001\n",
      "current run: (6, 24), epoch: 125, Loss: 0.03752574215179717\n",
      "current RMS: 0.40369606871735053, best RMS: 0.40369606871735053\n",
      "current run: (6, 24), epoch: 150, Loss: 0.02947566781643312\n",
      "current RMS: 0.3583165065394973, best RMS: 0.3583165065394973\n",
      "current run: (6, 24), epoch: 175, Loss: 0.021070037089715696\n",
      "current RMS: 0.30391898491326697, best RMS: 0.30391898491326697\n",
      "current run: (6, 24), epoch: 200, Loss: 0.013330636361916875\n",
      "current RMS: 0.24362965799507483, best RMS: 0.24362965799507483\n",
      "current run: (6, 24), epoch: 225, Loss: 0.007347960059006567\n",
      "current RMS: 0.18429010915822486, best RMS: 0.18429010915822486\n",
      "current run: (6, 24), epoch: 250, Loss: 0.003602366638606207\n",
      "current RMS: 0.13453293397118998, best RMS: 0.13453293397118998\n",
      "current run: (6, 24), epoch: 275, Loss: 0.001759804888891859\n",
      "current RMS: 0.10117956231624334, best RMS: 0.10117956231624334\n",
      "current run: (6, 24), epoch: 300, Loss: 0.0010589047334336476\n",
      "current RMS: 0.08453911176543266, best RMS: 0.08453911176543266\n",
      "current run: (6, 24), epoch: 325, Loss: 0.000845226008744935\n",
      "current RMS: 0.07823324638022314, best RMS: 0.07823324638022314\n",
      "current run: (6, 24), epoch: 350, Loss: 0.0007824293130713032\n",
      "current RMS: 0.07597932485561971, best RMS: 0.07597932485561971\n",
      "current run: (6, 24), epoch: 375, Loss: 0.0007552680886055235\n",
      "current RMS: 0.07491340772744215, best RMS: 0.07491340772744215\n",
      "current run: (6, 24), epoch: 400, Loss: 0.0007356606276828862\n",
      "current RMS: 0.07418304007825385, best RMS: 0.07418304007825385\n",
      "current run: (6, 24), epoch: 425, Loss: 0.0007184329923719534\n",
      "current RMS: 0.0735754764768286, best RMS: 0.0735754764768286\n",
      "current run: (6, 24), epoch: 450, Loss: 0.000702726635782393\n",
      "current RMS: 0.07303268700632547, best RMS: 0.07303268700632547\n",
      "current run: (6, 24), epoch: 475, Loss: 0.0006883002756918482\n",
      "current RMS: 0.07253415341650186, best RMS: 0.07253415341650186\n",
      "current run: (6, 24), epoch: 500, Loss: 0.0006749985697144833\n",
      "current RMS: 0.07207068733288104, best RMS: 0.07207068733288104\n",
      "current run: (6, 24), sim NRMS: 0.3327485933864183\n",
      "current run: (6, 25), epoch: 25, Loss: 0.1296388998748433\n",
      "current RMS: 0.7388669847065186, best RMS: 0.7388669847065186\n",
      "current run: (6, 25), epoch: 50, Loss: 0.07759448330403017\n",
      "current RMS: 0.5779056079450735, best RMS: 0.5779056079450735\n",
      "current run: (6, 25), epoch: 75, Loss: 0.061758382020925734\n",
      "current RMS: 0.5188157695023778, best RMS: 0.5188157695023778\n",
      "current run: (6, 25), epoch: 100, Loss: 0.05614699379155209\n",
      "current RMS: 0.49476766711698217, best RMS: 0.49476766711698217\n",
      "current run: (6, 25), epoch: 125, Loss: 0.05249572453695088\n",
      "current RMS: 0.47836181638858344, best RMS: 0.47836181638858344\n",
      "current run: (6, 25), epoch: 150, Loss: 0.048963953575576945\n",
      "current RMS: 0.46214251608382917, best RMS: 0.46214251608382917\n",
      "current run: (6, 25), epoch: 175, Loss: 0.045310976601993125\n",
      "current RMS: 0.44485212793291196, best RMS: 0.44485212793291196\n",
      "current run: (6, 25), epoch: 200, Loss: 0.041517482830280394\n",
      "current RMS: 0.4261655694277121, best RMS: 0.4261655694277121\n",
      "current run: (6, 25), epoch: 225, Loss: 0.037591470486433944\n",
      "current RMS: 0.4059236515056127, best RMS: 0.4059236515056127\n",
      "current run: (6, 25), epoch: 250, Loss: 0.03355550526707945\n",
      "current RMS: 0.38401488053618843, best RMS: 0.38401488053618843\n",
      "current run: (6, 25), epoch: 275, Loss: 0.029451833847058687\n",
      "current RMS: 0.36038691532031625, best RMS: 0.36038691532031625\n",
      "current run: (6, 25), epoch: 300, Loss: 0.025346426369575945\n",
      "current RMS: 0.3350963424353788, best RMS: 0.3350963424353788\n",
      "current run: (6, 25), epoch: 325, Loss: 0.02132792012463882\n",
      "current RMS: 0.3083470680314614, best RMS: 0.3083470680314614\n",
      "current run: (6, 25), epoch: 350, Loss: 0.017500400393247594\n",
      "current RMS: 0.28051399452539877, best RMS: 0.28051399452539877\n",
      "current run: (6, 25), epoch: 375, Loss: 0.013971644973619269\n",
      "current RMS: 0.2521500181824045, best RMS: 0.2521500181824045\n",
      "current run: (6, 25), epoch: 400, Loss: 0.010838570467606718\n",
      "current RMS: 0.22397205679998802, best RMS: 0.22397205679998802\n",
      "current run: (6, 25), epoch: 425, Loss: 0.008172197676058736\n",
      "current RMS: 0.19681883487220417, best RMS: 0.19681883487220417\n",
      "current run: (6, 25), epoch: 450, Loss: 0.006006054042669325\n",
      "current RMS: 0.17157872653228695, best RMS: 0.17157872653228695\n",
      "current run: (6, 25), epoch: 475, Loss: 0.004331675242242789\n",
      "current RMS: 0.14908946181349436, best RMS: 0.14908946181349436\n",
      "current run: (6, 25), epoch: 500, Loss: 0.0031027773459625448\n",
      "current RMS: 0.13001573534359898, best RMS: 0.13001573534359898\n",
      "current run: (6, 25), sim NRMS: 0.4018689037329389\n",
      "current run: (7, 14), epoch: 25, Loss: 0.1657851228755845\n",
      "current RMS: 0.8259737520817528, best RMS: 0.8259737520817528\n",
      "current run: (7, 14), epoch: 50, Loss: 0.09272319595801992\n",
      "current RMS: 0.6249176143000412, best RMS: 0.6249176143000412\n",
      "current run: (7, 14), epoch: 75, Loss: 0.0681599033596522\n",
      "current RMS: 0.5377533082005382, best RMS: 0.5377533082005382\n",
      "current run: (7, 14), epoch: 100, Loss: 0.055083435662431963\n",
      "current RMS: 0.4835234874129262, best RMS: 0.4835234874129262\n",
      "current run: (7, 14), epoch: 125, Loss: 0.04305939471316965\n",
      "current RMS: 0.4286279355100251, best RMS: 0.4286279355100251\n",
      "current run: (7, 14), epoch: 150, Loss: 0.031589227103085385\n",
      "current RMS: 0.3688995955282879, best RMS: 0.3688995955282879\n",
      "current run: (7, 14), epoch: 175, Loss: 0.021398507698431303\n",
      "current RMS: 0.30607401629404346, best RMS: 0.30607401629404346\n",
      "current run: (7, 14), epoch: 200, Loss: 0.013240047802561992\n",
      "current RMS: 0.24442335913994764, best RMS: 0.24442335913994764\n",
      "current run: (7, 14), epoch: 225, Loss: 0.007521859472212632\n",
      "current RMS: 0.18959508701334205, best RMS: 0.18959508701334205\n",
      "current run: (7, 14), epoch: 250, Loss: 0.004085072568514548\n",
      "current RMS: 0.14694032381054142, best RMS: 0.14694032381054142\n",
      "current run: (7, 14), epoch: 275, Loss: 0.002332493676910295\n",
      "current RMS: 0.11911916071626856, best RMS: 0.11911916071626856\n",
      "current run: (7, 14), epoch: 300, Loss: 0.0015719043216116\n",
      "current RMS: 0.10433966184284887, best RMS: 0.10433966184284887\n",
      "current run: (7, 14), epoch: 325, Loss: 0.0012839321616611799\n",
      "current RMS: 0.09776109363345373, best RMS: 0.09776109363345373\n",
      "current run: (7, 14), epoch: 350, Loss: 0.0011818298212406594\n",
      "current RMS: 0.09501036938544667, best RMS: 0.09501036938544667\n",
      "current run: (7, 14), epoch: 375, Loss: 0.0011417919707425903\n",
      "current RMS: 0.0937139630466511, best RMS: 0.0937139630466511\n",
      "current run: (7, 14), epoch: 400, Loss: 0.0011201694556306906\n",
      "current RMS: 0.09292270794379662, best RMS: 0.09292270794379662\n",
      "current run: (7, 14), epoch: 425, Loss: 0.0011039277020808047\n",
      "current RMS: 0.09231535976693352, best RMS: 0.09231535976693352\n",
      "current run: (7, 14), epoch: 450, Loss: 0.001089624159116183\n",
      "current RMS: 0.0917886256064537, best RMS: 0.0917886256064537\n",
      "current run: (7, 14), epoch: 475, Loss: 0.001076378285547121\n",
      "current RMS: 0.0913069301775332, best RMS: 0.0913069301775332\n",
      "current run: (7, 14), epoch: 500, Loss: 0.0010639202145511296\n",
      "current RMS: 0.09085589071421582, best RMS: 0.09085589071421582\n",
      "current run: (7, 14), sim NRMS: 0.3290562450614758\n",
      "current run: (7, 15), epoch: 25, Loss: 0.14983428726257145\n",
      "current RMS: 0.7876836491133885, best RMS: 0.7876836491133885\n",
      "current run: (7, 15), epoch: 50, Loss: 0.08863929046055706\n",
      "current RMS: 0.6105633742074988, best RMS: 0.6105633742074988\n",
      "current run: (7, 15), epoch: 75, Loss: 0.06960979388522325\n",
      "current RMS: 0.5416139695404426, best RMS: 0.5416139695404426\n",
      "current run: (7, 15), epoch: 100, Loss: 0.05370551258072494\n",
      "current RMS: 0.4767318876611937, best RMS: 0.4767318876611937\n",
      "current run: (7, 15), epoch: 125, Loss: 0.03764387699210019\n",
      "current RMS: 0.4003628955657213, best RMS: 0.4003628955657213\n",
      "current run: (7, 15), epoch: 150, Loss: 0.023008916802958405\n",
      "current RMS: 0.31515415701658844, best RMS: 0.31515415701658844\n",
      "current run: (7, 15), epoch: 175, Loss: 0.011915039228410423\n",
      "current RMS: 0.23104496690193022, best RMS: 0.23104496690193022\n",
      "current run: (7, 15), epoch: 200, Loss: 0.005284290186955545\n",
      "current RMS: 0.16152780213428686, best RMS: 0.16152780213428686\n",
      "current run: (7, 15), epoch: 225, Loss: 0.002331172287706686\n",
      "current RMS: 0.11815080922635966, best RMS: 0.11815080922635966\n",
      "current run: (7, 15), epoch: 250, Loss: 0.001393683033728873\n",
      "current RMS: 0.10014502670265384, best RMS: 0.10014502670265384\n",
      "current run: (7, 15), epoch: 275, Loss: 0.0011749353947828464\n",
      "current RMS: 0.09500022933899127, best RMS: 0.09500022933899127\n",
      "current run: (7, 15), epoch: 300, Loss: 0.0011237649434271745\n",
      "current RMS: 0.09346680736290275, best RMS: 0.09346680736290275\n",
      "current run: (7, 15), epoch: 325, Loss: 0.0010996695664491174\n",
      "current RMS: 0.09264687411094391, best RMS: 0.09264687411094391\n",
      "current run: (7, 15), epoch: 350, Loss: 0.0010798611107171747\n",
      "current RMS: 0.09197741740591893, best RMS: 0.09197741740591893\n",
      "current run: (7, 15), epoch: 375, Loss: 0.0010617594813994236\n",
      "current RMS: 0.09136453661021497, best RMS: 0.09136453661021497\n",
      "current run: (7, 15), epoch: 400, Loss: 0.00104499122417823\n",
      "current RMS: 0.09078915034933548, best RMS: 0.09078915034933548\n",
      "current run: (7, 15), epoch: 425, Loss: 0.0010293844923534995\n",
      "current RMS: 0.09024576827258052, best RMS: 0.09024576827258052\n",
      "current run: (7, 15), epoch: 450, Loss: 0.0010148100834513508\n",
      "current RMS: 0.0897314973678592, best RMS: 0.0897314973678592\n",
      "current run: (7, 15), epoch: 475, Loss: 0.0010011585865769901\n",
      "current RMS: 0.0892437327055955, best RMS: 0.0892437327055955\n",
      "current run: (7, 15), epoch: 500, Loss: 0.000988333507243633\n",
      "current RMS: 0.08877996646168199, best RMS: 0.08877996646168199\n",
      "current run: (7, 15), sim NRMS: 0.318673668998818\n",
      "current run: (7, 16), epoch: 25, Loss: 0.11079263206883821\n",
      "current RMS: 0.6818081278005572, best RMS: 0.6818081278005572\n",
      "current run: (7, 16), epoch: 50, Loss: 0.07494195040819226\n",
      "current RMS: 0.564680701518261, best RMS: 0.564680701518261\n",
      "current run: (7, 16), epoch: 75, Loss: 0.06093331302296207\n",
      "current RMS: 0.5091215603326272, best RMS: 0.5091215603326272\n",
      "current run: (7, 16), epoch: 100, Loss: 0.04736367811500823\n",
      "current RMS: 0.4500467462379883, best RMS: 0.4500467462379883\n",
      "current run: (7, 16), epoch: 125, Loss: 0.034062089099154605\n",
      "current RMS: 0.38267707160106684, best RMS: 0.38267707160106684\n",
      "current run: (7, 16), epoch: 150, Loss: 0.021795218027326802\n",
      "current RMS: 0.30829377252003953, best RMS: 0.30829377252003953\n",
      "current run: (7, 16), epoch: 175, Loss: 0.01201917608256311\n",
      "current RMS: 0.23307703596164336, best RMS: 0.23307703596164336\n",
      "current run: (7, 16), epoch: 200, Loss: 0.005708591720916233\n",
      "current RMS: 0.16789856491332586, best RMS: 0.16789856491332586\n",
      "current run: (7, 16), epoch: 225, Loss: 0.00260647520218404\n",
      "current RMS: 0.12387613909473806, best RMS: 0.12387613909473806\n",
      "current run: (7, 16), epoch: 250, Loss: 0.0014965012316571476\n",
      "current RMS: 0.10319711688222953, best RMS: 0.10319711688222953\n",
      "current run: (7, 16), epoch: 275, Loss: 0.001205403260768292\n",
      "current RMS: 0.09649391832987225, best RMS: 0.09649391832987225\n",
      "current run: (7, 16), epoch: 300, Loss: 0.0011388657172638364\n",
      "current RMS: 0.09451563915936258, best RMS: 0.09451563915936258\n",
      "current run: (7, 16), epoch: 325, Loss: 0.0011147311850593345\n",
      "current RMS: 0.09361809526008473, best RMS: 0.09361809526008473\n",
      "current run: (7, 16), epoch: 350, Loss: 0.0010968728410178025\n",
      "current RMS: 0.09294792078317035, best RMS: 0.09294792078317035\n",
      "current run: (7, 16), epoch: 375, Loss: 0.001080487026351418\n",
      "current RMS: 0.09234825350478743, best RMS: 0.09234825350478743\n",
      "current run: (7, 16), epoch: 400, Loss: 0.0010650962674150402\n",
      "current RMS: 0.09178715078068124, best RMS: 0.09178715078068124\n",
      "current run: (7, 16), epoch: 425, Loss: 0.0010506000344581426\n",
      "current RMS: 0.0912558185019357, best RMS: 0.0912558185019357\n",
      "current run: (7, 16), epoch: 450, Loss: 0.0010369202333336176\n",
      "current RMS: 0.0907509301928164, best RMS: 0.0907509301928164\n",
      "current run: (7, 16), epoch: 475, Loss: 0.001023984604184686\n",
      "current RMS: 0.09027038057587611, best RMS: 0.09027038057587611\n",
      "current run: (7, 16), epoch: 500, Loss: 0.001011725629216882\n",
      "current RMS: 0.08981229805869965, best RMS: 0.08981229805869965\n",
      "current run: (7, 16), sim NRMS: 0.31674270993492126\n",
      "current run: (7, 17), epoch: 25, Loss: 0.12532396680494984\n",
      "current RMS: 0.7169724863541503, best RMS: 0.7169724863541503\n",
      "current run: (7, 17), epoch: 50, Loss: 0.07842942988381092\n",
      "current RMS: 0.5760249702708468, best RMS: 0.5760249702708468\n",
      "current run: (7, 17), epoch: 75, Loss: 0.06128305610254588\n",
      "current RMS: 0.5127332403155614, best RMS: 0.5127332403155614\n",
      "current run: (7, 17), epoch: 100, Loss: 0.05185056130892794\n",
      "current RMS: 0.4726391713686571, best RMS: 0.4726391713686571\n",
      "current run: (7, 17), epoch: 125, Loss: 0.04361728274623111\n",
      "current RMS: 0.43456138338262595, best RMS: 0.43456138338262595\n",
      "current run: (7, 17), epoch: 150, Loss: 0.03606932715271555\n",
      "current RMS: 0.39647555130744566, best RMS: 0.39647555130744566\n",
      "current run: (7, 17), epoch: 175, Loss: 0.02922904238720033\n",
      "current RMS: 0.3584278429080849, best RMS: 0.3584278429080849\n",
      "current run: (7, 17), epoch: 200, Loss: 0.023142363884539136\n",
      "current RMS: 0.3207475531975257, best RMS: 0.3207475531975257\n",
      "current run: (7, 17), epoch: 225, Loss: 0.017865200737000854\n",
      "current RMS: 0.28402643157322816, best RMS: 0.28402643157322816\n",
      "current run: (7, 17), epoch: 250, Loss: 0.013437189704120629\n",
      "current RMS: 0.24901745149749724, best RMS: 0.24901745149749724\n",
      "current run: (7, 17), epoch: 275, Loss: 0.009861486973863565\n",
      "current RMS: 0.2165791875373178, best RMS: 0.2165791875373178\n",
      "current run: (7, 17), epoch: 300, Loss: 0.007095461581345263\n",
      "current RMS: 0.18757152109887829, best RMS: 0.18757152109887829\n",
      "current run: (7, 17), epoch: 325, Loss: 0.0050530989062989844\n",
      "current RMS: 0.16272979567203283, best RMS: 0.16272979567203283\n",
      "current run: (7, 17), epoch: 350, Loss: 0.0036171431417410583\n",
      "current RMS: 0.14252419052062484, best RMS: 0.14252419052062484\n",
      "current run: (7, 17), epoch: 375, Loss: 0.0026567428903603984\n",
      "current RMS: 0.12703225282199676, best RMS: 0.12703225282199676\n",
      "current run: (7, 17), epoch: 400, Loss: 0.002045238460549315\n",
      "current RMS: 0.11588347907481808, best RMS: 0.11588347907481808\n",
      "current run: (7, 17), epoch: 425, Loss: 0.0016734712913023951\n",
      "current RMS: 0.1083371702397968, best RMS: 0.1083371702397968\n",
      "current run: (7, 17), epoch: 450, Loss: 0.0014563732896506229\n",
      "current RMS: 0.10348235538828394, best RMS: 0.10348235538828394\n",
      "current run: (7, 17), epoch: 475, Loss: 0.0013333100894197547\n",
      "current RMS: 0.10045677507774745, best RMS: 0.10045677507774745\n",
      "current run: (7, 17), epoch: 500, Loss: 0.0012643718456628815\n",
      "current RMS: 0.09858125007949946, best RMS: 0.09858125007949946\n",
      "current run: (7, 17), sim NRMS: 0.3050002357700557\n",
      "current run: (7, 18), epoch: 25, Loss: 0.15733831443131366\n",
      "current RMS: 0.8098043898374415, best RMS: 0.8098043898374415\n",
      "current run: (7, 18), epoch: 50, Loss: 0.08492454008231533\n",
      "current RMS: 0.6023569777355541, best RMS: 0.6023569777355541\n",
      "current run: (7, 18), epoch: 75, Loss: 0.06256361070781796\n",
      "current RMS: 0.5196157264208809, best RMS: 0.5196157264208809\n",
      "current run: (7, 18), epoch: 100, Loss: 0.05377757380403606\n",
      "current RMS: 0.48199323009226025, best RMS: 0.48199323009226025\n",
      "current run: (7, 18), epoch: 125, Loss: 0.04657338875389318\n",
      "current RMS: 0.44926728845757213, best RMS: 0.44926728845757213\n",
      "current run: (7, 18), epoch: 150, Loss: 0.039277722533250514\n",
      "current RMS: 0.41362424503338996, best RMS: 0.41362424503338996\n",
      "current run: (7, 18), epoch: 175, Loss: 0.031949952544304154\n",
      "current RMS: 0.37436776789707715, best RMS: 0.37436776789707715\n",
      "current run: (7, 18), epoch: 200, Loss: 0.024812296084023664\n",
      "current RMS: 0.3316672740648495, best RMS: 0.3316672740648495\n",
      "current run: (7, 18), epoch: 225, Loss: 0.01822525877749104\n",
      "current RMS: 0.2866931486696516, best RMS: 0.2866931486696516\n",
      "current run: (7, 18), epoch: 250, Loss: 0.012584593819104447\n",
      "current RMS: 0.24163163801803753, best RMS: 0.24163163801803753\n",
      "current run: (7, 18), epoch: 275, Loss: 0.008183257749533534\n",
      "current RMS: 0.19949513419816117, best RMS: 0.19949513419816117\n",
      "current run: (7, 18), epoch: 300, Loss: 0.005101755415280525\n",
      "current RMS: 0.1635297028439418, best RMS: 0.1635297028439418\n",
      "current run: (7, 18), epoch: 325, Loss: 0.003186119035823021\n",
      "current RMS: 0.1362047116261686, best RMS: 0.1362047116261686\n",
      "current run: (7, 18), epoch: 350, Loss: 0.0021323116912433334\n",
      "current RMS: 0.11813830565280935, best RMS: 0.11813830565280935\n",
      "current run: (7, 18), epoch: 375, Loss: 0.0016162484737864595\n",
      "current RMS: 0.10778685231484016, best RMS: 0.10778685231484016\n",
      "current run: (7, 18), epoch: 400, Loss: 0.0013865213037212573\n",
      "current RMS: 0.10247368403148091, best RMS: 0.10247368403148091\n",
      "current run: (7, 18), epoch: 425, Loss: 0.0012888208248875534\n",
      "current RMS: 0.09983426351200678, best RMS: 0.09983426351200678\n",
      "current run: (7, 18), epoch: 450, Loss: 0.0012449134735938294\n",
      "current RMS: 0.09842256199974733, best RMS: 0.09842256199974733\n",
      "current run: (7, 18), epoch: 475, Loss: 0.0012209903327275605\n",
      "current RMS: 0.09753831505149319, best RMS: 0.09753831505149319\n",
      "current run: (7, 18), epoch: 500, Loss: 0.0012042378719879995\n",
      "current RMS: 0.09688636409721338, best RMS: 0.09688636409721338\n",
      "current run: (7, 18), sim NRMS: 0.3268369446796876\n",
      "current run: (7, 19), epoch: 25, Loss: 0.10160478759991398\n",
      "current RMS: 0.6529940694124138, best RMS: 0.6529940694124138\n",
      "current run: (7, 19), epoch: 50, Loss: 0.06147163366700767\n",
      "current RMS: 0.5142071941109019, best RMS: 0.5142071941109019\n",
      "current run: (7, 19), epoch: 75, Loss: 0.051946229046109536\n",
      "current RMS: 0.4731537457839976, best RMS: 0.4731537457839976\n",
      "current run: (7, 19), epoch: 100, Loss: 0.043459362773755186\n",
      "current RMS: 0.4344148531392132, best RMS: 0.4344148531392132\n",
      "current run: (7, 19), epoch: 125, Loss: 0.03496516916107465\n",
      "current RMS: 0.39076495490333285, best RMS: 0.39076495490333285\n",
      "current run: (7, 19), epoch: 150, Loss: 0.026375930974715155\n",
      "current RMS: 0.3409958317914191, best RMS: 0.3409958317914191\n",
      "current run: (7, 19), epoch: 175, Loss: 0.018174641733044825\n",
      "current RMS: 0.2854639399888515, best RMS: 0.2854639399888515\n",
      "current run: (7, 19), epoch: 200, Loss: 0.01116729965762171\n",
      "current RMS: 0.22754563412483206, best RMS: 0.22754563412483206\n",
      "current run: (7, 19), epoch: 225, Loss: 0.006092305813799871\n",
      "current RMS: 0.1739348876589156, best RMS: 0.1739348876589156\n",
      "current run: (7, 19), epoch: 250, Loss: 0.003114018735238209\n",
      "current RMS: 0.1324317929743115, best RMS: 0.1324317929743115\n",
      "current run: (7, 19), epoch: 275, Loss: 0.0017398289842860562\n",
      "current RMS: 0.10738841175150794, best RMS: 0.10738841175150794\n",
      "current run: (7, 19), epoch: 300, Loss: 0.0012437632709945976\n",
      "current RMS: 0.09605842415571422, best RMS: 0.09605842415571422\n",
      "current run: (7, 19), epoch: 325, Loss: 0.0010960498256466387\n",
      "current RMS: 0.09187977163064175, best RMS: 0.09187977163064175\n",
      "current run: (7, 19), epoch: 350, Loss: 0.001051134636484378\n",
      "current RMS: 0.09026970053075777, best RMS: 0.09026970053075777\n",
      "current run: (7, 19), epoch: 375, Loss: 0.001030015326898457\n",
      "current RMS: 0.0894191309046957, best RMS: 0.0894191309046957\n",
      "current run: (7, 19), epoch: 400, Loss: 0.0010140054168258866\n",
      "current RMS: 0.08880047644577381, best RMS: 0.08880047644577381\n",
      "current run: (7, 19), epoch: 425, Loss: 0.0009996391182042063\n",
      "current RMS: 0.08827075893932694, best RMS: 0.08827075893932694\n",
      "current run: (7, 19), epoch: 450, Loss: 0.0009862838730524987\n",
      "current RMS: 0.08778619196704963, best RMS: 0.08778619196704963\n",
      "current run: (7, 19), epoch: 475, Loss: 0.0009737349525267219\n",
      "current RMS: 0.08733114977248421, best RMS: 0.08733114977248421\n",
      "current run: (7, 19), epoch: 500, Loss: 0.0009618690344564533\n",
      "current RMS: 0.08689924395122192, best RMS: 0.08689924395122192\n",
      "current run: (7, 19), sim NRMS: 0.32241943518714866\n",
      "current run: (7, 20), epoch: 25, Loss: 0.09888330179390462\n",
      "current RMS: 0.6418329936388154, best RMS: 0.6418329936388154\n",
      "current run: (7, 20), epoch: 50, Loss: 0.05731519991473934\n",
      "current RMS: 0.498092806685594, best RMS: 0.498092806685594\n",
      "current run: (7, 20), epoch: 75, Loss: 0.04864542661335366\n",
      "current RMS: 0.460175064185761, best RMS: 0.460175064185761\n",
      "current run: (7, 20), epoch: 100, Loss: 0.042450842195521414\n",
      "current RMS: 0.430850186805815, best RMS: 0.430850186805815\n",
      "current run: (7, 20), epoch: 125, Loss: 0.036194435146118954\n",
      "current RMS: 0.39916574990572673, best RMS: 0.39916574990572673\n",
      "current run: (7, 20), epoch: 150, Loss: 0.029943332580117242\n",
      "current RMS: 0.3643865591406548, best RMS: 0.3643865591406548\n",
      "current run: (7, 20), epoch: 175, Loss: 0.023823709655751625\n",
      "current RMS: 0.32672731798156807, best RMS: 0.32672731798156807\n",
      "current run: (7, 20), epoch: 200, Loss: 0.01806625333147522\n",
      "current RMS: 0.286779742234969, best RMS: 0.286779742234969\n",
      "current run: (7, 20), epoch: 225, Loss: 0.012959009742839622\n",
      "current RMS: 0.24588580401612928, best RMS: 0.24588580401612928\n",
      "current run: (7, 20), epoch: 250, Loss: 0.00876890023161499\n",
      "current RMS: 0.20623942752301463, best RMS: 0.20623942752301463\n",
      "current run: (7, 20), epoch: 275, Loss: 0.005642776363525625\n",
      "current RMS: 0.17054552256533553, best RMS: 0.17054552256533553\n",
      "current run: (7, 20), epoch: 300, Loss: 0.003547816160062025\n",
      "current RMS: 0.14134135120481817, best RMS: 0.14134135120481817\n",
      "current run: (7, 20), epoch: 325, Loss: 0.0022944975019224293\n",
      "current RMS: 0.1200895644138226, best RMS: 0.1200895644138226\n",
      "current run: (7, 20), epoch: 350, Loss: 0.0016241081671231057\n",
      "current RMS: 0.10651572499549662, best RMS: 0.10651572499549662\n",
      "current run: (7, 20), epoch: 375, Loss: 0.0012997724619577646\n",
      "current RMS: 0.098829505244496, best RMS: 0.098829505244496\n",
      "current run: (7, 20), epoch: 400, Loss: 0.0011538999831950745\n",
      "current RMS: 0.09479878271024247, best RMS: 0.09479878271024247\n",
      "current run: (7, 20), epoch: 425, Loss: 0.0010893352743584046\n",
      "current RMS: 0.09269083911616031, best RMS: 0.09269083911616031\n",
      "current run: (7, 20), epoch: 450, Loss: 0.0010581895635561052\n",
      "current RMS: 0.09149381521413243, best RMS: 0.09149381521413243\n",
      "current run: (7, 20), epoch: 475, Loss: 0.0010398204635869348\n",
      "current RMS: 0.09071212480250157, best RMS: 0.09071212480250157\n",
      "current run: (7, 20), epoch: 500, Loss: 0.0010262622346218831\n",
      "current RMS: 0.09012534669414268, best RMS: 0.09012534669414268\n",
      "current run: (7, 20), sim NRMS: 0.31216103176846305\n",
      "current run: (7, 21), epoch: 25, Loss: 0.09879349486838962\n",
      "current RMS: 0.6456543314649963, best RMS: 0.6456543314649963\n",
      "current run: (7, 21), epoch: 50, Loss: 0.06258956967463772\n",
      "current RMS: 0.5213094835280381, best RMS: 0.5213094835280381\n",
      "current run: (7, 21), epoch: 75, Loss: 0.05432070744075068\n",
      "current RMS: 0.4864868671845046, best RMS: 0.4864868671845046\n",
      "current run: (7, 21), epoch: 100, Loss: 0.04815441215932244\n",
      "current RMS: 0.45884750416169506, best RMS: 0.45884750416169506\n",
      "current run: (7, 21), epoch: 125, Loss: 0.04185158886882063\n",
      "current RMS: 0.42880170104663196, best RMS: 0.42880170104663196\n",
      "current run: (7, 21), epoch: 150, Loss: 0.03521487662393497\n",
      "current RMS: 0.39440062903314643, best RMS: 0.39440062903314643\n",
      "current run: (7, 21), epoch: 175, Loss: 0.028300241460993518\n",
      "current RMS: 0.35502384750927146, best RMS: 0.35502384750927146\n",
      "current run: (7, 21), epoch: 200, Loss: 0.021374593849446216\n",
      "current RMS: 0.3105825070750248, best RMS: 0.3105825070750248\n",
      "current run: (7, 21), epoch: 225, Loss: 0.014927108633385571\n",
      "current RMS: 0.26247508886750676, best RMS: 0.26247508886750676\n",
      "current run: (7, 21), epoch: 250, Loss: 0.009538611195983537\n",
      "current RMS: 0.21402763298475597, best RMS: 0.21402763298475597\n",
      "current run: (7, 21), epoch: 275, Loss: 0.0056169608886217645\n",
      "current RMS: 0.17007921037625456, best RMS: 0.17007921037625456\n",
      "current run: (7, 21), epoch: 300, Loss: 0.0031886923921221793\n",
      "current RMS: 0.13547158613734459, best RMS: 0.13547158613734459\n",
      "current run: (7, 21), epoch: 325, Loss: 0.0019255092371971833\n",
      "current RMS: 0.11272727598286793, best RMS: 0.11272727598286793\n",
      "current run: (7, 21), epoch: 350, Loss: 0.0013715484183289377\n",
      "current RMS: 0.10047773126893153, best RMS: 0.10047773126893153\n",
      "current run: (7, 21), epoch: 375, Loss: 0.0011604644421199881\n",
      "current RMS: 0.0948371058532769, best RMS: 0.0948371058532769\n",
      "current run: (7, 21), epoch: 400, Loss: 0.0010842753424509294\n",
      "current RMS: 0.0923349112819139, best RMS: 0.0923349112819139\n",
      "current run: (7, 21), epoch: 425, Loss: 0.0010527620318468674\n",
      "current RMS: 0.09107961934096051, best RMS: 0.09107961934096051\n",
      "current run: (7, 21), epoch: 450, Loss: 0.0010344199003447963\n",
      "current RMS: 0.0902931403706826, best RMS: 0.0902931403706826\n",
      "current run: (7, 21), epoch: 475, Loss: 0.0010199971400371437\n",
      "current RMS: 0.08969515153504033, best RMS: 0.08969515153504033\n",
      "current run: (7, 21), epoch: 500, Loss: 0.0010070852714884543\n",
      "current RMS: 0.08918553812197258, best RMS: 0.08918553812197258\n",
      "current run: (7, 21), sim NRMS: 0.326697585760438\n",
      "current run: (7, 22), epoch: 25, Loss: 0.12044942654688116\n",
      "current RMS: 0.710994041952557, best RMS: 0.710994041952557\n",
      "current run: (7, 22), epoch: 50, Loss: 0.06544993136159657\n",
      "current RMS: 0.5321571364988926, best RMS: 0.5321571364988926\n",
      "current run: (7, 22), epoch: 75, Loss: 0.052119747308236104\n",
      "current RMS: 0.4767523716094314, best RMS: 0.4767523716094314\n",
      "current run: (7, 22), epoch: 100, Loss: 0.04600702057337221\n",
      "current RMS: 0.4490335712074291, best RMS: 0.4490335712074291\n",
      "current run: (7, 22), epoch: 125, Loss: 0.040284931367278405\n",
      "current RMS: 0.42126082437668155, best RMS: 0.42126082437668155\n",
      "current run: (7, 22), epoch: 150, Loss: 0.03422418343449033\n",
      "current RMS: 0.3895373920287478, best RMS: 0.3895373920287478\n",
      "current run: (7, 22), epoch: 175, Loss: 0.02783225484484656\n",
      "current RMS: 0.35282542039777354, best RMS: 0.35282542039777354\n",
      "current run: (7, 22), epoch: 200, Loss: 0.021316469791531387\n",
      "current RMS: 0.3108630592788467, best RMS: 0.3108630592788467\n",
      "current run: (7, 22), epoch: 225, Loss: 0.015103817484924021\n",
      "current RMS: 0.2646140377423217, best RMS: 0.2646140377423217\n",
      "current run: (7, 22), epoch: 250, Loss: 0.0097657502620694\n",
      "current RMS: 0.21696879300730174, best RMS: 0.21696879300730174\n",
      "current run: (7, 22), epoch: 275, Loss: 0.005781334007113651\n",
      "current RMS: 0.1727540413616233, best RMS: 0.1727540413616233\n",
      "current run: (7, 22), epoch: 300, Loss: 0.0032725382797450667\n",
      "current RMS: 0.13730847978549723, best RMS: 0.13730847978549723\n",
      "current run: (7, 22), epoch: 325, Loss: 0.001961802883523498\n",
      "current RMS: 0.11381016195068236, best RMS: 0.11381016195068236\n",
      "current run: (7, 22), epoch: 350, Loss: 0.0013930793533249704\n",
      "current RMS: 0.10121857499357825, best RMS: 0.10121857499357825\n",
      "current run: (7, 22), epoch: 375, Loss: 0.001182584832606812\n",
      "current RMS: 0.09555187198050404, best RMS: 0.09555187198050404\n",
      "current run: (7, 22), epoch: 400, Loss: 0.0011105980392010254\n",
      "current RMS: 0.09314767062122382, best RMS: 0.09314767062122382\n",
      "current run: (7, 22), epoch: 425, Loss: 0.0010830220989802057\n",
      "current RMS: 0.09201847302512309, best RMS: 0.09201847302512309\n",
      "current run: (7, 22), epoch: 450, Loss: 0.001067879417520074\n",
      "current RMS: 0.0913576223624475, best RMS: 0.0913576223624475\n",
      "current run: (7, 22), epoch: 475, Loss: 0.0010561270609950825\n",
      "current RMS: 0.09087705076265071, best RMS: 0.09087705076265071\n",
      "current run: (7, 22), epoch: 500, Loss: 0.001045523610387416\n",
      "current RMS: 0.09047398004135894, best RMS: 0.09047398004135894\n",
      "current run: (7, 22), sim NRMS: 0.320954050582985\n",
      "current run: (7, 23), epoch: 25, Loss: 0.10445925880617793\n",
      "current RMS: 0.6616269205749945, best RMS: 0.6616269205749945\n",
      "current run: (7, 23), epoch: 50, Loss: 0.059987950819526\n",
      "current RMS: 0.5094294055661397, best RMS: 0.5094294055661397\n",
      "current run: (7, 23), epoch: 75, Loss: 0.051667883125641446\n",
      "current RMS: 0.4732808835294028, best RMS: 0.4732808835294028\n",
      "current run: (7, 23), epoch: 100, Loss: 0.04384294231033701\n",
      "current RMS: 0.4375323636330471, best RMS: 0.4375323636330471\n",
      "current run: (7, 23), epoch: 125, Loss: 0.03526239314982699\n",
      "current RMS: 0.3936481422381585, best RMS: 0.3936481422381585\n",
      "current run: (7, 23), epoch: 150, Loss: 0.026019777106924682\n",
      "current RMS: 0.3398665672429402, best RMS: 0.3398665672429402\n",
      "current run: (7, 23), epoch: 175, Loss: 0.016999461331483123\n",
      "current RMS: 0.27742142799766184, best RMS: 0.27742142799766184\n",
      "current run: (7, 23), epoch: 200, Loss: 0.009529269385382812\n",
      "current RMS: 0.21216066777522413, best RMS: 0.21216066777522413\n",
      "current run: (7, 23), epoch: 225, Loss: 0.004615106109234829\n",
      "current RMS: 0.15466238273627142, best RMS: 0.15466238273627142\n",
      "current run: (7, 23), epoch: 250, Loss: 0.0022089004884972463\n",
      "current RMS: 0.1158238106967295, best RMS: 0.1158238106967295\n",
      "current run: (7, 23), epoch: 275, Loss: 0.00136780712675646\n",
      "current RMS: 0.09766870438371558, best RMS: 0.09766870438371558\n",
      "current run: (7, 23), epoch: 300, Loss: 0.001150441435540238\n",
      "current RMS: 0.09160983648164404, best RMS: 0.09160983648164404\n",
      "current run: (7, 23), epoch: 325, Loss: 0.0010937790739791043\n",
      "current RMS: 0.08961506744026751, best RMS: 0.08961506744026751\n",
      "current run: (7, 23), epoch: 350, Loss: 0.0010654958511368043\n",
      "current RMS: 0.08862431019998322, best RMS: 0.08862431019998322\n",
      "current run: (7, 23), epoch: 375, Loss: 0.0010420578215529547\n",
      "current RMS: 0.08788814332866954, best RMS: 0.08788814332866954\n",
      "current run: (7, 23), epoch: 400, Loss: 0.0010206899695743114\n",
      "current RMS: 0.087237808649134, best RMS: 0.087237808649134\n",
      "current run: (7, 23), epoch: 425, Loss: 0.0010010379775741447\n",
      "current RMS: 0.08663201282692816, best RMS: 0.08663201282692816\n",
      "current run: (7, 23), epoch: 450, Loss: 0.000982928720135207\n",
      "current RMS: 0.08606165996109737, best RMS: 0.08606165996109737\n",
      "current run: (7, 23), epoch: 475, Loss: 0.0009662094188772163\n",
      "current RMS: 0.08552520960565915, best RMS: 0.08552520960565915\n",
      "current run: (7, 23), epoch: 500, Loss: 0.0009507336854974853\n",
      "current RMS: 0.08502154261831803, best RMS: 0.08502154261831803\n",
      "current run: (7, 23), sim NRMS: 0.31381694936894367\n",
      "current run: (7, 24), epoch: 25, Loss: 0.11840095178034461\n",
      "current RMS: 0.7025311928137155, best RMS: 0.7025311928137155\n",
      "current run: (7, 24), epoch: 50, Loss: 0.06567789118720353\n",
      "current RMS: 0.5319356667555037, best RMS: 0.5319356667555037\n",
      "current run: (7, 24), epoch: 75, Loss: 0.05213548020210637\n",
      "current RMS: 0.47685361964013573, best RMS: 0.47685361964013573\n",
      "current run: (7, 24), epoch: 100, Loss: 0.046173305101804916\n",
      "current RMS: 0.4493957679245114, best RMS: 0.4493957679245114\n",
      "current run: (7, 24), epoch: 125, Loss: 0.04083127393204826\n",
      "current RMS: 0.4235843437928279, best RMS: 0.4235843437928279\n",
      "current run: (7, 24), epoch: 150, Loss: 0.035356172342465055\n",
      "current RMS: 0.39527411177546246, best RMS: 0.39527411177546246\n",
      "current run: (7, 24), epoch: 175, Loss: 0.029729940118506472\n",
      "current RMS: 0.3637341327047756, best RMS: 0.3637341327047756\n",
      "current run: (7, 24), epoch: 200, Loss: 0.024031737754966122\n",
      "current RMS: 0.3286145162915326, best RMS: 0.3286145162915326\n",
      "current run: (7, 24), epoch: 225, Loss: 0.018463174723196137\n",
      "current RMS: 0.2901516823052103, best RMS: 0.2901516823052103\n",
      "current run: (7, 24), epoch: 250, Loss: 0.013337792559741626\n",
      "current RMS: 0.24949303028438444, best RMS: 0.24949303028438444\n",
      "current run: (7, 24), epoch: 275, Loss: 0.009004196412538313\n",
      "current RMS: 0.20891901367884727, best RMS: 0.20891901367884727\n",
      "current run: (7, 24), epoch: 300, Loss: 0.005713493555209485\n",
      "current RMS: 0.17162370061288829, best RMS: 0.17162370061288829\n",
      "current run: (7, 24), epoch: 325, Loss: 0.003507829959384964\n",
      "current RMS: 0.1408843811405592, best RMS: 0.1408843811405592\n",
      "current run: (7, 24), epoch: 350, Loss: 0.002215042352725027\n",
      "current RMS: 0.11877967956117433, best RMS: 0.11877967956117433\n",
      "current run: (7, 24), epoch: 375, Loss: 0.001551994176013325\n",
      "current RMS: 0.10514661612251897, best RMS: 0.10514661612251897\n",
      "current run: (7, 24), epoch: 400, Loss: 0.0012502593044632876\n",
      "current RMS: 0.09784036490992984, best RMS: 0.09784036490992984\n",
      "current run: (7, 24), epoch: 425, Loss: 0.001123975592811348\n",
      "current RMS: 0.09423936881285147, best RMS: 0.09423936881285147\n",
      "current run: (7, 24), epoch: 450, Loss: 0.001071341379014313\n",
      "current RMS: 0.09244501981410004, best RMS: 0.09244501981410004\n",
      "current run: (7, 24), epoch: 475, Loss: 0.0010461483314970605\n",
      "current RMS: 0.09144218779172725, best RMS: 0.09144218779172725\n",
      "current run: (7, 24), epoch: 500, Loss: 0.0010304104723658756\n",
      "current RMS: 0.09077653854295502, best RMS: 0.09077653854295502\n",
      "current run: (7, 24), sim NRMS: 0.31952673123073316\n",
      "current run: (7, 25), epoch: 25, Loss: 0.1239923480834154\n",
      "current RMS: 0.7208275541494811, best RMS: 0.7208275541494811\n",
      "current run: (7, 25), epoch: 50, Loss: 0.06610126714109574\n",
      "current RMS: 0.534483396417961, best RMS: 0.534483396417961\n",
      "current run: (7, 25), epoch: 75, Loss: 0.05108859288381919\n",
      "current RMS: 0.47290023171254314, best RMS: 0.47290023171254314\n",
      "current run: (7, 25), epoch: 100, Loss: 0.04429179187734739\n",
      "current RMS: 0.44112350976102566, best RMS: 0.44112350976102566\n",
      "current run: (7, 25), epoch: 125, Loss: 0.037847443572777265\n",
      "current RMS: 0.4087760442275591, best RMS: 0.4087760442275591\n",
      "current run: (7, 25), epoch: 150, Loss: 0.030947374535230047\n",
      "current RMS: 0.3710438613857058, best RMS: 0.3710438613857058\n",
      "current run: (7, 25), epoch: 175, Loss: 0.023705053537460854\n",
      "current RMS: 0.3266268090770806, best RMS: 0.3266268090770806\n",
      "current run: (7, 25), epoch: 200, Loss: 0.016596596437023384\n",
      "current RMS: 0.2760967024083006, best RMS: 0.2760967024083006\n",
      "current run: (7, 25), epoch: 225, Loss: 0.010409772358170324\n",
      "current RMS: 0.22286542349256247, best RMS: 0.22286542349256247\n",
      "current run: (7, 25), epoch: 250, Loss: 0.005850666025947294\n",
      "current RMS: 0.17323209049403762, best RMS: 0.17323209049403762\n",
      "current run: (7, 25), epoch: 275, Loss: 0.0031141233333128364\n",
      "current RMS: 0.13443322066272598, best RMS: 0.13443322066272598\n",
      "current run: (7, 25), epoch: 300, Loss: 0.0018073266405684843\n",
      "current RMS: 0.1104650316651742, best RMS: 0.1104650316651742\n",
      "current run: (7, 25), epoch: 325, Loss: 0.0013090063724496307\n",
      "current RMS: 0.09903214996468028, best RMS: 0.09903214996468028\n",
      "current run: (7, 25), epoch: 350, Loss: 0.0011477841939152298\n",
      "current RMS: 0.09444628131735808, best RMS: 0.09444628131735808\n",
      "current run: (7, 25), epoch: 375, Loss: 0.0010937979601057062\n",
      "current RMS: 0.09253670737413613, best RMS: 0.09253670737413613\n",
      "current run: (7, 25), epoch: 400, Loss: 0.0010675764523197415\n",
      "current RMS: 0.09151592272502207, best RMS: 0.09151592272502207\n",
      "current run: (7, 25), epoch: 425, Loss: 0.0010483348346894095\n",
      "current RMS: 0.09080101887575412, best RMS: 0.09080101887575412\n",
      "current run: (7, 25), epoch: 450, Loss: 0.0010316667610847337\n",
      "current RMS: 0.09021450961882181, best RMS: 0.09021450961882181\n",
      "current run: (7, 25), epoch: 475, Loss: 0.001016663856799735\n",
      "current RMS: 0.08969708401381746, best RMS: 0.08969708401381746\n",
      "current run: (7, 25), epoch: 500, Loss: 0.0010030216917021881\n",
      "current RMS: 0.08922537031300737, best RMS: 0.08922537031300737\n",
      "current run: (7, 25), sim NRMS: 0.31655294773211884\n"
     ]
    }
   ],
   "source": [
    "for i, n_a in enumerate(na_list):\n",
    "    for j, n_b in enumerate(nb_list):\n",
    "\n",
    "        # construct NARX data\n",
    "        x_train_temp, y_train_temp = convert_to_narx(x_train, y_train,n_a, n_b)\n",
    "        x_val_temp, y_val_temp = convert_to_narx(x_val, y_val,n_a, n_b)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        x_train_temp, x_val_temp, y_train_temp, y_val_temp=[x.to(device) for x in [x_train_temp, x_val_temp, y_train_temp, y_val_temp]]\n",
    "\n",
    "        # initialise comparison values and results lists\n",
    "        best_NRMS=float('inf')\n",
    "        best_model=None\n",
    "        losses=[]\n",
    "        NRMSs=[]\n",
    "        best_NRMSs=[]\n",
    "\n",
    "        model = Narx(x_train_temp.shape[1], n_hidden_nodes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters()) \n",
    "        for epoch in range(n_epochs): \n",
    "            Loss = torch.mean((model(x_train_temp)-y_train_temp)**2) \n",
    "            optimizer.zero_grad() \n",
    "            Loss.backward() \n",
    "            optimizer.step() \n",
    "            if (epoch+1)%min((n_epochs//20),1000)==0:\n",
    "                print(f\"current run: {n_a, n_b}, epoch: {epoch+1}, Loss: {Loss.item()}\") \n",
    "                NRMS=calculate_error_nrms(model.forward(x_val_temp), y_val_temp)\n",
    "                if NRMS < best_NRMS:\n",
    "                    best_NRMS=NRMS\n",
    "                    best_model=deepcopy(model)\n",
    "                    print(f\"current RMS: {NRMS}, best RMS: {best_NRMS}\")\n",
    "                losses.append(Loss.item())\n",
    "                NRMSs.append(NRMS)\n",
    "                best_NRMSs.append(best_NRMS)\n",
    "\n",
    "        # store results\n",
    "        final_losses[i,j]=losses[-1]\n",
    "        final_best_NRMSs[i,j]=best_NRMSs[-1]\n",
    "        sim_NRMS=narx_sim_nrms(best_model, n_a, n_b, x_val, y_val, device)\n",
    "        simulation_NRMSs[i,j]=sim_NRMS\n",
    "        msg=f\"current run: {n_a, n_b}, sim NRMS: {simulation_NRMSs[i,j]}\"\n",
    "        if sim_NRMS< best_sim_NRMS:\n",
    "            best_sim_model=deepcopy(best_model)\n",
    "            msg+=f\". This is better than last sim best:{best_sim_NRMS} > {sim_NRMS}\"\n",
    "            best_sim_NRMS=sim_NRMS\n",
    "        print(msg) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_27016\\418227314.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels([0]+na_list)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_27016\\418227314.py:15: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_yticklabels([0]+na_list)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x2039c16dab0>,\n",
       " <matplotlib.axis.XTick at 0x2039c16da80>,\n",
       " <matplotlib.axis.XTick at 0x2039c16d690>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f4e20>,\n",
       " <matplotlib.axis.XTick at 0x2039c148730>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f57b0>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f6260>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f6d10>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f77c0>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f6590>,\n",
       " <matplotlib.axis.XTick at 0x2039a4f7d60>,\n",
       " <matplotlib.axis.XTick at 0x2039a530bb0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs=15\n",
    "fig = plt.figure(figsize=(15, 5),layout='constrained')\n",
    "ax1=fig.add_subplot(121)\n",
    "ax1.imshow(final_best_NRMSs, interpolation='none', norm='log')\n",
    "ax2=fig.add_subplot(122)\n",
    "ax2.imshow(simulation_NRMSs, interpolation='none', norm='log')\n",
    "ax1.set_title('Prediction NRMS',fontsize=fs)\n",
    "ax2.set_title('Simulation NRMS',fontsize=fs)\n",
    "fig.suptitle('Prediction and simulation NRMS for different combinations of na and nb for NARX', fontsize=25)\n",
    "ax1.set_ylabel('na',fontsize=fs)\n",
    "ax1.set_xlabel('nb',fontsize=fs)\n",
    "ax2.set_xlabel('nb',fontsize=fs)\n",
    "ax1.set_yticklabels([0]+na_list)\n",
    "ax1.set_xticks([*range(len(nb_list))],nb_list)\n",
    "ax2.set_yticklabels([0]+na_list)\n",
    "ax2.set_xticks([*range(len(nb_list))],nb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters by prediction NRMS: na= 5.0, nb= 18.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best parameters by simulation NRMS: na= 6.0, nb= 20.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.zeros((len(na_list), len(nb_list), 2))\n",
    "for i, n_a in enumerate(na_list):\n",
    "    for j, n_b in enumerate(nb_list):\n",
    "        params[i, j, :] = [n_a, n_b]\n",
    "\n",
    "min_arg = np.unravel_index(final_best_NRMSs.argmin(keepdims=True), final_best_NRMSs.shape)\n",
    "best_na, best_nb = params[min_arg].ravel()\n",
    "print(f\"Best parameters by prediction NRMS: na= {best_na}, nb= {best_nb}\")\n",
    "min_arg = np.unravel_index(simulation_NRMSs.argmin(keepdims=True), simulation_NRMSs.shape)\n",
    "best_na, best_nb = params[min_arg].ravel()\n",
    "f\"Best parameters by simulation NRMS: na= {best_na}, nb= {best_nb}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current run: 10, epoch: 2, Loss: 0.24165140321723894\n",
      "current RMS: 0.5025144542714477, best RMS: 0.5025144542714477\n",
      "current run: 10, epoch: 4, Loss: 0.23403606179390396\n",
      "current RMS: 0.4948659855087321, best RMS: 0.4948659855087321\n",
      "current run: 10, epoch: 6, Loss: 0.22684853999299256\n",
      "current RMS: 0.48754596360070424, best RMS: 0.48754596360070424\n",
      "current run: 10, epoch: 8, Loss: 0.22009815202829622\n",
      "current RMS: 0.4805776506361994, best RMS: 0.4805776506361994\n",
      "current run: 10, epoch: 10, Loss: 0.21379074607971968\n",
      "current RMS: 0.47398105850735595, best RMS: 0.47398105850735595\n",
      "current run: 10, epoch: 12, Loss: 0.20792832878146797\n",
      "current RMS: 0.46777218374132795, best RMS: 0.46777218374132795\n",
      "current run: 10, epoch: 14, Loss: 0.2025087624773525\n",
      "current RMS: 0.4619623060668021, best RMS: 0.4619623060668021\n",
      "current run: 10, epoch: 16, Loss: 0.19752555586345721\n",
      "current RMS: 0.4565573968939976, best RMS: 0.4565573968939976\n",
      "current run: 10, epoch: 18, Loss: 0.19296776793953402\n",
      "current RMS: 0.4515576844751637, best RMS: 0.4515576844751637\n",
      "current run: 10, epoch: 20, Loss: 0.18882004328007992\n",
      "current RMS: 0.44695741909328696, best RMS: 0.44695741909328696\n",
      "current run: 10, epoch: 22, Loss: 0.185062793138034\n",
      "current RMS: 0.4427448735747812, best RMS: 0.4427448735747812\n",
      "current run: 10, epoch: 24, Loss: 0.18167253143839712\n",
      "current RMS: 0.43890260156993993, best RMS: 0.43890260156993993\n",
      "current run: 10, epoch: 26, Loss: 0.17862236706027465\n",
      "current RMS: 0.4354079588607357, best RMS: 0.4354079588607357\n",
      "current run: 10, epoch: 28, Loss: 0.1758826439803857\n",
      "current RMS: 0.4322338726577438, best RMS: 0.4322338726577438\n",
      "current run: 10, epoch: 30, Loss: 0.17342170933913853\n",
      "current RMS: 0.42934982240708713, best RMS: 0.42934982240708713\n",
      "current run: 10, epoch: 32, Loss: 0.1712067773218579\n",
      "current RMS: 0.4267229756071524, best RMS: 0.4267229756071524\n",
      "current run: 10, epoch: 34, Loss: 0.169204845482241\n",
      "current RMS: 0.424319406346403, best RMS: 0.424319406346403\n",
      "current run: 10, epoch: 36, Loss: 0.167383611661815\n",
      "current RMS: 0.4221053152827891, best RMS: 0.4221053152827891\n",
      "current run: 10, epoch: 38, Loss: 0.16571233581651976\n",
      "current RMS: 0.42004816934627476, best RMS: 0.42004816934627476\n",
      "current run: 10, epoch: 40, Loss: 0.16416259315475026\n",
      "current RMS: 0.4181176880251505, best RMS: 0.4181176880251505\n",
      "current run: 10, epoch: 42, Loss: 0.16270887335690393\n",
      "current RMS: 0.4162866196462535, best RMS: 0.4162866196462535\n",
      "current run: 10, epoch: 44, Loss: 0.16132899443289536\n",
      "current RMS: 0.414531273153977, best RMS: 0.414531273153977\n",
      "current run: 10, epoch: 46, Loss: 0.16000431704741178\n",
      "current RMS: 0.41283179522623864, best RMS: 0.41283179522623864\n",
      "current run: 10, epoch: 48, Loss: 0.158719763310135\n",
      "current RMS: 0.411172205665443, best RMS: 0.411172205665443\n",
      "current run: 10, epoch: 50, Loss: 0.15746366044269908\n",
      "current RMS: 0.4095402229490825, best RMS: 0.4095402229490825\n",
      "current run: 20, epoch: 2, Loss: 0.22352999478512006\n",
      "current RMS: 0.48809962860467243, best RMS: 0.48809962860467243\n",
      "current run: 20, epoch: 4, Loss: 0.22056590530123804\n",
      "current RMS: 0.48489716227697666, best RMS: 0.48489716227697666\n",
      "current run: 20, epoch: 6, Loss: 0.21766325203822454\n",
      "current RMS: 0.4817199779599044, best RMS: 0.4817199779599044\n",
      "current run: 20, epoch: 8, Loss: 0.21481381134877564\n",
      "current RMS: 0.47857042993996135, best RMS: 0.47857042993996135\n",
      "current run: 20, epoch: 10, Loss: 0.21201429013690165\n",
      "current RMS: 0.47544698647558703, best RMS: 0.47544698647558703\n",
      "current run: 20, epoch: 12, Loss: 0.20926112237661482\n",
      "current RMS: 0.4723472659536685, best RMS: 0.4723472659536685\n",
      "current run: 20, epoch: 14, Loss: 0.2065506511110147\n",
      "current RMS: 0.46926883941283504, best RMS: 0.46926883941283504\n",
      "current run: 20, epoch: 16, Loss: 0.20387935283897304\n",
      "current RMS: 0.46620947547029185, best RMS: 0.46620947547029185\n",
      "current run: 20, epoch: 18, Loss: 0.20124380563552074\n",
      "current RMS: 0.46316696350713366, best RMS: 0.46316696350713366\n",
      "current run: 20, epoch: 20, Loss: 0.19864049467474554\n",
      "current RMS: 0.4601388113111797, best RMS: 0.4601388113111797\n",
      "current run: 20, epoch: 22, Loss: 0.19606566240204723\n",
      "current RMS: 0.4571220320368065, best RMS: 0.4571220320368065\n",
      "current run: 20, epoch: 24, Loss: 0.19351533066375382\n",
      "current RMS: 0.4541131713430961, best RMS: 0.4541131713430961\n",
      "current run: 20, epoch: 26, Loss: 0.19098555663625247\n",
      "current RMS: 0.4511085934393973, best RMS: 0.4511085934393973\n",
      "current run: 20, epoch: 28, Loss: 0.18847281863229842\n",
      "current RMS: 0.4481048586645987, best RMS: 0.4481048586645987\n",
      "current run: 20, epoch: 30, Loss: 0.1859743071852491\n",
      "current RMS: 0.44509896239963437, best RMS: 0.44509896239963437\n",
      "current run: 20, epoch: 32, Loss: 0.18348795413598298\n",
      "current RMS: 0.44208833419065313, best RMS: 0.44208833419065313\n",
      "current run: 20, epoch: 34, Loss: 0.1810122298793294\n",
      "current RMS: 0.4390707023549951, best RMS: 0.4390707023549951\n",
      "current run: 20, epoch: 36, Loss: 0.1785458981526808\n",
      "current RMS: 0.4360440184659748, best RMS: 0.4360440184659748\n",
      "current run: 20, epoch: 38, Loss: 0.17608790185783732\n",
      "current RMS: 0.4330065351786029, best RMS: 0.4330065351786029\n",
      "current run: 20, epoch: 40, Loss: 0.17363740198925068\n",
      "current RMS: 0.42995695831503, best RMS: 0.42995695831503\n",
      "current run: 20, epoch: 42, Loss: 0.17119386113702117\n",
      "current RMS: 0.4268945260475405, best RMS: 0.4268945260475405\n",
      "current run: 20, epoch: 44, Loss: 0.16875706159974396\n",
      "current RMS: 0.4238189449126449, best RMS: 0.4238189449126449\n",
      "current run: 20, epoch: 46, Loss: 0.16632703996897555\n",
      "current RMS: 0.42073023083125144, best RMS: 0.42073023083125144\n",
      "current run: 20, epoch: 48, Loss: 0.16390399815248394\n",
      "current RMS: 0.4176285577318761, best RMS: 0.4176285577318761\n",
      "current run: 20, epoch: 50, Loss: 0.1614882544154636\n",
      "current RMS: 0.4145141821332276, best RMS: 0.4145141821332276\n",
      "current run: 50, epoch: 2, Loss: 0.3544895509049868\n",
      "current RMS: 0.5986001796447082, best RMS: 0.5986001796447082\n",
      "current run: 50, epoch: 4, Loss: 0.3255095945505581\n",
      "current RMS: 0.5766601712998454, best RMS: 0.5766601712998454\n",
      "current run: 50, epoch: 6, Loss: 0.3028598506180079\n",
      "current RMS: 0.5594755842912315, best RMS: 0.5594755842912315\n",
      "current run: 50, epoch: 8, Loss: 0.2863326352525152\n",
      "current RMS: 0.5471190461471475, best RMS: 0.5471190461471475\n",
      "current run: 50, epoch: 10, Loss: 0.275301939234332\n",
      "current RMS: 0.5391025612779878, best RMS: 0.5391025612779878\n",
      "current run: 50, epoch: 12, Loss: 0.2686445745857792\n",
      "current RMS: 0.5343456538145023, best RMS: 0.5343456538145023\n",
      "current run: 50, epoch: 14, Loss: 0.26483348232774784\n",
      "current RMS: 0.5314071031381965, best RMS: 0.5314071031381965\n",
      "current run: 50, epoch: 16, Loss: 0.2622633210462867\n",
      "current RMS: 0.5289108446915356, best RMS: 0.5289108446915356\n",
      "current run: 50, epoch: 18, Loss: 0.25965409268809614\n",
      "current RMS: 0.5259061851099934, best RMS: 0.5259061851099934\n",
      "current run: 50, epoch: 20, Loss: 0.25628927750116576\n",
      "current RMS: 0.5219850889358414, best RMS: 0.5219850889358414\n",
      "current run: 50, epoch: 22, Loss: 0.2520061916757013\n",
      "current RMS: 0.5171899094811085, best RMS: 0.5171899094811085\n",
      "current run: 50, epoch: 24, Loss: 0.24702644417449077\n",
      "current RMS: 0.5118321257280148, best RMS: 0.5118321257280148\n",
      "current run: 50, epoch: 26, Loss: 0.2417463845608373\n",
      "current RMS: 0.5063121287019212, best RMS: 0.5063121287019212\n",
      "current run: 50, epoch: 28, Loss: 0.23656149853062228\n",
      "current RMS: 0.500980397153488, best RMS: 0.500980397153488\n",
      "current run: 50, epoch: 30, Loss: 0.23175248864844117\n",
      "current RMS: 0.49605314248631216, best RMS: 0.49605314248631216\n",
      "current run: 50, epoch: 32, Loss: 0.22743650075115504\n",
      "current RMS: 0.49158510796350213, best RMS: 0.49158510796350213\n",
      "current run: 50, epoch: 34, Loss: 0.22357616796232352\n",
      "current RMS: 0.48749435096979393, best RMS: 0.48749435096979393\n",
      "current run: 50, epoch: 36, Loss: 0.22003114018982273\n",
      "current RMS: 0.4836229362506544, best RMS: 0.4836229362506544\n",
      "current run: 50, epoch: 38, Loss: 0.21662900177151323\n",
      "current RMS: 0.4798079824274573, best RMS: 0.4798079824274573\n",
      "current run: 50, epoch: 40, Loss: 0.21322935371214402\n",
      "current RMS: 0.47593690873222294, best RMS: 0.47593690873222294\n",
      "current run: 50, epoch: 42, Loss: 0.20976084456920327\n",
      "current RMS: 0.4719709729426536, best RMS: 0.4719709729426536\n",
      "current run: 50, epoch: 44, Loss: 0.20622449736617277\n",
      "current RMS: 0.46793645777343373, best RMS: 0.46793645777343373\n",
      "current run: 50, epoch: 46, Loss: 0.20267071318885257\n",
      "current RMS: 0.4638950071613833, best RMS: 0.4638950071613833\n",
      "current run: 50, epoch: 48, Loss: 0.199165240310802\n",
      "current RMS: 0.45990926117526204, best RMS: 0.45990926117526204\n",
      "current run: 50, epoch: 50, Loss: 0.19575939056945313\n",
      "current RMS: 0.45601753384326477, best RMS: 0.45601753384326477\n",
      "current run: 100, epoch: 2, Loss: 0.3103221788458956\n",
      "current RMS: 0.5559289853599988, best RMS: 0.5559289853599988\n",
      "current run: 100, epoch: 4, Loss: 0.2764741734823424\n",
      "current RMS: 0.5351837802003814, best RMS: 0.5351837802003814\n",
      "current run: 100, epoch: 6, Loss: 0.2628101272545421\n",
      "current RMS: 0.5292065068535864, best RMS: 0.5292065068535864\n",
      "current run: 100, epoch: 8, Loss: 0.2603562540935475\n",
      "current RMS: 0.5279225290307421, best RMS: 0.5279225290307421\n",
      "current run: 100, epoch: 10, Loss: 0.2581642525324737\n",
      "current RMS: 0.5234698750795883, best RMS: 0.5234698750795883\n",
      "current run: 100, epoch: 12, Loss: 0.25156818862076574\n",
      "current RMS: 0.5146841746446417, best RMS: 0.5146841746446417\n",
      "current run: 100, epoch: 14, Loss: 0.24178740403843066\n",
      "current RMS: 0.5039517637585902, best RMS: 0.5039517637585902\n",
      "current run: 100, epoch: 16, Loss: 0.23176496234779834\n",
      "current RMS: 0.49396470972638046, best RMS: 0.49396470972638046\n",
      "current run: 100, epoch: 18, Loss: 0.22357446021392988\n",
      "current RMS: 0.48608048205924326, best RMS: 0.48608048205924326\n",
      "current run: 100, epoch: 20, Loss: 0.21753506151328017\n",
      "current RMS: 0.4799315910877906, best RMS: 0.4799315910877906\n",
      "current run: 100, epoch: 22, Loss: 0.212569988936514\n",
      "current RMS: 0.4741745990993353, best RMS: 0.4741745990993353\n",
      "current run: 100, epoch: 24, Loss: 0.2073566128481416\n",
      "current RMS: 0.46774096971138557, best RMS: 0.46774096971138557\n",
      "current run: 100, epoch: 26, Loss: 0.20134519010521668\n",
      "current RMS: 0.4605324632695392, best RMS: 0.4605324632695392\n",
      "current run: 100, epoch: 28, Loss: 0.19490468664914895\n",
      "current RMS: 0.4531860280921669, best RMS: 0.4531860280921669\n",
      "current run: 100, epoch: 30, Loss: 0.18875272467430476\n",
      "current RMS: 0.446374564436248, best RMS: 0.446374564436248\n",
      "current run: 100, epoch: 32, Loss: 0.1833144789739086\n",
      "current RMS: 0.4402744325468592, best RMS: 0.4402744325468592\n",
      "current run: 100, epoch: 34, Loss: 0.17848437943632073\n",
      "current RMS: 0.43454735929425375, best RMS: 0.43454735929425375\n",
      "current run: 100, epoch: 36, Loss: 0.17385807032458686\n",
      "current RMS: 0.4287414311664398, best RMS: 0.4287414311664398\n",
      "current run: 100, epoch: 38, Loss: 0.16913960128370578\n",
      "current RMS: 0.4226896269483083, best RMS: 0.4226896269483083\n",
      "current run: 100, epoch: 40, Loss: 0.16434730215421345\n",
      "current RMS: 0.4165722254094675, best RMS: 0.4165722254094675\n",
      "current run: 100, epoch: 42, Loss: 0.15970089305082547\n",
      "current RMS: 0.4106767454928652, best RMS: 0.4106767454928652\n",
      "current run: 100, epoch: 44, Loss: 0.15537320820937967\n",
      "current RMS: 0.4051326111138256, best RMS: 0.4051326111138256\n",
      "current run: 100, epoch: 46, Loss: 0.15135240278916612\n",
      "current RMS: 0.3998506578246171, best RMS: 0.3998506578246171\n",
      "current run: 100, epoch: 48, Loss: 0.14750279236896865\n",
      "current RMS: 0.39466947058562246, best RMS: 0.39466947058562246\n",
      "current run: 100, epoch: 50, Loss: 0.14371868349759484\n",
      "current RMS: 0.38952472442749864, best RMS: 0.38952472442749864\n"
     ]
    }
   ],
   "source": [
    "n_hidden_list=[10,20,50,100]\n",
    "\n",
    "best_NRMS=float('inf')\n",
    "best_model=None\n",
    "losses=[]\n",
    "RMSs=[]\n",
    "best_RMSs=[]\n",
    "n_a=5\n",
    "n_b=1\n",
    "final_losses=[]\n",
    "final_best_RMSs=[]\n",
    "for n_hidden_nodes in n_hidden_list:\n",
    "    x,y = load_narx_data(n_a, n_b)\n",
    "    x_train, x_val, y_train, y_val =train_test_split(x, y, shuffle=False)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x_train, x_val, y_train, y_val=[x.to(device) for x in [x_train, x_val, y_train, y_val]]\n",
    "    best_NRMS=float('inf')\n",
    "    best_model=None\n",
    "    losses=[]\n",
    "    RMSs=[]\n",
    "    best_RMSs=[]\n",
    "\n",
    "    model = Narx(x_train.shape[1], n_hidden_nodes).to(device) #a=)\n",
    "    optimizer = torch.optim.Adam(model.parameters()) #a)\n",
    "    for epoch in range(n_epochs): #a)\n",
    "        Loss = torch.mean((model(x_train)-y_train)**2) #a)\n",
    "        optimizer.zero_grad() #a)\n",
    "        Loss.backward() #a)\n",
    "        optimizer.step() #a)\n",
    "        if (epoch+1)%min((n_epochs//20),1000)==0: #a) monitor\n",
    "            print(f\"current run: {n_hidden_nodes}, epoch: {epoch+1}, Loss: {Loss.item()}\") #a)\n",
    "            RMS=np.mean((y_val.detach().cpu().numpy()-model.forward(x_val).detach().cpu().numpy())**2)**0.5\n",
    "            if RMS < best_NRMS:\n",
    "                best_NRMS=RMS\n",
    "                best_model=deepcopy(model)\n",
    "                print(f\"current RMS: {RMS}, best RMS: {best_NRMS}\")\n",
    "            losses.append(Loss.item())\n",
    "            RMSs.append(RMS)\n",
    "            best_RMSs.append(best_NRMS)\n",
    "    final_losses.append(losses[-1])\n",
    "    final_best_RMSs.append(best_RMSs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f01de947f0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_hidden_list,final_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
