{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b34da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch, gym, gym_unbalanced_disk, time, gym.wrappers\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b693827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qfunction(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super(Qfunction,self).__init__()\n",
    "        self.lay1 = nn.Linear(env.observation_space.shape[0], 40)\n",
    "        self.F1 =  nn.Tanh() #a)\n",
    "        self.lay2 = nn.Linear(40,env.action_space.n)\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        return self.lay2(self.F1(self.lay1(obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83e83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(Q,env):\n",
    "    with torch.no_grad():\n",
    "        #you can use Qfun(obs) as a shorthand for the q function.\n",
    "        Qfun = lambda x: Q(torch.tensor(x[None,:],dtype=torch.float32))[0].numpy() #convert x to torch.tensor -> put in the Q function -> back to numpy\n",
    "        try:\n",
    "            obs = env.reset() #b)\n",
    "            env.render() #b)\n",
    "            time.sleep(1) #b)\n",
    "            while True: #b)\n",
    "                action = np.argmax(Qfun(obs)) #b)\n",
    "                obs, reward, done, info = env.step(action) #b)\n",
    "                time.sleep(1/60) #b)\n",
    "                env.render() #b)\n",
    "                print(env.u)\n",
    "                if done: #b)\n",
    "                    time.sleep(0.5)  #b)\n",
    "                    break  #b)\n",
    "        finally: #this will always run even when an error occurs\n",
    "            env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eeb0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(Q, env, epsilon=0.1, N_rollout=10_000): \n",
    "    #save the following (use .append)\n",
    "    Start_state = [] #hold an array of (x_t)\n",
    "    Actions = [] #hold an array of (u_t)\n",
    "    Rewards = [] #hold an array of (r_{t+1})\n",
    "    End_state = [] #hold an array of (x_{t+1})\n",
    "    Terminal = [] #hold an array of (terminal_{t+1})\n",
    "    # Qfun( a numpy array of the obs) -> a numpy array of Q values\n",
    "    Qfun = lambda x: Q(torch.tensor(x[None,:],dtype=torch.float32))[0].numpy() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        obs = env.reset() #c)\n",
    "        for i in range(N_rollout): #c)\n",
    "            if np.random.uniform()>epsilon: #c)\n",
    "                Qnow = Qfun(obs) #c)\n",
    "                action = np.argmax(Qnow) #c)\n",
    "            else: #c)\n",
    "                action = env.action_space.sample() #c)\n",
    "            Start_state.append(obs) #c)\n",
    "            Actions.append(action) #c)\n",
    "\n",
    "            obs_next, reward, done, info = env.step(action) #c)\n",
    "            terminal = done and not info.get('TimeLimit.truncated', False) #c)\n",
    "\n",
    "            Terminal.append(terminal) #c)\n",
    "            Rewards.append(reward) #c)\n",
    "            End_state.append(obs_next) #c)\n",
    "\n",
    "            if done: #c)\n",
    "                obs = env.reset() #c)\n",
    "            else: #c)\n",
    "                obs = obs_next #c)\n",
    "                \n",
    "    #error checking:\n",
    "    assert len(Start_state)==len(Actions)==len(Rewards)==len(End_state)==len(Terminal), f'error in lengths: {len(Start_state)}=={len(Actions)}=={len(Rewards)}=={len(End_state)}=={len(Dones)}'\n",
    "    return np.array(Start_state), np.array(Actions), np.array(Rewards), np.array(End_state), np.array(Terminal).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6431873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Q(Q,env):\n",
    "    with torch.no_grad():\n",
    "        Qfun = lambda x: Q(torch.tensor(x[None,:],dtype=torch.float32))[0].numpy()\n",
    "        rewards_acc = 0 #d)\n",
    "        obs = env.reset() #d)\n",
    "        while True: #d)\n",
    "            action = np.argmax(Qfun(obs)) #d)\n",
    "            obs, reward, done, info = env.step(action) #d)\n",
    "            rewards_acc += reward #d)\n",
    "            if done: #d)\n",
    "                return rewards_acc #d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e55a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_rollout(Q, optimizer, env, gamma=0.98, use_target_net=False, N_iterations=21, N_rollout=20000, \\\n",
    "                N_epochs=10, batch_size=32, N_evals=10, target_net_update_feq=100):\n",
    "    best = -float('inf')\n",
    "    torch.save(Q.state_dict(),'Q-checkpoint')\n",
    "    try:\n",
    "        for iteration in range(N_iterations):\n",
    "            epsilon = 1.0 - iteration/(N_iterations-1) #e=) 1.\n",
    "            print(f'rollout iteration {iteration} with epsilon={epsilon:.2%}...')\n",
    "            \n",
    "            #2. rollout\n",
    "            Start_state, Actions, Rewards, End_state, Dones = rollout(Q, env, epsilon=epsilon, N_rollout=N_rollout) #e) 2.\n",
    "            \n",
    "            #Data conversion, no changes required\n",
    "            convert = lambda x: [torch.tensor(xi,dtype=torch.float32) for xi in x]\n",
    "            Start_state, Rewards, End_state, Dones = convert([Start_state, Rewards, End_state, Dones])\n",
    "            Actions = Actions.astype(int)\n",
    "\n",
    "            print('starting training on rollout information...')\n",
    "            t = 0\n",
    "            for epoch in range(N_epochs): \n",
    "                for i in range(batch_size,len(Start_state)+1,batch_size): \n",
    "                    if t%target_net_update_feq==0:\n",
    "                        Qtarget = deepcopy(Q) #g)\n",
    "                        pass\n",
    "                    t += 1\n",
    "                    \n",
    "                    Start_state_batch, Actions_batch, Rewards_batch, End_state_batch, Dones_batch = [d[i-batch_size:i] for d in [Start_state, Actions, Rewards, End_state, Dones]] #e=) 3.\n",
    "                    \n",
    "                    with torch.no_grad(): #3.\n",
    "                        if use_target_net:\n",
    "                            pass\n",
    "                            maxQ = torch.max(Qtarget(End_state_batch),dim=1)[0] #g)\n",
    "                        else:\n",
    "                            maxQ = torch.max(Q(End_state_batch),dim=1)[0] #e=) 3.\n",
    "                    \n",
    "                    action_index = np.stack((np.arange(batch_size),Actions_batch),axis=0)\n",
    "                    Qnow = Q(Start_state_batch)[action_index] #Q(x_t,u_t) is given\n",
    "                    \n",
    "                    Loss = torch.mean((Rewards_batch + gamma*maxQ*(1-Dones_batch) - Qnow)**2) #e) 3.\n",
    "                    optimizer.zero_grad() #e) 3.\n",
    "                    Loss.backward() #e) 3.\n",
    "                    optimizer.step() #e) 3.\n",
    "                \n",
    "                score = np.mean([eval_Q(Q,env) for i in range(N_evals)]) #e=) 3.\n",
    "                \n",
    "                print(f'iteration={iteration} epoch={epoch} Average Reward per episode:',score)\n",
    "                if score>best:\n",
    "                    best = score\n",
    "                    print('################################# \\n new best',best,'saving Q... \\n#################################')\n",
    "                    torch.save(Q.state_dict(),'Q-checkpoint')\n",
    "            \n",
    "            print('loading best result')\n",
    "            Q.load_state_dict(torch.load('Q-checkpoint'))\n",
    "    finally: #this will always run even when using the a KeyBoard Interrupt. \n",
    "        print('loading best result')\n",
    "        Q.load_state_dict(torch.load('Q-checkpoint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63af2e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward function changed\n",
      "Discrete value set changed to [-3.0, -1.2, -0.48, -0.19, 0, 0.19, 0.48, 1.2, 3.0]\n",
      "rollout iteration 0 with epsilon=100.00%...\n",
      "starting training on rollout information...\n",
      "iteration=0 epoch=0 Average Reward per episode: 0.00021127791553411434\n",
      "################################# \n",
      " new best 0.00021127791553411434 saving Q... \n",
      "#################################\n",
      "iteration=0 epoch=1 Average Reward per episode: 0.00012190196520878522\n",
      "iteration=0 epoch=2 Average Reward per episode: 0.0002908655402295783\n",
      "################################# \n",
      " new best 0.0002908655402295783 saving Q... \n",
      "#################################\n",
      "iteration=0 epoch=3 Average Reward per episode: 0.12028526241498334\n",
      "################################# \n",
      " new best 0.12028526241498334 saving Q... \n",
      "#################################\n",
      "iteration=0 epoch=4 Average Reward per episode: 8.735424701420571\n",
      "################################# \n",
      " new best 8.735424701420571 saving Q... \n",
      "#################################\n",
      "iteration=0 epoch=5 Average Reward per episode: 1.145099929444623\n",
      "iteration=0 epoch=6 Average Reward per episode: 6.417493903047157\n",
      "iteration=0 epoch=7 Average Reward per episode: 33.58215416805127\n",
      "################################# \n",
      " new best 33.58215416805127 saving Q... \n",
      "#################################\n",
      "iteration=0 epoch=8 Average Reward per episode: 1.1183840477929663\n",
      "iteration=0 epoch=9 Average Reward per episode: 122.56716083330589\n",
      "################################# \n",
      " new best 122.56716083330589 saving Q... \n",
      "#################################\n",
      "loading best result\n",
      "rollout iteration 1 with epsilon=95.00%...\n",
      "starting training on rollout information...\n",
      "iteration=1 epoch=0 Average Reward per episode: 8.119635568111986e-05\n",
      "iteration=1 epoch=1 Average Reward per episode: 0.00012731360838439098\n",
      "iteration=1 epoch=2 Average Reward per episode: 44.687287206626216\n",
      "iteration=1 epoch=3 Average Reward per episode: 56.29820641019053\n",
      "iteration=1 epoch=4 Average Reward per episode: 89.80200257271856\n",
      "iteration=1 epoch=5 Average Reward per episode: 58.565192533486005\n",
      "iteration=1 epoch=6 Average Reward per episode: 6.40742811726661\n",
      "iteration=1 epoch=7 Average Reward per episode: 22.084374577702942\n",
      "iteration=1 epoch=8 Average Reward per episode: 0.00014147468683023648\n",
      "iteration=1 epoch=9 Average Reward per episode: 81.42979838312752\n",
      "loading best result\n",
      "rollout iteration 2 with epsilon=90.00%...\n",
      "starting training on rollout information...\n",
      "iteration=2 epoch=0 Average Reward per episode: 1.1386919677768923\n",
      "iteration=2 epoch=1 Average Reward per episode: 76.29282363875936\n",
      "iteration=2 epoch=2 Average Reward per episode: 1.124952346122838\n",
      "iteration=2 epoch=3 Average Reward per episode: 36.06500574347395\n",
      "iteration=2 epoch=4 Average Reward per episode: 23.491496991113642\n",
      "iteration=2 epoch=5 Average Reward per episode: 614.355076739068\n",
      "################################# \n",
      " new best 614.355076739068 saving Q... \n",
      "#################################\n",
      "iteration=2 epoch=6 Average Reward per episode: 144.36287317589534\n",
      "iteration=2 epoch=7 Average Reward per episode: -0.07750560990863416\n",
      "iteration=2 epoch=8 Average Reward per episode: 66.60261354815815\n",
      "iteration=2 epoch=9 Average Reward per episode: -0.07748784756757995\n",
      "loading best result\n",
      "rollout iteration 3 with epsilon=85.00%...\n",
      "starting training on rollout information...\n",
      "iteration=3 epoch=0 Average Reward per episode: 127.60411022295304\n",
      "iteration=3 epoch=1 Average Reward per episode: 210.69084560132598\n",
      "iteration=3 epoch=2 Average Reward per episode: 279.18758436211294\n",
      "iteration=3 epoch=3 Average Reward per episode: 522.0602412002618\n",
      "iteration=3 epoch=4 Average Reward per episode: 159.0395717444252\n",
      "iteration=3 epoch=5 Average Reward per episode: 81.43804758342785\n",
      "iteration=3 epoch=6 Average Reward per episode: 702.2377939901578\n",
      "################################# \n",
      " new best 702.2377939901578 saving Q... \n",
      "#################################\n",
      "iteration=3 epoch=7 Average Reward per episode: 555.1272769331857\n",
      "iteration=3 epoch=8 Average Reward per episode: 558.8084735577553\n",
      "iteration=3 epoch=9 Average Reward per episode: 255.55916969304076\n",
      "loading best result\n",
      "rollout iteration 4 with epsilon=80.00%...\n",
      "starting training on rollout information...\n",
      "iteration=4 epoch=0 Average Reward per episode: 0.0002142240427746275\n",
      "iteration=4 epoch=1 Average Reward per episode: 81.50972684137203\n",
      "iteration=4 epoch=2 Average Reward per episode: 81.50262328743071\n",
      "iteration=4 epoch=3 Average Reward per episode: 429.4561491552119\n",
      "iteration=4 epoch=4 Average Reward per episode: 543.9707733465673\n",
      "iteration=4 epoch=5 Average Reward per episode: 327.7663280735858\n",
      "iteration=4 epoch=6 Average Reward per episode: 396.6136483852276\n",
      "iteration=4 epoch=7 Average Reward per episode: 660.8641835926798\n",
      "iteration=4 epoch=8 Average Reward per episode: 478.7304211193389\n",
      "iteration=4 epoch=9 Average Reward per episode: 81.46757064345371\n",
      "loading best result\n",
      "rollout iteration 5 with epsilon=75.00%...\n",
      "starting training on rollout information...\n",
      "iteration=5 epoch=0 Average Reward per episode: -0.07799400774890389\n",
      "iteration=5 epoch=1 Average Reward per episode: 215.47163881223906\n",
      "iteration=5 epoch=2 Average Reward per episode: 308.5325420889675\n",
      "iteration=5 epoch=3 Average Reward per episode: 405.46987353048974\n",
      "iteration=5 epoch=4 Average Reward per episode: 399.2738388101624\n",
      "iteration=5 epoch=5 Average Reward per episode: 341.4914832079723\n",
      "iteration=5 epoch=6 Average Reward per episode: 394.68826454769334\n",
      "iteration=5 epoch=7 Average Reward per episode: 473.1712083511244\n",
      "iteration=5 epoch=8 Average Reward per episode: 462.14931064133697\n",
      "iteration=5 epoch=9 Average Reward per episode: 228.12453661420014\n",
      "loading best result\n",
      "rollout iteration 6 with epsilon=70.00%...\n",
      "starting training on rollout information...\n",
      "iteration=6 epoch=0 Average Reward per episode: 4.4796873972322474e-05\n",
      "iteration=6 epoch=1 Average Reward per episode: 6.948426022616749e-05\n",
      "iteration=6 epoch=2 Average Reward per episode: 0.0003571887618038583\n",
      "iteration=6 epoch=3 Average Reward per episode: 0.000142459887399393\n",
      "iteration=6 epoch=4 Average Reward per episode: 468.7258292963068\n",
      "iteration=6 epoch=5 Average Reward per episode: 545.5957719784984\n",
      "iteration=6 epoch=6 Average Reward per episode: 631.8787837971273\n",
      "iteration=6 epoch=7 Average Reward per episode: 617.998697607816\n",
      "iteration=6 epoch=8 Average Reward per episode: 621.5022376812324\n",
      "iteration=6 epoch=9 Average Reward per episode: 81.49391302125211\n",
      "loading best result\n",
      "rollout iteration 7 with epsilon=65.00%...\n",
      "starting training on rollout information...\n",
      "iteration=7 epoch=0 Average Reward per episode: 211.02539476459643\n",
      "iteration=7 epoch=1 Average Reward per episode: 294.2541300820454\n",
      "iteration=7 epoch=2 Average Reward per episode: 227.27157396673198\n",
      "iteration=7 epoch=3 Average Reward per episode: 228.19666715572203\n",
      "iteration=7 epoch=4 Average Reward per episode: 262.9437649692613\n",
      "iteration=7 epoch=5 Average Reward per episode: 81.4399189054486\n",
      "iteration=7 epoch=6 Average Reward per episode: 81.49347849948484\n",
      "iteration=7 epoch=7 Average Reward per episode: 81.49318372407912\n",
      "iteration=7 epoch=8 Average Reward per episode: 583.1026224749414\n",
      "iteration=7 epoch=9 Average Reward per episode: 81.51342639303941\n",
      "loading best result\n",
      "rollout iteration 8 with epsilon=60.00%...\n",
      "starting training on rollout information...\n",
      "iteration=8 epoch=0 Average Reward per episode: 213.1696772610832\n",
      "iteration=8 epoch=1 Average Reward per episode: 8.554120189417929e-05\n",
      "iteration=8 epoch=2 Average Reward per episode: 214.8251496501974\n",
      "iteration=8 epoch=3 Average Reward per episode: 509.0123113739238\n",
      "iteration=8 epoch=4 Average Reward per episode: 599.8107357639316\n",
      "iteration=8 epoch=5 Average Reward per episode: 91.58770840439436\n",
      "iteration=8 epoch=6 Average Reward per episode: 81.48560463507685\n",
      "iteration=8 epoch=7 Average Reward per episode: 81.37062124749886\n",
      "iteration=8 epoch=8 Average Reward per episode: 81.50362908726044\n",
      "iteration=8 epoch=9 Average Reward per episode: 81.46166831625001\n",
      "loading best result\n",
      "rollout iteration 9 with epsilon=55.00%...\n",
      "starting training on rollout information...\n",
      "iteration=9 epoch=0 Average Reward per episode: 211.86763908930962\n",
      "iteration=9 epoch=1 Average Reward per episode: 210.97665432877966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=9 epoch=2 Average Reward per episode: 211.7872539804871\n",
      "iteration=9 epoch=3 Average Reward per episode: 211.77793707749046\n",
      "iteration=9 epoch=4 Average Reward per episode: 211.81251134191228\n",
      "iteration=9 epoch=5 Average Reward per episode: 81.46139773421002\n",
      "iteration=9 epoch=6 Average Reward per episode: 81.45408899571842\n",
      "iteration=9 epoch=7 Average Reward per episode: 81.45977310649307\n",
      "iteration=9 epoch=8 Average Reward per episode: 81.45088787139903\n",
      "iteration=9 epoch=9 Average Reward per episode: 81.45264433300535\n",
      "loading best result\n",
      "rollout iteration 10 with epsilon=50.00%...\n",
      "starting training on rollout information...\n",
      "iteration=10 epoch=0 Average Reward per episode: 210.97271668487514\n",
      "iteration=10 epoch=1 Average Reward per episode: 210.97262380198293\n",
      "iteration=10 epoch=2 Average Reward per episode: 208.28161313538985\n",
      "iteration=10 epoch=3 Average Reward per episode: 209.23230585996734\n",
      "iteration=10 epoch=4 Average Reward per episode: 209.22751680435846\n",
      "iteration=10 epoch=5 Average Reward per episode: 210.01891943499518\n",
      "iteration=10 epoch=6 Average Reward per episode: 230.4738681135681\n",
      "iteration=10 epoch=7 Average Reward per episode: 81.53171785407898\n",
      "iteration=10 epoch=8 Average Reward per episode: 81.4870961662927\n",
      "iteration=10 epoch=9 Average Reward per episode: 80.74476216012623\n",
      "loading best result\n",
      "rollout iteration 11 with epsilon=45.00%...\n",
      "starting training on rollout information...\n",
      "iteration=11 epoch=0 Average Reward per episode: 211.13379936095976\n",
      "iteration=11 epoch=1 Average Reward per episode: 211.14132938171437\n",
      "iteration=11 epoch=2 Average Reward per episode: 211.14674847617434\n",
      "iteration=11 epoch=3 Average Reward per episode: 209.3238174953596\n",
      "iteration=11 epoch=4 Average Reward per episode: 211.39453405469249\n",
      "iteration=11 epoch=5 Average Reward per episode: 211.1419183860899\n",
      "iteration=11 epoch=6 Average Reward per episode: 214.0094958821187\n",
      "iteration=11 epoch=7 Average Reward per episode: 81.46016209383059\n",
      "iteration=11 epoch=8 Average Reward per episode: 81.4941206855402\n",
      "iteration=11 epoch=9 Average Reward per episode: 81.41462204305066\n",
      "loading best result\n",
      "rollout iteration 12 with epsilon=40.00%...\n",
      "starting training on rollout information...\n",
      "iteration=12 epoch=0 Average Reward per episode: 211.44746009184115\n",
      "iteration=12 epoch=1 Average Reward per episode: 210.93777297686466\n",
      "iteration=12 epoch=2 Average Reward per episode: 209.07226712092717\n",
      "iteration=12 epoch=3 Average Reward per episode: 208.27399917786474\n",
      "iteration=12 epoch=4 Average Reward per episode: 207.56606979115872\n",
      "iteration=12 epoch=5 Average Reward per episode: 207.5651693494899\n",
      "iteration=12 epoch=6 Average Reward per episode: 207.2831432075173\n",
      "iteration=12 epoch=7 Average Reward per episode: 479.3415605327823\n",
      "iteration=12 epoch=8 Average Reward per episode: 81.43710189927984\n",
      "iteration=12 epoch=9 Average Reward per episode: 81.49168036769332\n",
      "loading best result\n",
      "rollout iteration 13 with epsilon=35.00%...\n",
      "starting training on rollout information...\n",
      "iteration=13 epoch=0 Average Reward per episode: 210.93684820303383\n",
      "iteration=13 epoch=1 Average Reward per episode: 210.93752703627564\n",
      "iteration=13 epoch=2 Average Reward per episode: 210.94068363392972\n",
      "iteration=13 epoch=3 Average Reward per episode: 211.02321995447042\n",
      "iteration=13 epoch=4 Average Reward per episode: 211.0396780805689\n",
      "iteration=13 epoch=5 Average Reward per episode: -0.07736559324073494\n",
      "iteration=13 epoch=6 Average Reward per episode: -0.07747433711659057\n",
      "iteration=13 epoch=7 Average Reward per episode: -0.07743653872087411\n",
      "iteration=13 epoch=8 Average Reward per episode: -0.07725580434546404\n",
      "iteration=13 epoch=9 Average Reward per episode: -0.07668647417635333\n",
      "loading best result\n",
      "rollout iteration 14 with epsilon=30.00%...\n",
      "starting training on rollout information...\n",
      "iteration=14 epoch=0 Average Reward per episode: 211.4427789215336\n",
      "iteration=14 epoch=1 Average Reward per episode: 211.07410682285135\n",
      "iteration=14 epoch=2 Average Reward per episode: -0.07766121041893137\n",
      "iteration=14 epoch=3 Average Reward per episode: 209.09730349385782\n",
      "iteration=14 epoch=4 Average Reward per episode: 1.1389049613105575\n",
      "iteration=14 epoch=5 Average Reward per episode: 1.1526022103942455\n",
      "iteration=14 epoch=6 Average Reward per episode: 1.155513985942174\n",
      "iteration=14 epoch=7 Average Reward per episode: -0.07758090682933254\n",
      "iteration=14 epoch=8 Average Reward per episode: -0.07731591153472629\n",
      "iteration=14 epoch=9 Average Reward per episode: -0.0772116228489377\n",
      "loading best result\n",
      "rollout iteration 15 with epsilon=25.00%...\n",
      "starting training on rollout information...\n",
      "iteration=15 epoch=0 Average Reward per episode: 211.4556431422403\n",
      "iteration=15 epoch=1 Average Reward per episode: 211.05013499472224\n",
      "iteration=15 epoch=2 Average Reward per episode: 1.1471077554941393\n",
      "iteration=15 epoch=3 Average Reward per episode: 1.1374794307640437\n",
      "iteration=15 epoch=4 Average Reward per episode: 1.142401020196156\n",
      "iteration=15 epoch=5 Average Reward per episode: 1.136365661790145\n",
      "iteration=15 epoch=6 Average Reward per episode: 1.154562990362119\n",
      "iteration=15 epoch=7 Average Reward per episode: 1.131545078410385\n",
      "iteration=15 epoch=8 Average Reward per episode: 1.1365170924213686\n",
      "iteration=15 epoch=9 Average Reward per episode: -0.07731953377757267\n",
      "loading best result\n",
      "rollout iteration 16 with epsilon=20.00%...\n",
      "starting training on rollout information...\n",
      "iteration=16 epoch=0 Average Reward per episode: 211.43679455057855\n",
      "iteration=16 epoch=1 Average Reward per episode: 211.45189323846006\n",
      "iteration=16 epoch=2 Average Reward per episode: 213.4591160915076\n",
      "iteration=16 epoch=3 Average Reward per episode: -0.07756592907352236\n",
      "iteration=16 epoch=4 Average Reward per episode: -0.07702647393353744\n",
      "iteration=16 epoch=5 Average Reward per episode: -0.07783961355082536\n",
      "iteration=16 epoch=6 Average Reward per episode: -0.07764765865837792\n",
      "iteration=16 epoch=7 Average Reward per episode: -0.07715691583977793\n",
      "iteration=16 epoch=8 Average Reward per episode: -0.07752387555699221\n",
      "iteration=16 epoch=9 Average Reward per episode: -0.07731690978981962\n",
      "loading best result\n",
      "rollout iteration 17 with epsilon=15.00%...\n",
      "starting training on rollout information...\n",
      "iteration=17 epoch=0 Average Reward per episode: 210.9378154906674\n",
      "iteration=17 epoch=1 Average Reward per episode: 210.93694878948918\n",
      "iteration=17 epoch=2 Average Reward per episode: 1.130783776686863\n",
      "iteration=17 epoch=3 Average Reward per episode: 1.1444527926149068\n",
      "iteration=17 epoch=4 Average Reward per episode: 1.1336440528740355\n",
      "iteration=17 epoch=5 Average Reward per episode: 1.1448445161936263\n",
      "iteration=17 epoch=6 Average Reward per episode: 1.130353672254825\n",
      "iteration=17 epoch=7 Average Reward per episode: 1.1300655446045158\n",
      "iteration=17 epoch=8 Average Reward per episode: 1.135157294666573\n",
      "iteration=17 epoch=9 Average Reward per episode: 1.1558768047532477\n",
      "loading best result\n",
      "rollout iteration 18 with epsilon=10.00%...\n",
      "starting training on rollout information...\n",
      "iteration=18 epoch=0 Average Reward per episode: 210.9380566283929\n",
      "iteration=18 epoch=1 Average Reward per episode: 209.43285916010026\n",
      "iteration=18 epoch=2 Average Reward per episode: 1.1508645430757525\n",
      "iteration=18 epoch=3 Average Reward per episode: 1.1490610531769274\n",
      "iteration=18 epoch=4 Average Reward per episode: 1.1478083146904599\n",
      "iteration=18 epoch=5 Average Reward per episode: 1.157967889596723\n",
      "iteration=18 epoch=6 Average Reward per episode: 1.136274276179394\n",
      "iteration=18 epoch=7 Average Reward per episode: 1.1282761301695334\n",
      "iteration=18 epoch=8 Average Reward per episode: 1.1264184839586608\n",
      "iteration=18 epoch=9 Average Reward per episode: 1.1225860724244454\n",
      "loading best result\n",
      "rollout iteration 19 with epsilon=5.00%...\n",
      "starting training on rollout information...\n",
      "iteration=19 epoch=0 Average Reward per episode: 211.46391465481565\n",
      "iteration=19 epoch=1 Average Reward per episode: 211.02401606957488\n",
      "iteration=19 epoch=2 Average Reward per episode: 1.1340758374991053\n",
      "iteration=19 epoch=3 Average Reward per episode: 1.1684956951993475\n",
      "iteration=19 epoch=4 Average Reward per episode: 1.1348963778748016\n",
      "iteration=19 epoch=5 Average Reward per episode: 1.1345649955901647\n",
      "iteration=19 epoch=6 Average Reward per episode: 1.1380309305117946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=19 epoch=7 Average Reward per episode: 1.1402290182047188\n",
      "iteration=19 epoch=8 Average Reward per episode: 1.129052722531172\n",
      "iteration=19 epoch=9 Average Reward per episode: 1.1394790785552238\n",
      "loading best result\n",
      "rollout iteration 20 with epsilon=0.00%...\n",
      "starting training on rollout information...\n",
      "iteration=20 epoch=0 Average Reward per episode: 81.47664309679548\n",
      "iteration=20 epoch=1 Average Reward per episode: 81.42877594808672\n",
      "iteration=20 epoch=2 Average Reward per episode: 81.38494661864988\n",
      "iteration=20 epoch=3 Average Reward per episode: -0.07779244179122016\n",
      "iteration=20 epoch=4 Average Reward per episode: -0.07716795977970377\n",
      "iteration=20 epoch=5 Average Reward per episode: -0.077853330194281\n",
      "iteration=20 epoch=6 Average Reward per episode: -0.0781145402467274\n",
      "iteration=20 epoch=7 Average Reward per episode: -0.07759075839234084\n",
      "iteration=20 epoch=8 Average Reward per episode: -0.07797432821344756\n",
      "iteration=20 epoch=9 Average Reward per episode: -0.07785900432675708\n",
      "loading best result\n",
      "loading best result\n"
     ]
    }
   ],
   "source": [
    "max_episode_steps = 300\n",
    "env = gym.make('unbalanced-disk-sincos-v0', dt=0.025, umax=3.)\n",
    "env = gym.wrappers.time_limit.TimeLimit(env,max_episode_steps=max_episode_steps)\n",
    "\n",
    "target_angle = np.pi # target set to be balanced on top\n",
    "# reward_function =  lambda self: (np.cos(self.th - target_angle)+1)**2  - np.cos(self.th-(np.pi+target_angle)) - 0.01*(self.omega)**2 - 0.01*(self.u)**2\n",
    "reward_function =  lambda self: ((np.cos(self.th-target_angle)+1.5)**2 - 0.25) + 0.00125*(((np.cos(self.th)+1)/2)*(self.omega)**2) - 0.0075*((self.u)**2) - 0.0025*((self.omega)**2)\n",
    "# \n",
    "\n",
    "# a = 1\n",
    "# b = 0.01\n",
    "# c = 0.001\n",
    "\n",
    "# reward_function =  lambda self: -(a*(np.abs(self.th)-np.abs(target_angle))**2 + b*(self.omega)**2 + c*(self.u)**2)\n",
    "\n",
    "env.change_reward_function(reward_function)\n",
    "\n",
    "env.set_discrete_values(discrete_size = 9, minmax = 3.0, div = 2.5, rnd = 2)\n",
    "\n",
    "gamma = 0.98 #f=)\n",
    "batch_size = 32 #f=)\n",
    "N_iterations = 21 #f=)\n",
    "N_rollout = 20000 #f=)\n",
    "N_epochs = 10 #f=)\n",
    "N_evals = 5 #f=)\n",
    "lr = 0.0005 #given\n",
    "\n",
    "assert isinstance(env.action_space,gym.spaces.Discrete), 'action space requires to be discrete'\n",
    "Q = Qfunction(env)\n",
    "optimizer = torch.optim.Adam(Q.parameters(),lr=lr) #low learning rate\n",
    "DQN_rollout(Q, optimizer, env, use_target_net=True, gamma=gamma, N_iterations=N_iterations, \\\n",
    "            N_rollout=N_rollout, N_epochs=N_epochs, N_evals=N_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e71adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_episode_steps = 200\n",
    "# env = gym.make('unbalanced-disk-sincos-v0', dt=0.025, umax=3.)\n",
    "# env = gym.wrappers.time_limit.TimeLimit(env,max_episode_steps=max_episode_steps)\n",
    "# env.set_discrete_values(discrete_size = 13, minmax = 3.0, div = 2.5, rnd = 2)\n",
    "\n",
    "# target_angle = np.pi # target set to be balanced on top\n",
    "\n",
    "# gamma = 0.98 #f=)\n",
    "# batch_size = 32 #f=)\n",
    "# N_iterations = 21 #f=)\n",
    "# N_rollout = 20000 #f=)\n",
    "# N_epochs = 10 #f=)\n",
    "# N_evals = 5 #f=)\n",
    "# lr = 0.0005 #given\n",
    "\n",
    "# a_list = [0.5,1,5]\n",
    "# b_list = [0.1, 0.01, 0.001]\n",
    "# c_list = [0.1, 0.01, 0.001]\n",
    "\n",
    "# results_table = np.zeros((len(a_list),len(b_list),len(c_list)))\n",
    "\n",
    "# best_result = -float('inf') \n",
    "# best_result_idx = [0,0,0]\n",
    "\n",
    "# for i, a in enumerate(a_list):\n",
    "#     for j, b in enumerate(b_list):\n",
    "#         for k, c in enumerate(c_list):\n",
    "#             print(f'Currently running a = {a}, b = {b} and c = {c}')\n",
    "#             env_it = deepcopy(env)\n",
    "#             reward_function =  lambda self: -(a*(np.abs(self.th)-np.abs(target_angle))**2 + b*(self.omega)**2 + c*(self.u)**2)\n",
    "#             env_it.change_reward_function(reward_function)\n",
    "            \n",
    "#             assert isinstance(env.action_space,gym.spaces.Discrete), 'action space requires to be discrete'\n",
    "#             Q = Qfunction(env_it)\n",
    "#             optimizer = torch.optim.Adam(Q.parameters(),lr=lr) #low learning rate\n",
    "#             DQN_rollout(Q, optimizer, env_it, use_target_net=True, gamma=gamma, N_iterations=N_iterations, \\\n",
    "#                         N_rollout=N_rollout, N_epochs=N_epochs, N_evals=N_evals)\n",
    "            \n",
    "#             result = eval_Q(Q,env_it)\n",
    "#             results_table[i,j,k] = result\n",
    "            \n",
    "#             print(f'Result = {result}')\n",
    "            \n",
    "#             if result > best_result:\n",
    "#                 best_result = result\n",
    "#                 best_result_idx = [i,j,k]\n",
    "#                 print(f'################################# \\n new best',result,'saving result... \\n#################################')\n",
    "\n",
    "\n",
    "# print(best_result)\n",
    "# print(results_table)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180bf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "-3.0\n",
      "0.48\n",
      "0.48\n",
      "0.19\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.48\n",
      "1.2\n",
      "1.2\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "-0.48\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "-0.19\n",
      "-0.19\n",
      "-0.19\n",
      "1.2\n",
      "1.2\n",
      "1.2\n",
      "3.0\n",
      "3.0\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "701.9496338871293"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(Q,env)\n",
    "eval_Q(Q,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a59e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname('')\n",
    "np.save(os.path.realpath(os.path.join(ROOT_DIR, 'Qfunction.npy')), Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc7a5889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "Rewards = [eval_Q(Q,env) for i in range(100)]\n",
    "plt.plot(Rewards,'.')\n",
    "plt.title(f'mean={np.mean(Rewards)}')\n",
    "plt.xlabel('instance')\n",
    "plt.ylabel('Reward per episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f0815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
