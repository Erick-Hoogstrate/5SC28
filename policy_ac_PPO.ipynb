{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, gym_unbalanced_disk, time\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, SAC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_angle(theta):\n",
    "    return ((theta)%(2*np.pi))-np.pi\n",
    "\n",
    "def compute_reward(self):\n",
    "    q=normalise_angle(self.th)\n",
    "    if abs(q)<np.pi/3:\n",
    "        return 500 - 10*self.omega**2 +(self.u/self.omega)**2\n",
    "    else:\n",
    "        return q**2+20*self.omega**2+self.u**2 # +10*(self.u/self.omega)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "target_angle=np.pi\n",
    "reward_fun = lambda self: (np.cos(self.th - target_angle)+1)**2  - np.cos(self.th-(np.pi+target_angle)) - 0.1 *(self.omega)**2 - 0.001*(self.u)**2 # mediocre\n",
    "reward_fun = lambda self: np.exp(-(self.th%(2*np.pi)-np.pi)**2/(2*(np.pi/7)**2)) #example reward function, change this! Okay\n",
    "reward_fun=lambda self: -((self.th%(2*np.pi)-np.pi)**2 + 0.5 * self.omega**2)\n",
    "reward_fun=lambda self: -((self.th-np.pi)%(2*np.pi)**2 + 0.1 * self.omega**2 + 0.001 * self.u**2)\n",
    "reward_fun =  lambda self: ((np.cos(self.th-target_angle)+1.5)*2 - 0.25) + 0.00125*(((np.cos(self.th)+1)/2)*(self.omega)**2) - 0.01*((self.u)**2)\n",
    "reward_fun = lambda self: 5*normalise_angle(self.th)**2+0.1*self.omega**2-1.5*self.u**2\n",
    "reward_fun = lambda self: compute_reward(self)\n",
    "\n",
    "\n",
    "env = gym.make('unbalanced-disk-v0', dt=0.025, umax=3.,reward_fun=reward_fun) \n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1) #b)\n",
    "# model = SAC('MlpPolicy', env, verbose=2, learning_starts=1000) #b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 300      |\n",
      "|    ep_rew_mean     | 1.39e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 246      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 2.17e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007658064 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 5.96e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.12e+05    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.56e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 300          |\n",
      "|    ep_rew_mean          | 3.78e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040684994 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.000369    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+06     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.76e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 7.84e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004153791 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -0.000104   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+07    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.7e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 300          |\n",
      "|    ep_rew_mean          | 1.31e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018919314 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.57e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.17e+07     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.69e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    247\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    249\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 250\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:207\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    204\u001b[0m             terminal_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mpredict_values(terminal_obs)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    205\u001b[0m         rewards[idx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m terminal_value\n\u001b[1;32m--> 207\u001b[0m rollout_buffer\u001b[39m.\u001b[39;49madd(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_last_obs, actions, rewards, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_last_episode_starts, values, log_probs)\n\u001b[0;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39m=\u001b[39m new_obs\n\u001b[0;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_episode_starts \u001b[39m=\u001b[39m dones\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:440\u001b[0m, in \u001b[0;36mRolloutBuffer.add\u001b[1;34m(self, obs, action, reward, episode_start, value, log_prob)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(reward)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_starts[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(episode_start)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos] \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mclone()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_probs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos] \u001b[39m=\u001b[39m log_prob\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100_000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "thetas=[]\n",
    "omegas=[]\n",
    "rewards=[]\n",
    "try:\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        thetas.append(obs[0])\n",
    "        omegas.append(obs[1])\n",
    "        rewards.append(reward)\n",
    "        time.sleep(1/50)\n",
    "        if done:\n",
    "            obs=env.reset()\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25310b1cbe0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas)\n",
    "plt.plot(omegas)\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m         obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(us[i])\n\u001b[0;32m      8\u001b[0m         thetas\u001b[39m.\u001b[39mappend(obs[\u001b[39m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m         env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\gym\\wrappers\\time_limit.py:18\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32md:\\documents\\tue\\msc_ai&es\\5sc28-ml for systems and control\\project_example\\gym_unbalanced_disk\\envs\\UnbalancedDisk.py:66\u001b[0m, in \u001b[0;36mUnbalancedDisk.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     64\u001b[0m     domegadt \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39momega0\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msin(th\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta_th) \u001b[39m-\u001b[39m friction \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mKu\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([dthdt, domegadt])\n\u001b[1;32m---> 66\u001b[0m sol \u001b[39m=\u001b[39m solve_ivp(f,[\u001b[39m0\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdt],[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mth,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49momega]) \u001b[39m#integration\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mth, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39momega \u001b[39m=\u001b[39m sol\u001b[39m.\u001b[39my[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     68\u001b[0m \u001b[39m##### End do not edit   #####\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\scipy\\integrate\\_ivp\\ivp.py:663\u001b[0m, in \u001b[0;36msolve_ivp\u001b[1;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[39mif\u001b[39;00m t_eval \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    662\u001b[0m     ts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(ts)\n\u001b[1;32m--> 663\u001b[0m     ys \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack(ys)\u001b[39m.\u001b[39mT\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m ts:\n\u001b[0;32m    665\u001b[0m     ts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack(ts)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\anaconda3\\envs\\ml4sc\\lib\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# obs = env.reset()\n",
    "# thetas=[]\n",
    "# windup_time=15\n",
    "# us=np.array([3]*windup_time + [-3]*(1000-windup_time))*(-1)\n",
    "# try:\n",
    "#     for i in range(1000):\n",
    "#         obs, reward, done, info = env.step(us[i])\n",
    "#         thetas.append(obs[0])\n",
    "#         env.render()\n",
    "#         time.sleep(1/50)\n",
    "#         if done:\n",
    "#             env.reset()\n",
    "# finally:\n",
    "#     env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
