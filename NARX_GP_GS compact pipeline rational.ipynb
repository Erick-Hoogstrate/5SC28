{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d7fdd8c",
   "metadata": {},
   "source": [
    "# NARX GP Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62974d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic, Product\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from data import load_narx_data, load_data\n",
    "from util_fun import calculate_error_nrms, use_NARX_model_in_simulation, plot_NRMS_Pred_vs_Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c09dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stationary parameters\n",
    "\n",
    "Split = [0.6, 0.2, 0.2] # split; [training, validation, test]\n",
    "total_number_of_points = 5000 # total number of points to consider from the larger dataset (starting from index 0)\n",
    "\n",
    "na_list=[*range(2,11)]\n",
    "nb_list=[*range(2,6)]\n",
    "restarts = 5\n",
    "\n",
    "val_pred_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "val_sim_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "test_pred_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "test_sim_NRMSs=np.ndarray((len(na_list),len(nb_list)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65cd611d",
   "metadata": {},
   "source": [
    "## Define your kernel here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b13d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RationalQuadratic() + WhiteKernel()\n",
    "reg = GaussianProcessRegressor(kernel, n_restarts_optimizer=restarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7853ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3000 datapoints for training set\n"
     ]
    }
   ],
   "source": [
    "#Load normal data\n",
    "Xtrain,Ytrain = load_data(section=\"train\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xval,Yval = load_data(section=\"validation\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xtest,Ytest = load_data(section=\"test\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e114a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 2, nb= 2\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 2, nb= 3\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 2, nb= 4\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 2, nb= 5\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 2\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 3\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 4\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 5\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 4, nb= 2\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 4, nb= 3\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 4, nb= 4\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 4, nb= 5\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 5, nb= 2\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m Yval_pred, Yval_pred_std \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(Xval_NARX,return_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[39m#Simulation on validation set\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m Yval_sim \u001b[39m=\u001b[39m use_NARX_model_in_simulation(Xval, fmodel, n_a, n_b)\n\u001b[0;32m     28\u001b[0m \u001b[39m#Prediction on test set\u001b[39;00m\n\u001b[0;32m     29\u001b[0m Ytest_pred, Ytest_pred_std \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(Xtest_NARX,return_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\20191695\\Desktop\\TUe\\Master\\Year1\\Q4\\5SC28\\5SC28\\util_fun.py:21\u001b[0m, in \u001b[0;36muse_NARX_model_in_simulation\u001b[1;34m(ulist, f, na, nb)\u001b[0m\n\u001b[0;32m     18\u001b[0m ylist \u001b[39m=\u001b[39m []\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m unow \u001b[39min\u001b[39;00m ulist:\n\u001b[0;32m     20\u001b[0m     \u001b[39m#compute the current y given by f\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     ynow \u001b[39m=\u001b[39m f(upast,ypast) \n\u001b[0;32m     23\u001b[0m     \u001b[39m#update past arrays\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     upast\u001b[39m.\u001b[39mappend(unow)\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(u, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m reg\u001b[39m.\u001b[39mfit(XtrainSparse, YtrainSparse)\n\u001b[0;32m     19\u001b[0m \u001b[39m#Initialize parameters for simulation\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fmodel \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m u,y: reg\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mconcatenate([u,y])[\u001b[39mNone\u001b[39;49;00m,:])[\u001b[39m0\u001b[39m] \n\u001b[0;32m     22\u001b[0m \u001b[39m#Prediction on validation set\u001b[39;00m\n\u001b[0;32m     23\u001b[0m Yval_pred, Yval_pred_std \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(Xval_NARX,return_std\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:405\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.predict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[39mreturn\u001b[39;00m y_mean\n\u001b[0;32m    403\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Predict based on GP posterior\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[39m# Alg 2.1, page 19, line 4 -> f*_bar = K(X_test, X_train) . alpha\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     K_trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train_)\n\u001b[0;32m    406\u001b[0m     y_mean \u001b[39m=\u001b[39m K_trans \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_\n\u001b[0;32m    408\u001b[0m     \u001b[39m# undo normalisation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:846\u001b[0m, in \u001b[0;36mSum.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[39mreturn\u001b[39;00m K1 \u001b[39m+\u001b[39m K2, np\u001b[39m.\u001b[39mdstack((K1_gradient, K2_gradient))\n\u001b[0;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk1(X, Y) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk2(X, Y)\n",
      "File \u001b[1;32mc:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1904\u001b[0m, in \u001b[0;36mRationalQuadratic.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGradient can only be evaluated when Y is None.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1903\u001b[0m     dists \u001b[39m=\u001b[39m cdist(X, Y, metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqeuclidean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1904\u001b[0m     K \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m+\u001b[39;49m dists \u001b[39m/\u001b[39;49m (\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlength_scale\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha\n\u001b[0;32m   1906\u001b[0m \u001b[39mif\u001b[39;00m eval_gradient:\n\u001b[0;32m   1907\u001b[0m     \u001b[39m# gradient with respect to length_scale\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameter_length_scale\u001b[39m.\u001b[39mfixed:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, n_a in enumerate(na_list):\n",
    "    for j, n_b in enumerate(nb_list):\n",
    "        \n",
    "        print(f\"Currently running: na= {n_a}, nb= {n_b}\")\n",
    "        \n",
    "        #Construct NARX data\n",
    "        Xtrain_NARX,Ytrain_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"train\", split=Split, as_tensor=False)\n",
    "        Xval_NARX,Yval_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"validation\", split=Split, as_tensor=False)\n",
    "        Xtest_NARX,Ytest_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"test\", split=Split, as_tensor=False)\n",
    "        \n",
    "\n",
    "        #Convert to sparce matrices\n",
    "        XtrainSparse = csr_matrix(Xtrain_NARX).toarray()\n",
    "        YtrainSparse = csr_matrix(Ytrain_NARX).toarray().transpose()\n",
    "\n",
    "        #Fit the GP\n",
    "        reg.fit(XtrainSparse, YtrainSparse)\n",
    "        \n",
    "        #Initialize parameters for simulation\n",
    "        fmodel = lambda u,y: reg.predict(np.concatenate([u,y])[None,:])[0] \n",
    "        \n",
    "        #Prediction on validation set\n",
    "        Yval_pred, Yval_pred_std = reg.predict(Xval_NARX,return_std=True)\n",
    "        \n",
    "        #Simulation on validation set\n",
    "        Yval_sim = use_NARX_model_in_simulation(Xval, fmodel, n_a, n_b)\n",
    "        \n",
    "        #Prediction on test set\n",
    "        Ytest_pred, Ytest_pred_std = reg.predict(Xtest_NARX,return_std=True)\n",
    "        \n",
    "        #Simulation on test set\n",
    "        Ytest_sim = use_NARX_model_in_simulation(Xtest, fmodel, n_a, n_b)\n",
    "        \n",
    "        #Store results\n",
    "        val_pred_NRMSs[i,j] = calculate_error_nrms(Yval_pred, Yval_NARX)\n",
    "        val_sim_NRMSs[i,j] = calculate_error_nrms(Yval_sim, Yval)\n",
    "        test_pred_NRMSs[i,j] = calculate_error_nrms(Ytest_pred, Ytest_NARX)\n",
    "        test_sim_NRMSs[i,j] = calculate_error_nrms(Ytest_sim, Ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93dc64c3",
   "metadata": {},
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67785fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_na_nb_val_pred, best_na_nb_val_sim = plot_NRMS_Pred_vs_Sim(val_pred_NRMSs, val_sim_NRMSs, na_list, nb_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e39ed47",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13df093",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_na_nb_test_pred, best_na_nb_test_sim = plot_NRMS_Pred_vs_Sim(test_pred_NRMSs, test_sim_NRMSs, na_list, nb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best test prediction NRMS found: {test_pred_NRMSs.min()}\")\n",
    "print(f\"Best test simulation NRMS found: {test_sim_NRMSs.min()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a72ec3",
   "metadata": {},
   "source": [
    "# Run best na and nb again on larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a, n_b = best_na_nb_val_pred\n",
    "Split = [0.6, 0.2, 0.2] # split; [training, validation, test]\n",
    "total_number_of_points = 300 # total number of points to consider from the larger dataset (starting from index 0)\n",
    "restart = 5\n",
    "\n",
    "Xtrain_NARX, Ytrain_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"train\", split=Split, as_tensor=False)\n",
    "Xval_NARX, Yval_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"validation\", split=Split, as_tensor=False)\n",
    "Xtest_NARX, Ytest_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"test\", split=Split, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainNARXSparse = csr_matrix(Xtrain_NARX).toarray()\n",
    "YtrainNARXSparse = csr_matrix(Ytrain_NARX).toarray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale_bounds=[1,50]) + WhiteKernel(noise_level_bounds=[1e-6,1e-2])\n",
    "# kernel = RationalQuadratic() + WhiteKernel()\n",
    "reg = GaussianProcessRegressor(kernel, n_restarts_optimizer=restart)\n",
    "\n",
    "reg.fit(XtrainNARXSparse, YtrainNARXSparse)\n",
    "\n",
    "print(reg.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_pred, Ytrain_pred_std = reg.predict(Xtrain_NARX,return_std=True)\n",
    "NRMS_train_pred = calculate_error_nrms(Ytrain_pred, Ytrain_NARX)\n",
    "print(f'Train prediction NRMS: {NRMS_train_pred:.2f} %')\n",
    "\n",
    "Yval_pred, Yval_pred_std = reg.predict(Xval_NARX,return_std=True)\n",
    "NRMS_val_pred = calculate_error_nrms(Yval_pred, Yval_NARX)\n",
    "print(f'Validation prediction NRMS: {NRMS_val_pred:.2f} %')\n",
    "\n",
    "Ytest_pred, Ytest_pred_std = reg.predict(Xtest_NARX,return_std=True)\n",
    "NRMS_test_pred = calculate_error_nrms(Ytest_pred, Ytest_NARX)\n",
    "print(f'Test prediction NRMS: {NRMS_test_pred:.2f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42144ce",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = load_data(section=\"train\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xval,Yval = load_data(section=\"validation\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xtest,Ytest = load_data(section=\"test\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model = lambda u,y: reg.predict(np.concatenate([u,y])[None,:])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c596b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_sim = use_NARX_model_in_simulation(Xtrain, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34896b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_train_sim = calculate_error_nrms(Ytrain_sim, Ytrain)\n",
    "print(f'Train simulation NRMS: {NRMS_train_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Ytrain,'b-.')\n",
    "plt.plot(Ytrain_pred, 'y')\n",
    "plt.plot(Ytrain_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Train prediction NRMS: {NRMS_train_pred:.2f} %')\n",
    "print(f'Train simulation NRMS: {NRMS_train_sim:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval_sim = use_NARX_model_in_simulation(Xval, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb72dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_val_sim = calculate_error_nrms(Yval_sim, Yval)\n",
    "print(f'Validation simulation NRMS: {NRMS_val_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Yval,'b-.')\n",
    "plt.plot(Yval_pred, 'y')\n",
    "plt.plot(Yval_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Validation prediction NRMS: {NRMS_val_pred:.2f} %')\n",
    "print(f'Validation simulation NRMS: {NRMS_val_sim:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_sim = use_NARX_model_in_simulation(Xtest, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_test_sim = calculate_error_nrms(Ytest_sim, Ytest)\n",
    "print(f'Test simulation NRMS: {NRMS_test_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Ytest,'b-.')\n",
    "plt.plot(Ytest_pred, 'y')\n",
    "plt.plot(Ytest_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Test prediction NRMS: {NRMS_test_pred:.2f} %')\n",
    "print(f'Test simulation NRMS: {NRMS_test_sim:.2f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f99cd909",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Prediction': [NRMS_train_pred, NRMS_val_pred, NRMS_test_pred],\n",
    "    'Simulation': [NRMS_train_sim, NRMS_val_sim, NRMS_test_sim]\n",
    "}\n",
    "    \n",
    "index = ['Train', 'Validation', 'Test']\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "df = df.round(2)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Prediction': [NRMS_train_pred, NRMS_val_pred, NRMS_test_pred],\n",
    "    'Simulation': [NRMS_train_sim, NRMS_val_sim, NRMS_test_sim]\n",
    "}\n",
    "    \n",
    "index = ['Train', 'Validation', 'Test']\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "df = df.round(2)\n",
    "\n",
    "display(df)\n",
    "\n",
    "dfs = [df, df, df]\n",
    "\n",
    "df_combined = pd.concat(\n",
    "    [df.rename(columns=lambda x: x.zfill(4)) for df in dfs],\n",
    "    keys=['HEADER TITLE{}'.format(i) for i in range(1, len(dfs) + 1)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
