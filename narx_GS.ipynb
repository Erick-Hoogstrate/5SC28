{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_fun import narx_sim_nrms, calculate_error_nrms, print_log\n",
    "from model import Narx\n",
    "from data import load_data, convert_to_narx, GS_Dataset, create_gs_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from time import time, sleep\n",
    "from datetime import timedelta\n",
    "from os import path\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "N_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_a\": [*range(1, 10)],\n",
    "    \"n_b\": [*range(10, 30)],\n",
    "    \"n_layers\": [1, 3, 5, 7],\n",
    "    \"n_nodes\": [10, 50, 100, 200, 500],\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    \"n_a\": [*range(1, 4)],\n",
    "    \"n_b\": [*range(10, 13)],\n",
    "    \"n_layers\": [1, 3],\n",
    "    \"n_nodes\": [10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GSResults:\n",
    "    best_model: Narx = None\n",
    "    best_sim_model: Narx = None\n",
    "    best_nrms: float = None\n",
    "    best_sim_nrms: float = None\n",
    "    loss_list: list = None\n",
    "    nrms_list: list = None\n",
    "    sim_nrms_list: list = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_narx_simval(\n",
    "    model: Narx,\n",
    "    n_a: int,\n",
    "    n_b: int,\n",
    "    data: GS_Dataset,\n",
    "    log_file: str,\n",
    "    param_msg: str = None,\n",
    "    n_epochs: int = N_EPOCHS,\n",
    "    device: torch.device = DEVICE,\n",
    "):\n",
    "    # initialise comparison values and results lists\n",
    "    best_nrms = float(\"inf\")\n",
    "    best_model = None\n",
    "    best_sim_nrms = float(\"inf\")\n",
    "    best_sim_model = None\n",
    "    loss_list = []\n",
    "    nrms_list = []\n",
    "    sim_nrms_list = []\n",
    "\n",
    "    # initialise checkpoints for validation\n",
    "    checkpoints = [*range(0, n_epochs + 1, max(n_epochs // 25, 1))]\n",
    "    if checkpoints[-1] != n_epochs:\n",
    "        checkpoints += [n_epochs]\n",
    "\n",
    "    # start training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        loss = torch.mean((model(data.x_train) - data.y_train) ** 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch in checkpoints:\n",
    "            print_log(f\"Checkpoint at epoch {epoch+1}: \\n\" + param_msg, log_file )\n",
    "            # append loss to list, check prediction and simulation nrms\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            nrms = calculate_error_nrms(model.forward(data.x_val), data.y_val)\n",
    "            nrms_list.append(nrms)\n",
    "            if nrms < best_nrms:\n",
    "                print_log(\n",
    "                    f\"current pred NRMS: {nrms}, previous best pred NRMS: {best_nrms} \\n\",\n",
    "                    log_file,\n",
    "                )\n",
    "                best_nrms = nrms\n",
    "                best_model = deepcopy(model)\n",
    "\n",
    "            _, _, _, sim_nrms = narx_sim_nrms(\n",
    "                model, n_a, n_b, data.x_data, data.y_data, device\n",
    "            )\n",
    "            sim_nrms_list.append(sim_nrms)\n",
    "            if sim_nrms < best_sim_nrms:\n",
    "                print_log(\n",
    "                    f\"current sim NRMS: {sim_nrms}, previous best sim NRMS: {best_sim_nrms} \\n\",\n",
    "                    log_file,\n",
    "                )\n",
    "                best_sim_nrms = sim_nrms\n",
    "                best_sim_model = deepcopy(model)\n",
    "\n",
    "    results = GSResults(\n",
    "        best_model,\n",
    "        best_sim_model,\n",
    "        best_nrms,\n",
    "        best_sim_nrms,\n",
    "        loss_list,\n",
    "        nrms_list,\n",
    "        sim_nrms_list,\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_file():\n",
    "    filename='narx_gs_log'\n",
    "    fileext='.txt'\n",
    "    i=0\n",
    "    while(path.exists(filename+str(i)+fileext)):\n",
    "        i+=1\n",
    "    return filename+str(i)+fileext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new Grid Search with parameters {'n_a': [1, 2, 3], 'n_b': [10, 11, 12], 'n_layers': [1, 3], 'n_nodes': [10, 20]} \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i, n_a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid_search_params[\u001b[39m\"\u001b[39m\u001b[39mn_a\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m j, n_b \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid_search_params[\u001b[39m\"\u001b[39m\u001b[39mn_b\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m     23\u001b[0m         \u001b[39m# n_a and n_b are the only two parameters that change the dataset\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m         data \u001b[39m=\u001b[39m create_gs_dataset(x, y, n_a, n_b, device)\n\u001b[0;32m     25\u001b[0m         \u001b[39mfor\u001b[39;00m k, n_nodes \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid_search_params[\u001b[39m\"\u001b[39m\u001b[39mn_nodes\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m     26\u001b[0m             \u001b[39mfor\u001b[39;00m l, n_layers \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid_search_params[\u001b[39m\"\u001b[39m\u001b[39mn_layers\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m     27\u001b[0m                 \u001b[39m# general administration and timekeeping\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\TUe\\MSC_AI&ES\\5SC28-ML for Systems and Control\\Project\\data.py:84\u001b[0m, in \u001b[0;36mcreate_gs_dataset\u001b[1;34m(x_data, y_data, n_a, n_b, device)\u001b[0m\n\u001b[0;32m     82\u001b[0m x_train, x_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(x_data, y_data, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     83\u001b[0m x_train, y_train \u001b[39m=\u001b[39m convert_to_narx(x_train, y_train, n_a, n_b)\n\u001b[1;32m---> 84\u001b[0m x_val, y_val \u001b[39m=\u001b[39m convert_to_narx(x_val, y_val, n_a, n_b)\n\u001b[0;32m     85\u001b[0m x_train, x_val, y_train, y_val \u001b[39m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     87\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [x_train, x_val, y_train, y_val]\n\u001b[0;32m     88\u001b[0m ]\n\u001b[0;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m GS_Dataset(x_data, y_data, x_train, y_train, x_val, y_val)\n",
      "File \u001b[1;32md:\\Documents\\TUe\\MSC_AI&ES\\5SC28-ML for Systems and Control\\Project\\data.py:59\u001b[0m, in \u001b[0;36mconvert_to_narx\u001b[1;34m(x, y, n_a, n_b, as_tensor)\u001b[0m\n\u001b[0;32m     57\u001b[0m Y \u001b[39m=\u001b[39m []\n\u001b[0;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mmax\u001b[39m(n_a, n_b), \u001b[39mlen\u001b[39m(x)):\n\u001b[1;32m---> 59\u001b[0m     X\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mconcatenate([x[k \u001b[39m-\u001b[39;49m n_b : k], y[k \u001b[39m-\u001b[39;49m n_a : k]]))\n\u001b[0;32m     60\u001b[0m     Y\u001b[39m.\u001b[39mappend(y[k])\n\u001b[0;32m     62\u001b[0m X, Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X), np\u001b[39m.\u001b[39marray(Y)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "device = DEVICE\n",
    "n_epochs = N_EPOCHS\n",
    "best_nrms = float(\"inf\")\n",
    "best_sim_nrms = float(\"inf\")\n",
    "best_model = None\n",
    "best_sim_model = None\n",
    "best_params = None\n",
    "best_sim_params = None\n",
    "\n",
    "grid_search_params = test_params\n",
    "x, y = load_data()\n",
    "total_runs = 1\n",
    "for key in grid_search_params:\n",
    "    total_runs *= len(grid_search_params[key])\n",
    "run_counter = 0\n",
    "start_time_list = []\n",
    "log_file=make_log_file()\n",
    "\n",
    "print_log(f\"Starting new Grid Search with parameters {grid_search_params} \\n\", log_file)\n",
    "for i, n_a in enumerate(grid_search_params[\"n_a\"]):\n",
    "    for j, n_b in enumerate(grid_search_params[\"n_b\"]):\n",
    "        # n_a and n_b are the only two parameters that change the dataset\n",
    "        data = create_gs_dataset(x, y, n_a, n_b, device)\n",
    "        for k, n_nodes in enumerate(grid_search_params[\"n_nodes\"]):\n",
    "            for l, n_layers in enumerate(grid_search_params[\"n_layers\"]):\n",
    "                # general administration and timekeeping\n",
    "                run_counter += 1\n",
    "                start_time_list.append(time())\n",
    "                param_string = f\"{n_a=}, {n_b=}, {n_nodes=}, {n_layers=}\"\n",
    "                print_log(\n",
    "                    f\"Starting run {run_counter} out of {total_runs} \\n\", log_file\n",
    "                )\n",
    "                # generate model, do the actual training run, save the results\n",
    "                model = Narx(n_a + n_b, n_nodes, n_layers)\n",
    "                result = train_narx_simval(\n",
    "                    model, n_a, n_b, data, log_file, param_string, n_epochs, device\n",
    "                )\n",
    "                results_dict[param_string] = result\n",
    "\n",
    "                # check new results against old results, save if better\n",
    "                if result.best_nrms < best_nrms:\n",
    "                    print_log(\n",
    "                        f\"Found new best prediction model, with parameters {param_string} \\n\",\n",
    "                        log_file,\n",
    "                    )\n",
    "                    print_log(\n",
    "                        f\"new best pred NRMS= {result.best_nrms}, previous best: {best_nrms} \\n\",\n",
    "                        log_file,\n",
    "                    )\n",
    "                    best_nrms = result.best_nrms\n",
    "                    best_model = deepcopy(result.best_model)\n",
    "                    best_params = param_string\n",
    "                if result.best_sim_nrms < best_sim_nrms:\n",
    "                    print_log(\n",
    "                        f\"Found new best simulation model, with parameters {param_string} \\n\",\n",
    "                        log_file,\n",
    "                    )\n",
    "                    print_log(\n",
    "                        f\"new best sim NRMS= {result.best_sim_nrms}, previous best: {best_sim_nrms} \\n\",\n",
    "                        log_file,\n",
    "                    )\n",
    "                    best_sim_nrms = result.best_sim_nrms\n",
    "                    best_sim_model = deepcopy(result.best_sim_model)\n",
    "                    best_sim_params = param_string\n",
    "\n",
    "                # finish the run\n",
    "                run_time = timedelta(seconds=time() - start_time_list[-1])\n",
    "                total_time = timedelta(seconds=time() - start_time_list[0])\n",
    "                print_log(\n",
    "                    f\"Finished run {run_counter} out of {total_runs}. Time elapsed this run: {run_time}, total time elapsed: {total_time} \\n\",\n",
    "                    log_file,\n",
    "                )\n",
    "\n",
    "print_log(\n",
    "    f\"Best prediction model found with parameters: {best_params}, and NRMS: {best_nrms}. \\n \"\n",
    "    + f\"Best simulation model found with parameters: {best_sim_params}, and NRMS: {best_sim_nrms}. \\n\"\n",
    "    + f\"Total time elapsed: {time()-start_time_list[0]} \\n\",\n",
    "    log_file,\n",
    ")\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log3.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(filename+str(i)+fileext)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
