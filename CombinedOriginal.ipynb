{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from data import load_data, load_narx_data\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from data import load_narx_data\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared, Matern, Product\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a, n_b = 2, 2\n",
    "Split = [0.6, 0.2, 0.2] # split; [training, validation, test]\n",
    "total_number_of_points = 5000 # total number of points to consider from the larger dataset (starting from index 0)\n",
    "restart = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = load_narx_data(n_a, n_b, total_number_of_points, section=\"train\", split=Split, as_tensor=True)\n",
    "Xval,Yval = load_narx_data(n_a, n_b, total_number_of_points, section=\"validation\", split=Split, as_tensor=True)\n",
    "Xtest,Ytest = load_narx_data(n_a, n_b, total_number_of_points, section=\"test\", split=Split, as_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard settings\n",
    "kernel = RBF(length_scale=1) + WhiteKernel(noise_level=0.1)\n",
    "reg = GaussianProcessRegressor(kernel, n_restarts_optimizer=restart)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainSparse = csr_matrix(Xtrain)\n",
    "YtrainSparse = csr_matrix(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval = Yval.numpy()  # Convert Yval from Tensor to NumPy array\n",
    "Ytest = Ytest.numpy()  # Convert Ytest from Tensor to NumPy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval_pred, Yval_pred_std = reg.predict(Xval, return_std=True) \n",
    "\n",
    "NRMS = np.mean((Yval_pred-Yval)**2)**0.5/np.std(Yval)\n",
    "\n",
    "print(f'Validation NRMS= {NRMS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.kernel_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some nice plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "Ytrain_pred, Ytrain_pred_std = reg.predict(Xtrain, return_std=True) \n",
    "plt.figure(figsize=(12, 5)) \n",
    "plt.plot(Ytrain) \n",
    "plt.title('Prediction on the training set')\n",
    "plt.errorbar(np.arange(len(Xtrain)), Ytrain_pred, yerr=2 * Ytrain_pred_std, fmt='.r') \n",
    "plt.grid()\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Measured', 'Pred'])\n",
    "plt.xlim([0, 250])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5)) \n",
    "plt.title('Prediction on the validation set')\n",
    "plt.plot(Yval) \n",
    "Yval_pred, Yval_pred_std = reg.predict(Xval, return_std=True) \n",
    "plt.errorbar(np.arange(len(Xval)), Yval_pred, yerr=2 * Yval_pred_std, fmt='.r') \n",
    "plt.grid()\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Measured', 'Pred']) \n",
    "plt.xlim([0, 250])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f'Validation NRMS= {np.mean((Yval_pred-Yval)**2)**0.5/np.std(Yval)}')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.title('Prediction on the test set')\n",
    "plt.plot(Ytest)\n",
    "ytest_pred, ytest_pred_std = reg.predict(Xtest, return_std=True)\n",
    "plt.errorbar(np.arange(len(Xtest)), ytest_pred, yerr=2 * ytest_pred_std, fmt='.r')\n",
    "plt.grid()\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Measured', 'Pred'])\n",
    "plt.xlim([0, 250])\n",
    "plt.show()\n",
    "\n",
    "print(f'Test NRMS = {np.mean((ytest_pred - Ytest) ** 2, axis=0) ** 0.5 / np.std(Ytest)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
