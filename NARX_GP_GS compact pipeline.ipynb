{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d7fdd8c",
   "metadata": {},
   "source": [
    "# NARX GP Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62974d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic, Product\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from data import load_narx_data, load_data\n",
    "from util_fun import calculate_error_nrms, use_NARX_model_in_simulation, plot_NRMS_Pred_vs_Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c09dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stationary parameters\n",
    "\n",
    "Split = [0.6, 0.2, 0.2] # split; [training, validation, test]\n",
    "total_number_of_points = 5000 # total number of points to consider from the larger dataset (starting from index 0)\n",
    "\n",
    "na_list=[*range(2,11)]\n",
    "nb_list=[*range(2,6)]\n",
    "restarts = 5\n",
    "\n",
    "val_pred_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "val_sim_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "test_pred_NRMSs=np.ndarray((len(na_list),len(nb_list)))\n",
    "test_sim_NRMSs=np.ndarray((len(na_list),len(nb_list)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65cd611d",
   "metadata": {},
   "source": [
    "## Define your kernel here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b13d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RationalQuadratic() + WhiteKernel()\n",
    "reg = GaussianProcessRegressor(kernel, n_restarts_optimizer=restarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7853ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3000 datapoints for training set\n"
     ]
    }
   ],
   "source": [
    "#Load normal data\n",
    "Xtrain,Ytrain = load_data(section=\"train\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xval,Yval = load_data(section=\"validation\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xtest,Ytest = load_data(section=\"test\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e114a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 2, nb= 2\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 2, nb= 3\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 2, nb= 4\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 2, nb= 5\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 2\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 3\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 4\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 3, nb= 5\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 4, nb= 2\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 4, nb= 3\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 4, nb= 4\n",
      "Using 3000 datapoints for training set\n",
      "Currently running: na= 4, nb= 5\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running: na= 5, nb= 2\n",
      "Using 3000 datapoints for training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191695\\Anaconda3\\envs\\ml4sc\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "for i, n_a in enumerate(na_list):\n",
    "    for j, n_b in enumerate(nb_list):\n",
    "        \n",
    "        print(f\"Currently running: na= {n_a}, nb= {n_b}\")\n",
    "        \n",
    "        #Construct NARX data\n",
    "        Xtrain_NARX,Ytrain_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"train\", split=Split, as_tensor=False)\n",
    "        Xval_NARX,Yval_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"validation\", split=Split, as_tensor=False)\n",
    "        Xtest_NARX,Ytest_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"test\", split=Split, as_tensor=False)\n",
    "        \n",
    "\n",
    "        #Convert to sparce matrices\n",
    "        XtrainSparse = csr_matrix(Xtrain_NARX).toarray()\n",
    "        YtrainSparse = csr_matrix(Ytrain_NARX).toarray().transpose()\n",
    "\n",
    "        #Fit the GP\n",
    "        reg.fit(XtrainSparse, YtrainSparse)\n",
    "        \n",
    "        #Initialize parameters for simulation\n",
    "        fmodel = lambda u,y: reg.predict(np.concatenate([u,y])[None,:])[0] \n",
    "        \n",
    "        #Prediction on validation set\n",
    "        Yval_pred, Yval_pred_std = reg.predict(Xval_NARX,return_std=True)\n",
    "        \n",
    "        #Simulation on validation set\n",
    "        Yval_sim = use_NARX_model_in_simulation(Xval, fmodel, n_a, n_b)\n",
    "        \n",
    "        #Prediction on test set\n",
    "        Ytest_pred, Ytest_pred_std = reg.predict(Xtest_NARX,return_std=True)\n",
    "        \n",
    "        #Simulation on test set\n",
    "        Ytest_sim = use_NARX_model_in_simulation(Xtest, fmodel, n_a, n_b)\n",
    "        \n",
    "        #Store results\n",
    "        val_pred_NRMSs[i,j] = calculate_error_nrms(Yval_pred, Yval_NARX)\n",
    "        val_sim_NRMSs[i,j] = calculate_error_nrms(Yval_sim, Yval)\n",
    "        test_pred_NRMSs[i,j] = calculate_error_nrms(Ytest_pred, Ytest_NARX)\n",
    "        test_sim_NRMSs[i,j] = calculate_error_nrms(Ytest_sim, Ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93dc64c3",
   "metadata": {},
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67785fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_na_nb_val_pred, best_na_nb_val_sim = plot_NRMS_Pred_vs_Sim(val_pred_NRMSs, val_sim_NRMSs, na_list, nb_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e39ed47",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13df093",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_na_nb_test_pred, best_na_nb_test_sim = plot_NRMS_Pred_vs_Sim(test_pred_NRMSs, test_sim_NRMSs, na_list, nb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best test prediction NRMS found: {test_pred_NRMSs.min()}\")\n",
    "print(f\"Best test simulation NRMS found: {test_sim_NRMSs.min()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14a72ec3",
   "metadata": {},
   "source": [
    "# Run best na and nb again on larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a, n_b = best_na_nb_val_pred\n",
    "Split = [0.6, 0.2, 0.2] # split; [training, validation, test]\n",
    "total_number_of_points = 300 # total number of points to consider from the larger dataset (starting from index 0)\n",
    "restart = 5\n",
    "\n",
    "Xtrain_NARX, Ytrain_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"train\", split=Split, as_tensor=False)\n",
    "Xval_NARX, Yval_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"validation\", split=Split, as_tensor=False)\n",
    "Xtest_NARX, Ytest_NARX = load_narx_data(n_a, n_b, total_number_of_points, section=\"test\", split=Split, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainNARXSparse = csr_matrix(Xtrain_NARX).toarray()\n",
    "YtrainNARXSparse = csr_matrix(Ytrain_NARX).toarray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale_bounds=[1,50]) + WhiteKernel(noise_level_bounds=[1e-6,1e-2])\n",
    "# kernel = RationalQuadratic() + WhiteKernel()\n",
    "reg = GaussianProcessRegressor(kernel, n_restarts_optimizer=restart)\n",
    "\n",
    "reg.fit(XtrainNARXSparse, YtrainNARXSparse)\n",
    "\n",
    "print(reg.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_pred, Ytrain_pred_std = reg.predict(Xtrain_NARX,return_std=True)\n",
    "NRMS_train_pred = calculate_error_nrms(Ytrain_pred, Ytrain_NARX)\n",
    "print(f'Train prediction NRMS: {NRMS_train_pred:.2f} %')\n",
    "\n",
    "Yval_pred, Yval_pred_std = reg.predict(Xval_NARX,return_std=True)\n",
    "NRMS_val_pred = calculate_error_nrms(Yval_pred, Yval_NARX)\n",
    "print(f'Validation prediction NRMS: {NRMS_val_pred:.2f} %')\n",
    "\n",
    "Ytest_pred, Ytest_pred_std = reg.predict(Xtest_NARX,return_std=True)\n",
    "NRMS_test_pred = calculate_error_nrms(Ytest_pred, Ytest_NARX)\n",
    "print(f'Test prediction NRMS: {NRMS_test_pred:.2f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42144ce",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = load_data(section=\"train\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xval,Yval = load_data(section=\"validation\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)\n",
    "Xtest,Ytest = load_data(section=\"test\", split=Split, total_number_of_points=total_number_of_points, as_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model = lambda u,y: reg.predict(np.concatenate([u,y])[None,:])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c596b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_sim = use_NARX_model_in_simulation(Xtrain, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34896b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_train_sim = calculate_error_nrms(Ytrain_sim, Ytrain)\n",
    "print(f'Train simulation NRMS: {NRMS_train_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Ytrain,'b-.')\n",
    "plt.plot(Ytrain_pred, 'y')\n",
    "plt.plot(Ytrain_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Train prediction NRMS: {NRMS_train_pred:.2f} %')\n",
    "print(f'Train simulation NRMS: {NRMS_train_sim:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval_sim = use_NARX_model_in_simulation(Xval, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb72dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_val_sim = calculate_error_nrms(Yval_sim, Yval)\n",
    "print(f'Validation simulation NRMS: {NRMS_val_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Yval,'b-.')\n",
    "plt.plot(Yval_pred, 'y')\n",
    "plt.plot(Yval_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Validation prediction NRMS: {NRMS_val_pred:.2f} %')\n",
    "print(f'Validation simulation NRMS: {NRMS_val_sim:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_sim = use_NARX_model_in_simulation(Xtest, sim_model, n_a, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMS_test_sim = calculate_error_nrms(Ytest_sim, Ytest)\n",
    "print(f'Test simulation NRMS: {NRMS_test_sim:.2f} %')\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(Ytest,'b-.')\n",
    "plt.plot(Ytest_pred, 'y')\n",
    "plt.plot(Ytest_sim)\n",
    "plt.title(\"Measured vs Prediction vs Simulation\")\n",
    "plt.legend(['Measured','Prediction','Simulation'])\n",
    "plt.show()\n",
    "\n",
    "print(f'Test prediction NRMS: {NRMS_test_pred:.2f} %')\n",
    "print(f'Test simulation NRMS: {NRMS_test_sim:.2f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f99cd909",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Prediction': [NRMS_train_pred, NRMS_val_pred, NRMS_test_pred],\n",
    "    'Simulation': [NRMS_train_sim, NRMS_val_sim, NRMS_test_sim]\n",
    "}\n",
    "    \n",
    "index = ['Train', 'Validation', 'Test']\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "df = df.round(2)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Prediction': [NRMS_train_pred, NRMS_val_pred, NRMS_test_pred],\n",
    "    'Simulation': [NRMS_train_sim, NRMS_val_sim, NRMS_test_sim]\n",
    "}\n",
    "    \n",
    "index = ['Train', 'Validation', 'Test']\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "df = df.round(2)\n",
    "\n",
    "display(df)\n",
    "\n",
    "dfs = [df, df, df]\n",
    "\n",
    "df_combined = pd.concat(\n",
    "    [df.rename(columns=lambda x: x.zfill(4)) for df in dfs],\n",
    "    keys=['HEADER TITLE{}'.format(i) for i in range(1, len(dfs) + 1)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
